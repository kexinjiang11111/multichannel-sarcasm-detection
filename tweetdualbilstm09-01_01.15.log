Mon, 01 Sep 2025 01:38:06 dataUtils.py INFO 构建词汇表...
Mon, 01 Sep 2025 01:38:47 main.py INFO model parameters: Namespace(batch_size=128, bidirectional=1, breakpoint=-1, cell_dropout_rate=0.5, data_dir='./tweet/spacy/', device=device(type='cuda'), dim_bert=768, dim_hidden=256, dim_input=300, embed_dropout_rate=0.5, final_dropout_rate=0.5, iter_num=4800, lambda1=0.5, learning_rate=0.001, linear_dropout_rate=0.1, lr_bert=5e-05, lr_word_vector=0.0001, margin=0.5, max_length_sen=100, model_dir='models/tweet_dualbilstm/', multi_dim=20, n_class=2, n_layers=3, name_dataset='tweet', name_model='dualbilstm', optim_type='Adam', path_wordvec='glove.840B.300d.txt', per_checkpoint=64, predict=0, predict_dir='./predict/', rnn_type='LSTM', save_model=0, seed=2021, supcon=1, t_sne=0, tokenizer='spacy', voc_size=30000, weight_decay=0)
Mon, 01 Sep 2025 01:38:47 main.py INFO Use device: cuda
Mon, 01 Sep 2025 01:38:47 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:38:47 main.py INFO Time of iter training 0.00 s
Mon, 01 Sep 2025 01:38:47 main.py INFO On iter step 0.0:, global step 0 Loss-step [2.7183 2.7183 2.7183 2.7183]
Mon, 01 Sep 2025 01:38:52 main.py INFO In dataset train: Loss is [2.0646 0.6921 0.6794 0.6931]
Mon, 01 Sep 2025 01:38:52 main.py INFO 		Acc is 0.5204, F1-micro is 0.5204
Mon, 01 Sep 2025 01:38:52 main.py INFO 		F1-macro is 0.3815, AUC is 0.5000
Mon, 01 Sep 2025 01:38:52 main.py INFO 		Pre-macro is 0.5970, Rec_macro is 0.5128
Mon, 01 Sep 2025 01:38:52 main.py INFO 		For sarcasm, C_M is 
[[ 235 4739]
 [ 111 5027]]
Mon, 01 Sep 2025 01:38:52 main.py INFO 		Acc is 0.7357, F1-micro is 0.7357
Mon, 01 Sep 2025 01:38:52 main.py INFO 		F1-macro is 0.4239, AUC is 0.5000
Mon, 01 Sep 2025 01:38:52 main.py INFO 		Pre-macro is 0.3678, Rec_macro is 0.5000
Mon, 01 Sep 2025 01:38:52 main.py INFO 		For literal, C_M is 
[[   0 2673]
 [   0 7439]]
Mon, 01 Sep 2025 01:38:52 main.py INFO 		Acc is 0.4997, F1-micro is 0.4997
Mon, 01 Sep 2025 01:38:52 main.py INFO 		F1-macro is 0.3332, AUC is 0.5000
Mon, 01 Sep 2025 01:38:52 main.py INFO 		Pre-macro is 0.2499, Rec_macro is 0.5000
Mon, 01 Sep 2025 01:38:52 main.py INFO 		For deep, C_M is 
[[5053    0]
 [5059    0]]
Mon, 01 Sep 2025 01:38:54 main.py INFO In dataset test: Loss is [2.0646 0.6915 0.6800 0.6931]
Mon, 01 Sep 2025 01:38:54 main.py INFO 		Acc is 0.5260, F1-micro is 0.5260
Mon, 01 Sep 2025 01:38:54 main.py INFO 		F1-macro is 0.3829, AUC is 0.5000
Mon, 01 Sep 2025 01:38:54 main.py INFO 		Pre-macro is 0.5603, Rec_macro is 0.5087
Mon, 01 Sep 2025 01:38:54 main.py INFO 		For sarcasm, C_M is 
[[ 181 3731]
 [ 122 4094]]
Mon, 01 Sep 2025 01:38:54 main.py INFO 		Acc is 0.7254, F1-micro is 0.7254
Mon, 01 Sep 2025 01:38:54 main.py INFO 		F1-macro is 0.4204, AUC is 0.5000
Mon, 01 Sep 2025 01:38:54 main.py INFO 		Pre-macro is 0.3627, Rec_macro is 0.5000
Mon, 01 Sep 2025 01:38:54 main.py INFO 		For literal, C_M is 
[[   0 2232]
 [   0 5896]]
Mon, 01 Sep 2025 01:38:54 main.py INFO 		Acc is 0.5081, F1-micro is 0.5081
Mon, 01 Sep 2025 01:38:54 main.py INFO 		F1-macro is 0.3369, AUC is 0.5000
Mon, 01 Sep 2025 01:38:54 main.py INFO 		Pre-macro is 0.2541, Rec_macro is 0.5000
Mon, 01 Sep 2025 01:38:54 main.py INFO 		For deep, C_M is 
[[4130    0]
 [3998    0]]
Mon, 01 Sep 2025 01:38:54 main.py INFO testacc: 0.5260
Mon, 01 Sep 2025 01:39:02 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:39:02 main.py INFO Time of iter training 7.56 s
Mon, 01 Sep 2025 01:39:02 main.py INFO On iter step 1.0:, global step 64 Loss-step [2.5810 1.7664 1.0967 1.3323]
Mon, 01 Sep 2025 01:39:06 main.py INFO In dataset train: Loss is [0.7026 0.4938 0.0001 0.2087]
Mon, 01 Sep 2025 01:39:06 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:39:06 main.py INFO 		F1-macro is 0.8504, AUC is 0.5000
Mon, 01 Sep 2025 01:39:06 main.py INFO 		Pre-macro is 0.8750, Rec_macro is 0.8512
Mon, 01 Sep 2025 01:39:06 main.py INFO 		For sarcasm, C_M is 
[[3634 1340]
 [ 145 4993]]
Mon, 01 Sep 2025 01:39:06 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:39:06 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:39:06 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:39:06 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:39:06 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:39:06 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:39:06 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:39:06 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:39:09 main.py INFO In dataset test: Loss is [0.7193 0.5111 0.0001 0.2081]
Mon, 01 Sep 2025 01:39:09 main.py INFO 		Acc is 0.8434, F1-micro is 0.8434
Mon, 01 Sep 2025 01:39:09 main.py INFO 		F1-macro is 0.8393, AUC is 0.5000
Mon, 01 Sep 2025 01:39:09 main.py INFO 		Pre-macro is 0.8671, Rec_macro is 0.8386
Mon, 01 Sep 2025 01:39:09 main.py INFO 		For sarcasm, C_M is 
[[2781 1131]
 [ 142 4074]]
Mon, 01 Sep 2025 01:39:09 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:39:09 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:39:09 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:39:09 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:39:09 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:39:09 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:39:09 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:39:09 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:39:09 main.py INFO testacc: 0.8434
Mon, 01 Sep 2025 01:39:17 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:39:17 main.py INFO Time of iter training 7.92 s
Mon, 01 Sep 2025 01:39:17 main.py INFO On iter step 2.0:, global step 128 Loss-step [2.0362 1.6424 1.0001 1.2397]
Mon, 01 Sep 2025 01:39:21 main.py INFO In dataset train: Loss is [0.6836 0.4739 0.0000 0.2096]
Mon, 01 Sep 2025 01:39:21 main.py INFO 		Acc is 0.7529, F1-micro is 0.7529
Mon, 01 Sep 2025 01:39:21 main.py INFO 		F1-macro is 0.7346, AUC is 0.5000
Mon, 01 Sep 2025 01:39:21 main.py INFO 		Pre-macro is 0.8355, Rec_macro is 0.7488
Mon, 01 Sep 2025 01:39:21 main.py INFO 		For sarcasm, C_M is 
[[2480 2494]
 [   5 5133]]
Mon, 01 Sep 2025 01:39:21 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:39:21 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:39:21 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:39:21 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:39:21 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:39:21 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:39:21 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:39:21 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:39:24 main.py INFO In dataset test: Loss is [0.6858 0.4767 0.0000 0.2091]
Mon, 01 Sep 2025 01:39:24 main.py INFO 		Acc is 0.7581, F1-micro is 0.7581
Mon, 01 Sep 2025 01:39:24 main.py INFO 		F1-macro is 0.7377, AUC is 0.5000
Mon, 01 Sep 2025 01:39:24 main.py INFO 		Pre-macro is 0.8410, Rec_macro is 0.7487
Mon, 01 Sep 2025 01:39:24 main.py INFO 		For sarcasm, C_M is 
[[1946 1966]
 [   0 4216]]
Mon, 01 Sep 2025 01:39:24 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:39:24 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:39:24 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:39:24 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:39:24 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:39:24 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:39:24 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:39:24 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:39:24 main.py INFO testacc: 0.8434
Mon, 01 Sep 2025 01:39:32 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:39:32 main.py INFO Time of iter training 7.94 s
Mon, 01 Sep 2025 01:39:32 main.py INFO On iter step 3.0:, global step 192 Loss-step [2.0059 1.6247 1.0001 1.2345]
Mon, 01 Sep 2025 01:39:36 main.py INFO In dataset train: Loss is [0.6824 0.4739 0.0000 0.2085]
Mon, 01 Sep 2025 01:39:36 main.py INFO 		Acc is 0.8632, F1-micro is 0.8632
Mon, 01 Sep 2025 01:39:36 main.py INFO 		F1-macro is 0.8600, AUC is 0.5000
Mon, 01 Sep 2025 01:39:36 main.py INFO 		Pre-macro is 0.8939, Rec_macro is 0.8610
Mon, 01 Sep 2025 01:39:36 main.py INFO 		For sarcasm, C_M is 
[[3592 1382]
 [   1 5137]]
Mon, 01 Sep 2025 01:39:36 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:39:36 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:39:36 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:39:36 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:39:36 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:39:36 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:39:36 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:39:36 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:39:39 main.py INFO In dataset test: Loss is [0.6877 0.4798 0.0000 0.2078]
Mon, 01 Sep 2025 01:39:39 main.py INFO 		Acc is 0.8574, F1-micro is 0.8574
Mon, 01 Sep 2025 01:39:39 main.py INFO 		F1-macro is 0.8526, AUC is 0.5000
Mon, 01 Sep 2025 01:39:39 main.py INFO 		Pre-macro is 0.8922, Rec_macro is 0.8519
Mon, 01 Sep 2025 01:39:39 main.py INFO 		For sarcasm, C_M is 
[[2753 1159]
 [   0 4216]]
Mon, 01 Sep 2025 01:39:39 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:39:39 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:39:39 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:39:39 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:39:39 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:39:39 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:39:39 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:39:39 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:39:39 main.py INFO testacc: 0.8574
Mon, 01 Sep 2025 01:39:47 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:39:47 main.py INFO Time of iter training 8.44 s
Mon, 01 Sep 2025 01:39:47 main.py INFO On iter step 4.0:, global step 256 Loss-step [2.0086 1.6123 1.0001 1.2457]
Mon, 01 Sep 2025 01:39:51 main.py INFO In dataset train: Loss is [0.6869 0.4764 0.0000 0.2105]
Mon, 01 Sep 2025 01:39:51 main.py INFO 		Acc is 0.8633, F1-micro is 0.8633
Mon, 01 Sep 2025 01:39:51 main.py INFO 		F1-macro is 0.8601, AUC is 0.5000
Mon, 01 Sep 2025 01:39:51 main.py INFO 		Pre-macro is 0.8938, Rec_macro is 0.8611
Mon, 01 Sep 2025 01:39:51 main.py INFO 		For sarcasm, C_M is 
[[3594 1380]
 [   2 5136]]
Mon, 01 Sep 2025 01:39:51 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:39:51 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:39:51 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:39:51 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:39:51 main.py INFO 		Acc is 0.8453, F1-micro is 0.8453
Mon, 01 Sep 2025 01:39:51 main.py INFO 		F1-macro is 0.8416, AUC is 0.5000
Mon, 01 Sep 2025 01:39:51 main.py INFO 		Pre-macro is 0.8818, Rec_macro is 0.8454
Mon, 01 Sep 2025 01:39:51 main.py INFO 		For deep, C_M is 
[[5053    0]
 [1564 3495]]
Mon, 01 Sep 2025 01:39:55 main.py INFO In dataset test: Loss is [0.6882 0.4785 0.0000 0.2096]
Mon, 01 Sep 2025 01:39:55 main.py INFO 		Acc is 0.8580, F1-micro is 0.8580
Mon, 01 Sep 2025 01:39:55 main.py INFO 		F1-macro is 0.8533, AUC is 0.5000
Mon, 01 Sep 2025 01:39:55 main.py INFO 		Pre-macro is 0.8926, Rec_macro is 0.8525
Mon, 01 Sep 2025 01:39:55 main.py INFO 		For sarcasm, C_M is 
[[2758 1154]
 [   0 4216]]
Mon, 01 Sep 2025 01:39:55 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:39:55 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:39:55 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:39:55 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:39:55 main.py INFO 		Acc is 0.8469, F1-micro is 0.8469
Mon, 01 Sep 2025 01:39:55 main.py INFO 		F1-macro is 0.8424, AUC is 0.5000
Mon, 01 Sep 2025 01:39:55 main.py INFO 		Pre-macro is 0.8843, Rec_macro is 0.8444
Mon, 01 Sep 2025 01:39:55 main.py INFO 		For deep, C_M is 
[[4130    0]
 [1244 2754]]
Mon, 01 Sep 2025 01:39:55 main.py INFO testacc: 0.8580
Mon, 01 Sep 2025 01:40:02 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:40:02 main.py INFO Time of iter training 7.77 s
Mon, 01 Sep 2025 01:40:02 main.py INFO On iter step 5.0:, global step 320 Loss-step [2.0134 1.6244 1.0001 1.2394]
Mon, 01 Sep 2025 01:40:06 main.py INFO In dataset train: Loss is [0.6813 0.4727 0.0001 0.2085]
Mon, 01 Sep 2025 01:40:06 main.py INFO 		Acc is 0.8046, F1-micro is 0.8046
Mon, 01 Sep 2025 01:40:06 main.py INFO 		F1-macro is 0.7954, AUC is 0.5000
Mon, 01 Sep 2025 01:40:06 main.py INFO 		Pre-macro is 0.8610, Rec_macro is 0.8014
Mon, 01 Sep 2025 01:40:06 main.py INFO 		For sarcasm, C_M is 
[[2999 1975]
 [   1 5137]]
Mon, 01 Sep 2025 01:40:06 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:40:06 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:40:06 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:40:06 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:40:06 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:40:06 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:40:06 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:40:06 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:40:09 main.py INFO In dataset test: Loss is [0.6846 0.4767 0.0001 0.2078]
Mon, 01 Sep 2025 01:40:09 main.py INFO 		Acc is 0.8068, F1-micro is 0.8068
Mon, 01 Sep 2025 01:40:09 main.py INFO 		F1-macro is 0.7960, AUC is 0.5000
Mon, 01 Sep 2025 01:40:09 main.py INFO 		Pre-macro is 0.8642, Rec_macro is 0.7993
Mon, 01 Sep 2025 01:40:09 main.py INFO 		For sarcasm, C_M is 
[[2343 1569]
 [   1 4215]]
Mon, 01 Sep 2025 01:40:09 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:40:09 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:40:09 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:40:09 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:40:09 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:40:09 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:40:09 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:40:09 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:40:09 main.py INFO testacc: 0.8580
Mon, 01 Sep 2025 01:40:17 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:40:17 main.py INFO Time of iter training 7.67 s
Mon, 01 Sep 2025 01:40:17 main.py INFO On iter step 6.0:, global step 384 Loss-step [2.0117 1.6149 1.0001 1.2456]
Mon, 01 Sep 2025 01:40:21 main.py INFO In dataset train: Loss is [0.6811 0.4726 0.0000 0.2084]
Mon, 01 Sep 2025 01:40:21 main.py INFO 		Acc is 0.8651, F1-micro is 0.8651
Mon, 01 Sep 2025 01:40:21 main.py INFO 		F1-macro is 0.8620, AUC is 0.5000
Mon, 01 Sep 2025 01:40:21 main.py INFO 		Pre-macro is 0.8949, Rec_macro is 0.8629
Mon, 01 Sep 2025 01:40:21 main.py INFO 		For sarcasm, C_M is 
[[3612 1362]
 [   2 5136]]
Mon, 01 Sep 2025 01:40:21 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:40:21 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:40:21 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:40:21 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:40:21 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:40:21 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:40:21 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:40:21 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:40:23 main.py INFO In dataset test: Loss is [0.6864 0.4785 0.0000 0.2078]
Mon, 01 Sep 2025 01:40:23 main.py INFO 		Acc is 0.8590, F1-micro is 0.8590
Mon, 01 Sep 2025 01:40:23 main.py INFO 		F1-macro is 0.8544, AUC is 0.5000
Mon, 01 Sep 2025 01:40:23 main.py INFO 		Pre-macro is 0.8931, Rec_macro is 0.8535
Mon, 01 Sep 2025 01:40:23 main.py INFO 		For sarcasm, C_M is 
[[2766 1146]
 [   0 4216]]
Mon, 01 Sep 2025 01:40:23 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:40:23 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:40:23 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:40:23 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:40:23 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:40:23 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:40:23 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:40:23 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:40:23 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:40:31 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:40:31 main.py INFO Time of iter training 7.37 s
Mon, 01 Sep 2025 01:40:31 main.py INFO On iter step 7.0:, global step 448 Loss-step [2.0155 1.6245 1.0001 1.2406]
Mon, 01 Sep 2025 01:40:35 main.py INFO In dataset train: Loss is [0.6782 0.4697 0.0000 0.2085]
Mon, 01 Sep 2025 01:40:35 main.py INFO 		Acc is 0.7825, F1-micro is 0.7825
Mon, 01 Sep 2025 01:40:35 main.py INFO 		F1-macro is 0.7700, AUC is 0.5000
Mon, 01 Sep 2025 01:40:35 main.py INFO 		Pre-macro is 0.8497, Rec_macro is 0.7790
Mon, 01 Sep 2025 01:40:35 main.py INFO 		For sarcasm, C_M is 
[[2778 2196]
 [   3 5135]]
Mon, 01 Sep 2025 01:40:35 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:40:35 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:40:35 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:40:35 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:40:35 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:40:35 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:40:35 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:40:35 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:40:38 main.py INFO In dataset test: Loss is [0.6809 0.4731 0.0000 0.2078]
Mon, 01 Sep 2025 01:40:38 main.py INFO 		Acc is 0.7831, F1-micro is 0.7831
Mon, 01 Sep 2025 01:40:38 main.py INFO 		F1-macro is 0.7681, AUC is 0.5000
Mon, 01 Sep 2025 01:40:38 main.py INFO 		Pre-macro is 0.8526, Rec_macro is 0.7747
Mon, 01 Sep 2025 01:40:38 main.py INFO 		For sarcasm, C_M is 
[[2149 1763]
 [   0 4216]]
Mon, 01 Sep 2025 01:40:38 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:40:38 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:40:38 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:40:38 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:40:38 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:40:38 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:40:38 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:40:38 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:40:38 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:40:47 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:40:47 main.py INFO Time of iter training 8.43 s
Mon, 01 Sep 2025 01:40:47 main.py INFO On iter step 8.0:, global step 512 Loss-step [2.0092 1.6354 1.0000 1.2285]
Mon, 01 Sep 2025 01:40:51 main.py INFO In dataset train: Loss is [0.6799 0.4713 0.0001 0.2085]
Mon, 01 Sep 2025 01:40:51 main.py INFO 		Acc is 0.7950, F1-micro is 0.7950
Mon, 01 Sep 2025 01:40:51 main.py INFO 		F1-macro is 0.7848, AUC is 0.5000
Mon, 01 Sep 2025 01:40:51 main.py INFO 		Pre-macro is 0.8540, Rec_macro is 0.7917
Mon, 01 Sep 2025 01:40:51 main.py INFO 		For sarcasm, C_M is 
[[2917 2057]
 [  16 5122]]
Mon, 01 Sep 2025 01:40:51 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:40:51 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:40:51 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:40:51 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:40:51 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:40:51 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:40:51 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:40:51 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:40:54 main.py INFO In dataset test: Loss is [0.6830 0.4752 0.0001 0.2078]
Mon, 01 Sep 2025 01:40:54 main.py INFO 		Acc is 0.7927, F1-micro is 0.7927
Mon, 01 Sep 2025 01:40:54 main.py INFO 		F1-macro is 0.7798, AUC is 0.5000
Mon, 01 Sep 2025 01:40:54 main.py INFO 		Pre-macro is 0.8554, Rec_macro is 0.7847
Mon, 01 Sep 2025 01:40:54 main.py INFO 		For sarcasm, C_M is 
[[2237 1675]
 [  10 4206]]
Mon, 01 Sep 2025 01:40:54 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:40:54 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:40:54 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:40:54 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:40:54 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:40:54 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:40:54 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:40:54 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:40:54 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:41:01 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:41:01 main.py INFO Time of iter training 7.77 s
Mon, 01 Sep 2025 01:41:01 main.py INFO On iter step 9.0:, global step 576 Loss-step [2.0115 1.6320 1.0001 1.2324]
Mon, 01 Sep 2025 01:41:05 main.py INFO In dataset train: Loss is [0.6844 0.4758 0.0000 0.2085]
Mon, 01 Sep 2025 01:41:05 main.py INFO 		Acc is 0.8508, F1-micro is 0.8508
Mon, 01 Sep 2025 01:41:05 main.py INFO 		F1-macro is 0.8466, AUC is 0.5000
Mon, 01 Sep 2025 01:41:05 main.py INFO 		Pre-macro is 0.8863, Rec_macro is 0.8483
Mon, 01 Sep 2025 01:41:05 main.py INFO 		For sarcasm, C_M is 
[[3467 1507]
 [   2 5136]]
Mon, 01 Sep 2025 01:41:05 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:41:05 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:41:05 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:41:05 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:41:05 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:41:05 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:41:05 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:41:05 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:41:08 main.py INFO In dataset test: Loss is [0.6880 0.4802 0.0000 0.2078]
Mon, 01 Sep 2025 01:41:08 main.py INFO 		Acc is 0.8446, F1-micro is 0.8446
Mon, 01 Sep 2025 01:41:08 main.py INFO 		F1-macro is 0.8386, AUC is 0.5000
Mon, 01 Sep 2025 01:41:08 main.py INFO 		Pre-macro is 0.8847, Rec_macro is 0.8386
Mon, 01 Sep 2025 01:41:08 main.py INFO 		For sarcasm, C_M is 
[[2649 1263]
 [   0 4216]]
Mon, 01 Sep 2025 01:41:08 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:41:08 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:41:08 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:41:08 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:41:08 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:41:08 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:41:08 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:41:08 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:41:08 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:41:16 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:41:16 main.py INFO Time of iter training 7.90 s
Mon, 01 Sep 2025 01:41:16 main.py INFO On iter step 10.0:, global step 640 Loss-step [1.9980 1.6137 1.0001 1.2381]
Mon, 01 Sep 2025 01:41:20 main.py INFO In dataset train: Loss is [0.6793 0.4708 0.0001 0.2085]
Mon, 01 Sep 2025 01:41:20 main.py INFO 		Acc is 0.7900, F1-micro is 0.7900
Mon, 01 Sep 2025 01:41:20 main.py INFO 		F1-macro is 0.7788, AUC is 0.5000
Mon, 01 Sep 2025 01:41:20 main.py INFO 		Pre-macro is 0.8526, Rec_macro is 0.7865
Mon, 01 Sep 2025 01:41:20 main.py INFO 		For sarcasm, C_M is 
[[2858 2116]
 [   8 5130]]
Mon, 01 Sep 2025 01:41:20 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:41:20 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:41:20 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:41:20 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:41:20 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:41:20 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:41:20 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:41:20 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:41:23 main.py INFO In dataset test: Loss is [0.6825 0.4747 0.0001 0.2078]
Mon, 01 Sep 2025 01:41:23 main.py INFO 		Acc is 0.7904, F1-micro is 0.7904
Mon, 01 Sep 2025 01:41:23 main.py INFO 		F1-macro is 0.7769, AUC is 0.5000
Mon, 01 Sep 2025 01:41:23 main.py INFO 		Pre-macro is 0.8549, Rec_macro is 0.7823
Mon, 01 Sep 2025 01:41:23 main.py INFO 		For sarcasm, C_M is 
[[2214 1698]
 [   6 4210]]
Mon, 01 Sep 2025 01:41:23 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:41:23 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:41:23 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:41:23 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:41:23 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:41:23 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:41:23 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:41:23 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:41:23 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:41:31 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:41:31 main.py INFO Time of iter training 7.89 s
Mon, 01 Sep 2025 01:41:31 main.py INFO On iter step 11.0:, global step 704 Loss-step [1.9713 1.6009 1.0000 1.2313]
Mon, 01 Sep 2025 01:41:35 main.py INFO In dataset train: Loss is [0.6768 0.4682 0.0000 0.2086]
Mon, 01 Sep 2025 01:41:35 main.py INFO 		Acc is 0.8630, F1-micro is 0.8630
Mon, 01 Sep 2025 01:41:35 main.py INFO 		F1-macro is 0.8599, AUC is 0.5000
Mon, 01 Sep 2025 01:41:35 main.py INFO 		Pre-macro is 0.8918, Rec_macro is 0.8608
Mon, 01 Sep 2025 01:41:35 main.py INFO 		For sarcasm, C_M is 
[[3611 1363]
 [  22 5116]]
Mon, 01 Sep 2025 01:41:35 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:41:35 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:41:35 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:41:35 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:41:35 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:41:35 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:41:35 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:41:35 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:41:38 main.py INFO In dataset test: Loss is [0.6839 0.4759 0.0000 0.2080]
Mon, 01 Sep 2025 01:41:38 main.py INFO 		Acc is 0.8556, F1-micro is 0.8556
Mon, 01 Sep 2025 01:41:38 main.py INFO 		F1-macro is 0.8510, AUC is 0.5000
Mon, 01 Sep 2025 01:41:38 main.py INFO 		Pre-macro is 0.8876, Rec_macro is 0.8502
Mon, 01 Sep 2025 01:41:38 main.py INFO 		For sarcasm, C_M is 
[[2766 1146]
 [  28 4188]]
Mon, 01 Sep 2025 01:41:38 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:41:38 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:41:38 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:41:38 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:41:38 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:41:38 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:41:38 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:41:38 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:41:38 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:41:46 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:41:46 main.py INFO Time of iter training 7.97 s
Mon, 01 Sep 2025 01:41:46 main.py INFO On iter step 12.0:, global step 768 Loss-step [1.9892 1.6094 1.0000 1.2359]
Mon, 01 Sep 2025 01:41:50 main.py INFO In dataset train: Loss is [0.6792 0.4696 0.0000 0.2095]
Mon, 01 Sep 2025 01:41:50 main.py INFO 		Acc is 0.8138, F1-micro is 0.8138
Mon, 01 Sep 2025 01:41:50 main.py INFO 		F1-macro is 0.8067, AUC is 0.5000
Mon, 01 Sep 2025 01:41:50 main.py INFO 		Pre-macro is 0.8588, Rec_macro is 0.8109
Mon, 01 Sep 2025 01:41:50 main.py INFO 		For sarcasm, C_M is 
[[3149 1825]
 [  58 5080]]
Mon, 01 Sep 2025 01:41:50 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:41:50 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:41:50 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:41:50 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:41:50 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:41:50 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:41:50 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:41:50 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:41:53 main.py INFO In dataset test: Loss is [0.6842 0.4751 0.0000 0.2090]
Mon, 01 Sep 2025 01:41:53 main.py INFO 		Acc is 0.8057, F1-micro is 0.8057
Mon, 01 Sep 2025 01:41:53 main.py INFO 		F1-macro is 0.7961, AUC is 0.5000
Mon, 01 Sep 2025 01:41:53 main.py INFO 		Pre-macro is 0.8539, Rec_macro is 0.7987
Mon, 01 Sep 2025 01:41:53 main.py INFO 		For sarcasm, C_M is 
[[2393 1519]
 [  60 4156]]
Mon, 01 Sep 2025 01:41:53 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:41:53 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:41:53 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:41:53 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:41:53 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:41:53 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:41:53 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:41:53 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:41:53 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:42:00 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:42:00 main.py INFO Time of iter training 7.36 s
Mon, 01 Sep 2025 01:42:00 main.py INFO On iter step 13.0:, global step 832 Loss-step [1.9762 1.6015 1.0000 1.2339]
Mon, 01 Sep 2025 01:42:04 main.py INFO In dataset train: Loss is [0.6783 0.4698 0.0000 0.2084]
Mon, 01 Sep 2025 01:42:04 main.py INFO 		Acc is 0.8648, F1-micro is 0.8648
Mon, 01 Sep 2025 01:42:04 main.py INFO 		F1-macro is 0.8617, AUC is 0.5000
Mon, 01 Sep 2025 01:42:04 main.py INFO 		Pre-macro is 0.8946, Rec_macro is 0.8626
Mon, 01 Sep 2025 01:42:04 main.py INFO 		For sarcasm, C_M is 
[[3611 1363]
 [   4 5134]]
Mon, 01 Sep 2025 01:42:04 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:42:04 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:42:04 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:42:04 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:42:04 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:42:04 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:42:04 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:42:04 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:42:07 main.py INFO In dataset test: Loss is [0.6851 0.4773 0.0000 0.2078]
Mon, 01 Sep 2025 01:42:07 main.py INFO 		Acc is 0.8589, F1-micro is 0.8589
Mon, 01 Sep 2025 01:42:07 main.py INFO 		F1-macro is 0.8543, AUC is 0.5000
Mon, 01 Sep 2025 01:42:07 main.py INFO 		Pre-macro is 0.8929, Rec_macro is 0.8534
Mon, 01 Sep 2025 01:42:07 main.py INFO 		For sarcasm, C_M is 
[[2766 1146]
 [   1 4215]]
Mon, 01 Sep 2025 01:42:07 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:42:07 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:42:07 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:42:07 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:42:07 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:42:07 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:42:07 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:42:07 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:42:07 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:42:14 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:42:14 main.py INFO Time of iter training 7.52 s
Mon, 01 Sep 2025 01:42:14 main.py INFO On iter step 14.0:, global step 896 Loss-step [1.9975 1.6041 1.0000 1.2452]
Mon, 01 Sep 2025 01:42:18 main.py INFO In dataset train: Loss is [0.6777 0.4691 0.0001 0.2086]
Mon, 01 Sep 2025 01:42:18 main.py INFO 		Acc is 0.8473, F1-micro is 0.8473
Mon, 01 Sep 2025 01:42:18 main.py INFO 		F1-macro is 0.8429, AUC is 0.5000
Mon, 01 Sep 2025 01:42:18 main.py INFO 		Pre-macro is 0.8840, Rec_macro is 0.8448
Mon, 01 Sep 2025 01:42:18 main.py INFO 		For sarcasm, C_M is 
[[3434 1540]
 [   4 5134]]
Mon, 01 Sep 2025 01:42:18 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:42:18 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:42:18 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:42:18 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:42:18 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:42:18 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:42:18 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:42:18 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:42:21 main.py INFO In dataset test: Loss is [0.6807 0.4728 0.0001 0.2079]
Mon, 01 Sep 2025 01:42:21 main.py INFO 		Acc is 0.8449, F1-micro is 0.8449
Mon, 01 Sep 2025 01:42:21 main.py INFO 		F1-macro is 0.8389, AUC is 0.5000
Mon, 01 Sep 2025 01:42:21 main.py INFO 		Pre-macro is 0.8846, Rec_macro is 0.8388
Mon, 01 Sep 2025 01:42:21 main.py INFO 		For sarcasm, C_M is 
[[2653 1259]
 [   2 4214]]
Mon, 01 Sep 2025 01:42:21 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:42:21 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:42:21 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:42:21 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:42:21 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:42:21 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:42:21 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:42:21 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:42:21 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:42:29 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:42:29 main.py INFO Time of iter training 8.27 s
Mon, 01 Sep 2025 01:42:29 main.py INFO On iter step 15.0:, global step 960 Loss-step [2.0139 1.6240 1.0000 1.2400]
Mon, 01 Sep 2025 01:42:33 main.py INFO In dataset train: Loss is [0.6783 0.4699 0.0000 0.2084]
Mon, 01 Sep 2025 01:42:33 main.py INFO 		Acc is 0.8400, F1-micro is 0.8400
Mon, 01 Sep 2025 01:42:33 main.py INFO 		F1-macro is 0.8350, AUC is 0.5000
Mon, 01 Sep 2025 01:42:33 main.py INFO 		Pre-macro is 0.8791, Rec_macro is 0.8374
Mon, 01 Sep 2025 01:42:33 main.py INFO 		For sarcasm, C_M is 
[[3367 1607]
 [  11 5127]]
Mon, 01 Sep 2025 01:42:33 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:42:33 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:42:33 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:42:33 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:42:33 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:42:33 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:42:33 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:42:33 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:42:36 main.py INFO In dataset test: Loss is [0.6816 0.4738 0.0000 0.2078]
Mon, 01 Sep 2025 01:42:36 main.py INFO 		Acc is 0.8378, F1-micro is 0.8378
Mon, 01 Sep 2025 01:42:36 main.py INFO 		F1-macro is 0.8312, AUC is 0.5000
Mon, 01 Sep 2025 01:42:36 main.py INFO 		Pre-macro is 0.8801, Rec_macro is 0.8316
Mon, 01 Sep 2025 01:42:36 main.py INFO 		For sarcasm, C_M is 
[[2600 1312]
 [   6 4210]]
Mon, 01 Sep 2025 01:42:36 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:42:36 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:42:36 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:42:36 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:42:36 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:42:36 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:42:36 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:42:36 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:42:36 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:42:44 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:42:44 main.py INFO Time of iter training 7.83 s
Mon, 01 Sep 2025 01:42:44 main.py INFO On iter step 16.0:, global step 1024 Loss-step [2.0148 1.6162 1.0000 1.2466]
Mon, 01 Sep 2025 01:42:48 main.py INFO In dataset train: Loss is [0.6802 0.4718 0.0000 0.2084]
Mon, 01 Sep 2025 01:42:48 main.py INFO 		Acc is 0.8631, F1-micro is 0.8631
Mon, 01 Sep 2025 01:42:48 main.py INFO 		F1-macro is 0.8599, AUC is 0.5000
Mon, 01 Sep 2025 01:42:48 main.py INFO 		Pre-macro is 0.8933, Rec_macro is 0.8609
Mon, 01 Sep 2025 01:42:48 main.py INFO 		For sarcasm, C_M is 
[[3596 1378]
 [   6 5132]]
Mon, 01 Sep 2025 01:42:48 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:42:48 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:42:48 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:42:48 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:42:48 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:42:48 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:42:48 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:42:48 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:42:51 main.py INFO In dataset test: Loss is [0.6855 0.4777 0.0000 0.2078]
Mon, 01 Sep 2025 01:42:51 main.py INFO 		Acc is 0.8565, F1-micro is 0.8565
Mon, 01 Sep 2025 01:42:51 main.py INFO 		F1-macro is 0.8517, AUC is 0.5000
Mon, 01 Sep 2025 01:42:51 main.py INFO 		Pre-macro is 0.8913, Rec_macro is 0.8510
Mon, 01 Sep 2025 01:42:51 main.py INFO 		For sarcasm, C_M is 
[[2749 1163]
 [   3 4213]]
Mon, 01 Sep 2025 01:42:51 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:42:51 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:42:51 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:42:51 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:42:51 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:42:51 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:42:51 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:42:51 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:42:51 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:43:00 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:43:00 main.py INFO Time of iter training 8.73 s
Mon, 01 Sep 2025 01:43:00 main.py INFO On iter step 17.0:, global step 1088 Loss-step [2.0076 1.6255 1.0001 1.2349]
Mon, 01 Sep 2025 01:43:04 main.py INFO In dataset train: Loss is [0.6786 0.4702 0.0000 0.2084]
Mon, 01 Sep 2025 01:43:04 main.py INFO 		Acc is 0.8123, F1-micro is 0.8123
Mon, 01 Sep 2025 01:43:04 main.py INFO 		F1-macro is 0.8048, AUC is 0.5000
Mon, 01 Sep 2025 01:43:04 main.py INFO 		Pre-macro is 0.8605, Rec_macro is 0.8093
Mon, 01 Sep 2025 01:43:04 main.py INFO 		For sarcasm, C_M is 
[[3113 1861]
 [  37 5101]]
Mon, 01 Sep 2025 01:43:04 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:43:04 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:43:04 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:43:04 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:43:04 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:43:04 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:43:04 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:43:04 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:43:07 main.py INFO In dataset test: Loss is [0.6826 0.4748 0.0000 0.2078]
Mon, 01 Sep 2025 01:43:07 main.py INFO 		Acc is 0.8115, F1-micro is 0.8115
Mon, 01 Sep 2025 01:43:07 main.py INFO 		F1-macro is 0.8017, AUC is 0.5000
Mon, 01 Sep 2025 01:43:07 main.py INFO 		Pre-macro is 0.8646, Rec_macro is 0.8043
Mon, 01 Sep 2025 01:43:07 main.py INFO 		For sarcasm, C_M is 
[[2393 1519]
 [  13 4203]]
Mon, 01 Sep 2025 01:43:07 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:43:07 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:43:07 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:43:07 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:43:07 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:43:07 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:43:07 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:43:07 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:43:07 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:43:15 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:43:15 main.py INFO Time of iter training 7.70 s
Mon, 01 Sep 2025 01:43:15 main.py INFO On iter step 18.0:, global step 1152 Loss-step [2.0122 1.6386 1.0000 1.2280]
Mon, 01 Sep 2025 01:43:18 main.py INFO In dataset train: Loss is [0.6795 0.4710 0.0000 0.2085]
Mon, 01 Sep 2025 01:43:18 main.py INFO 		Acc is 0.7541, F1-micro is 0.7541
Mon, 01 Sep 2025 01:43:18 main.py INFO 		F1-macro is 0.7362, AUC is 0.5000
Mon, 01 Sep 2025 01:43:18 main.py INFO 		Pre-macro is 0.8353, Rec_macro is 0.7500
Mon, 01 Sep 2025 01:43:18 main.py INFO 		For sarcasm, C_M is 
[[2496 2478]
 [   9 5129]]
Mon, 01 Sep 2025 01:43:18 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:43:18 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:43:18 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:43:18 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:43:18 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:43:18 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:43:18 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:43:18 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:43:22 main.py INFO In dataset test: Loss is [0.6826 0.4748 0.0000 0.2078]
Mon, 01 Sep 2025 01:43:22 main.py INFO 		Acc is 0.7587, F1-micro is 0.7587
Mon, 01 Sep 2025 01:43:22 main.py INFO 		F1-macro is 0.7390, AUC is 0.5000
Mon, 01 Sep 2025 01:43:22 main.py INFO 		Pre-macro is 0.8381, Rec_macro is 0.7495
Mon, 01 Sep 2025 01:43:22 main.py INFO 		For sarcasm, C_M is 
[[1965 1947]
 [  14 4202]]
Mon, 01 Sep 2025 01:43:22 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:43:22 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:43:22 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:43:22 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:43:22 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:43:22 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:43:22 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:43:22 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:43:22 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:43:30 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:43:30 main.py INFO Time of iter training 8.46 s
Mon, 01 Sep 2025 01:43:30 main.py INFO On iter step 19.0:, global step 1216 Loss-step [1.9945 1.6167 1.0000 1.2337]
Mon, 01 Sep 2025 01:43:34 main.py INFO In dataset train: Loss is [0.6783 0.4698 0.0000 0.2085]
Mon, 01 Sep 2025 01:43:34 main.py INFO 		Acc is 0.7560, F1-micro is 0.7560
Mon, 01 Sep 2025 01:43:34 main.py INFO 		F1-macro is 0.7383, AUC is 0.5000
Mon, 01 Sep 2025 01:43:34 main.py INFO 		Pre-macro is 0.8376, Rec_macro is 0.7520
Mon, 01 Sep 2025 01:43:34 main.py INFO 		For sarcasm, C_M is 
[[2508 2466]
 [   1 5137]]
Mon, 01 Sep 2025 01:43:34 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:43:34 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:43:34 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:43:34 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:43:34 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:43:34 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:43:34 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:43:34 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:43:37 main.py INFO In dataset test: Loss is [0.6804 0.4725 0.0000 0.2078]
Mon, 01 Sep 2025 01:43:37 main.py INFO 		Acc is 0.7609, F1-micro is 0.7609
Mon, 01 Sep 2025 01:43:37 main.py INFO 		F1-macro is 0.7412, AUC is 0.5000
Mon, 01 Sep 2025 01:43:37 main.py INFO 		Pre-macro is 0.8423, Rec_macro is 0.7517
Mon, 01 Sep 2025 01:43:37 main.py INFO 		For sarcasm, C_M is 
[[1969 1943]
 [   0 4216]]
Mon, 01 Sep 2025 01:43:37 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:43:37 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:43:37 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:43:37 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:43:37 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:43:37 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:43:37 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:43:37 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:43:37 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:43:44 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:43:44 main.py INFO Time of iter training 7.58 s
Mon, 01 Sep 2025 01:43:44 main.py INFO On iter step 20.0:, global step 1280 Loss-step [1.9822 1.6022 1.0000 1.2372]
Mon, 01 Sep 2025 01:43:48 main.py INFO In dataset train: Loss is [0.6781 0.4696 0.0000 0.2084]
Mon, 01 Sep 2025 01:43:48 main.py INFO 		Acc is 0.8087, F1-micro is 0.8087
Mon, 01 Sep 2025 01:43:48 main.py INFO 		F1-macro is 0.8004, AUC is 0.5000
Mon, 01 Sep 2025 01:43:48 main.py INFO 		Pre-macro is 0.8610, Rec_macro is 0.8056
Mon, 01 Sep 2025 01:43:48 main.py INFO 		For sarcasm, C_M is 
[[3057 1917]
 [  17 5121]]
Mon, 01 Sep 2025 01:43:48 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:43:48 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:43:48 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:43:48 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:43:48 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:43:48 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:43:48 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:43:48 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:43:51 main.py INFO In dataset test: Loss is [0.6819 0.4741 0.0000 0.2078]
Mon, 01 Sep 2025 01:43:51 main.py INFO 		Acc is 0.8066, F1-micro is 0.8066
Mon, 01 Sep 2025 01:43:51 main.py INFO 		F1-macro is 0.7959, AUC is 0.5000
Mon, 01 Sep 2025 01:43:51 main.py INFO 		Pre-macro is 0.8626, Rec_macro is 0.7992
Mon, 01 Sep 2025 01:43:51 main.py INFO 		For sarcasm, C_M is 
[[2349 1563]
 [   9 4207]]
Mon, 01 Sep 2025 01:43:51 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:43:51 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:43:51 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:43:51 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:43:51 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:43:51 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:43:51 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:43:51 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:43:51 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:43:59 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:43:59 main.py INFO Time of iter training 7.63 s
Mon, 01 Sep 2025 01:43:59 main.py INFO On iter step 21.0:, global step 1344 Loss-step [1.9743 1.6035 1.0000 1.2312]
Mon, 01 Sep 2025 01:44:02 main.py INFO In dataset train: Loss is [0.6757 0.4672 0.0000 0.2084]
Mon, 01 Sep 2025 01:44:02 main.py INFO 		Acc is 0.8573, F1-micro is 0.8573
Mon, 01 Sep 2025 01:44:02 main.py INFO 		F1-macro is 0.8536, AUC is 0.5000
Mon, 01 Sep 2025 01:44:02 main.py INFO 		Pre-macro is 0.8900, Rec_macro is 0.8550
Mon, 01 Sep 2025 01:44:02 main.py INFO 		For sarcasm, C_M is 
[[3535 1439]
 [   4 5134]]
Mon, 01 Sep 2025 01:44:02 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:44:02 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:44:02 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:44:02 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:44:02 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:44:02 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:44:02 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:44:02 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:44:05 main.py INFO In dataset test: Loss is [0.6836 0.4758 0.0000 0.2078]
Mon, 01 Sep 2025 01:44:05 main.py INFO 		Acc is 0.8510, F1-micro is 0.8510
Mon, 01 Sep 2025 01:44:05 main.py INFO 		F1-macro is 0.8457, AUC is 0.5000
Mon, 01 Sep 2025 01:44:05 main.py INFO 		Pre-macro is 0.8883, Rec_macro is 0.8452
Mon, 01 Sep 2025 01:44:05 main.py INFO 		For sarcasm, C_M is 
[[2702 1210]
 [   1 4215]]
Mon, 01 Sep 2025 01:44:05 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:44:05 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:44:05 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:44:05 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:44:05 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:44:05 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:44:05 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:44:05 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:44:05 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:44:12 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:44:12 main.py INFO Time of iter training 6.95 s
Mon, 01 Sep 2025 01:44:12 main.py INFO On iter step 22.0:, global step 1408 Loss-step [1.9897 1.6114 1.0000 1.2348]
Mon, 01 Sep 2025 01:44:16 main.py INFO In dataset train: Loss is [0.6761 0.4675 0.0000 0.2086]
Mon, 01 Sep 2025 01:44:16 main.py INFO 		Acc is 0.8414, F1-micro is 0.8414
Mon, 01 Sep 2025 01:44:16 main.py INFO 		F1-macro is 0.8369, AUC is 0.5000
Mon, 01 Sep 2025 01:44:16 main.py INFO 		Pre-macro is 0.8765, Rec_macro is 0.8389
Mon, 01 Sep 2025 01:44:16 main.py INFO 		For sarcasm, C_M is 
[[3413 1561]
 [  43 5095]]
Mon, 01 Sep 2025 01:44:16 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:44:16 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:44:16 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:44:16 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:44:16 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:44:16 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:44:16 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:44:16 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:44:19 main.py INFO In dataset test: Loss is [0.6816 0.4736 0.0000 0.2080]
Mon, 01 Sep 2025 01:44:19 main.py INFO 		Acc is 0.8362, F1-micro is 0.8362
Mon, 01 Sep 2025 01:44:19 main.py INFO 		F1-macro is 0.8299, AUC is 0.5000
Mon, 01 Sep 2025 01:44:19 main.py INFO 		Pre-macro is 0.8752, Rec_macro is 0.8302
Mon, 01 Sep 2025 01:44:19 main.py INFO 		For sarcasm, C_M is 
[[2615 1297]
 [  34 4182]]
Mon, 01 Sep 2025 01:44:19 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:44:19 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:44:19 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:44:19 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:44:19 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:44:19 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:44:19 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:44:19 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:44:19 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:44:26 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:44:26 main.py INFO Time of iter training 7.13 s
Mon, 01 Sep 2025 01:44:26 main.py INFO On iter step 23.0:, global step 1472 Loss-step [1.9798 1.5998 1.0000 1.2375]
Mon, 01 Sep 2025 01:44:30 main.py INFO In dataset train: Loss is [0.6806 0.4721 0.0000 0.2084]
Mon, 01 Sep 2025 01:44:30 main.py INFO 		Acc is 0.8616, F1-micro is 0.8616
Mon, 01 Sep 2025 01:44:30 main.py INFO 		F1-macro is 0.8583, AUC is 0.5000
Mon, 01 Sep 2025 01:44:30 main.py INFO 		Pre-macro is 0.8919, Rec_macro is 0.8593
Mon, 01 Sep 2025 01:44:30 main.py INFO 		For sarcasm, C_M is 
[[3585 1389]
 [  11 5127]]
Mon, 01 Sep 2025 01:44:30 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:44:30 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:44:30 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:44:30 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:44:30 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:44:30 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:44:30 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:44:30 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:44:33 main.py INFO In dataset test: Loss is [0.6873 0.4796 0.0000 0.2077]
Mon, 01 Sep 2025 01:44:33 main.py INFO 		Acc is 0.8552, F1-micro is 0.8552
Mon, 01 Sep 2025 01:44:33 main.py INFO 		F1-macro is 0.8503, AUC is 0.5000
Mon, 01 Sep 2025 01:44:33 main.py INFO 		Pre-macro is 0.8902, Rec_macro is 0.8496
Mon, 01 Sep 2025 01:44:33 main.py INFO 		For sarcasm, C_M is 
[[2740 1172]
 [   5 4211]]
Mon, 01 Sep 2025 01:44:33 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:44:33 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:44:33 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:44:33 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:44:33 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:44:33 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:44:33 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:44:33 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:44:33 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:44:41 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:44:41 main.py INFO Time of iter training 8.46 s
Mon, 01 Sep 2025 01:44:41 main.py INFO On iter step 24.0:, global step 1536 Loss-step [1.9928 1.6040 1.0000 1.2423]
Mon, 01 Sep 2025 01:44:46 main.py INFO In dataset train: Loss is [0.6770 0.4685 0.0000 0.2084]
Mon, 01 Sep 2025 01:44:46 main.py INFO 		Acc is 0.8285, F1-micro is 0.8285
Mon, 01 Sep 2025 01:44:46 main.py INFO 		F1-macro is 0.8224, AUC is 0.5000
Mon, 01 Sep 2025 01:44:46 main.py INFO 		Pre-macro is 0.8724, Rec_macro is 0.8257
Mon, 01 Sep 2025 01:44:46 main.py INFO 		For sarcasm, C_M is 
[[3252 1722]
 [  12 5126]]
Mon, 01 Sep 2025 01:44:46 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:44:46 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:44:46 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:44:46 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:44:46 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:44:46 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:44:46 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:44:46 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:44:49 main.py INFO In dataset test: Loss is [0.6808 0.4730 0.0000 0.2077]
Mon, 01 Sep 2025 01:44:49 main.py INFO 		Acc is 0.8260, F1-micro is 0.8260
Mon, 01 Sep 2025 01:44:49 main.py INFO 		F1-macro is 0.8180, AUC is 0.5000
Mon, 01 Sep 2025 01:44:49 main.py INFO 		Pre-macro is 0.8735, Rec_macro is 0.8193
Mon, 01 Sep 2025 01:44:49 main.py INFO 		For sarcasm, C_M is 
[[2504 1408]
 [   6 4210]]
Mon, 01 Sep 2025 01:44:49 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:44:49 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:44:49 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:44:49 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:44:49 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:44:49 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:44:49 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:44:49 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:44:49 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:44:57 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:44:57 main.py INFO Time of iter training 7.75 s
Mon, 01 Sep 2025 01:44:57 main.py INFO On iter step 25.0:, global step 1600 Loss-step [2.0141 1.6255 1.0000 1.2390]
Mon, 01 Sep 2025 01:45:01 main.py INFO In dataset train: Loss is [0.6831 0.4746 0.0001 0.2084]
Mon, 01 Sep 2025 01:45:01 main.py INFO 		Acc is 0.8356, F1-micro is 0.8356
Mon, 01 Sep 2025 01:45:01 main.py INFO 		F1-macro is 0.8309, AUC is 0.5000
Mon, 01 Sep 2025 01:45:01 main.py INFO 		Pre-macro is 0.8710, Rec_macro is 0.8331
Mon, 01 Sep 2025 01:45:01 main.py INFO 		For sarcasm, C_M is 
[[3375 1599]
 [  63 5075]]
Mon, 01 Sep 2025 01:45:01 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:45:01 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:45:01 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:45:01 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:45:01 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:45:01 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:45:01 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:45:01 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:45:04 main.py INFO In dataset test: Loss is [0.6860 0.4781 0.0001 0.2078]
Mon, 01 Sep 2025 01:45:04 main.py INFO 		Acc is 0.8313, F1-micro is 0.8313
Mon, 01 Sep 2025 01:45:04 main.py INFO 		F1-macro is 0.8249, AUC is 0.5000
Mon, 01 Sep 2025 01:45:04 main.py INFO 		Pre-macro is 0.8687, Rec_macro is 0.8253
Mon, 01 Sep 2025 01:45:04 main.py INFO 		For sarcasm, C_M is 
[[2602 1310]
 [  61 4155]]
Mon, 01 Sep 2025 01:45:04 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:45:04 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:45:04 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:45:04 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:45:04 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:45:04 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:45:04 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:45:04 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:45:04 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:45:11 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:45:11 main.py INFO Time of iter training 7.24 s
Mon, 01 Sep 2025 01:45:11 main.py INFO On iter step 26.0:, global step 1664 Loss-step [2.0100 1.6110 1.0000 1.2476]
Mon, 01 Sep 2025 01:45:15 main.py INFO In dataset train: Loss is [0.6773 0.4689 0.0000 0.2084]
Mon, 01 Sep 2025 01:45:15 main.py INFO 		Acc is 0.8624, F1-micro is 0.8624
Mon, 01 Sep 2025 01:45:15 main.py INFO 		F1-macro is 0.8592, AUC is 0.5000
Mon, 01 Sep 2025 01:45:15 main.py INFO 		Pre-macro is 0.8930, Rec_macro is 0.8602
Mon, 01 Sep 2025 01:45:15 main.py INFO 		For sarcasm, C_M is 
[[3588 1386]
 [   5 5133]]
Mon, 01 Sep 2025 01:45:15 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:45:15 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:45:15 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:45:15 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:45:15 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:45:15 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:45:15 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:45:15 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:45:18 main.py INFO In dataset test: Loss is [0.6812 0.4734 0.0000 0.2077]
Mon, 01 Sep 2025 01:45:18 main.py INFO 		Acc is 0.8573, F1-micro is 0.8573
Mon, 01 Sep 2025 01:45:18 main.py INFO 		F1-macro is 0.8525, AUC is 0.5000
Mon, 01 Sep 2025 01:45:18 main.py INFO 		Pre-macro is 0.8920, Rec_macro is 0.8517
Mon, 01 Sep 2025 01:45:18 main.py INFO 		For sarcasm, C_M is 
[[2753 1159]
 [   1 4215]]
Mon, 01 Sep 2025 01:45:18 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:45:18 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:45:18 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:45:18 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:45:18 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:45:18 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:45:18 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:45:18 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:45:18 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:45:26 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:45:26 main.py INFO Time of iter training 7.87 s
Mon, 01 Sep 2025 01:45:26 main.py INFO On iter step 27.0:, global step 1728 Loss-step [1.9950 1.6155 1.0000 1.2349]
Mon, 01 Sep 2025 01:45:30 main.py INFO In dataset train: Loss is [0.6777 0.4692 0.0000 0.2084]
Mon, 01 Sep 2025 01:45:30 main.py INFO 		Acc is 0.7863, F1-micro is 0.7863
Mon, 01 Sep 2025 01:45:30 main.py INFO 		F1-macro is 0.7748, AUC is 0.5000
Mon, 01 Sep 2025 01:45:30 main.py INFO 		Pre-macro is 0.8489, Rec_macro is 0.7828
Mon, 01 Sep 2025 01:45:30 main.py INFO 		For sarcasm, C_M is 
[[2834 2140]
 [  21 5117]]
Mon, 01 Sep 2025 01:45:30 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:45:30 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:45:30 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:45:30 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:45:30 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:45:30 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:45:30 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:45:30 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:45:33 main.py INFO In dataset test: Loss is [0.6805 0.4728 0.0000 0.2077]
Mon, 01 Sep 2025 01:45:33 main.py INFO 		Acc is 0.7873, F1-micro is 0.7873
Mon, 01 Sep 2025 01:45:33 main.py INFO 		F1-macro is 0.7737, AUC is 0.5000
Mon, 01 Sep 2025 01:45:33 main.py INFO 		Pre-macro is 0.8508, Rec_macro is 0.7792
Mon, 01 Sep 2025 01:45:33 main.py INFO 		For sarcasm, C_M is 
[[2203 1709]
 [  20 4196]]
Mon, 01 Sep 2025 01:45:33 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:45:33 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:45:33 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:45:33 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:45:33 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:45:33 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:45:33 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:45:33 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:45:33 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:45:40 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:45:40 main.py INFO Time of iter training 7.72 s
Mon, 01 Sep 2025 01:45:40 main.py INFO On iter step 28.0:, global step 1792 Loss-step [2.0024 1.6311 1.0000 1.2277]
Mon, 01 Sep 2025 01:45:44 main.py INFO In dataset train: Loss is [0.6803 0.4719 0.0000 0.2084]
Mon, 01 Sep 2025 01:45:44 main.py INFO 		Acc is 0.7582, F1-micro is 0.7582
Mon, 01 Sep 2025 01:45:44 main.py INFO 		F1-macro is 0.7419, AUC is 0.5000
Mon, 01 Sep 2025 01:45:44 main.py INFO 		Pre-macro is 0.8332, Rec_macro is 0.7543
Mon, 01 Sep 2025 01:45:44 main.py INFO 		For sarcasm, C_M is 
[[2562 2412]
 [  33 5105]]
Mon, 01 Sep 2025 01:45:44 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:45:44 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:45:44 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:45:44 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:45:44 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:45:44 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:45:44 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:45:44 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:45:47 main.py INFO In dataset test: Loss is [0.6839 0.4762 0.0000 0.2077]
Mon, 01 Sep 2025 01:45:47 main.py INFO 		Acc is 0.7608, F1-micro is 0.7608
Mon, 01 Sep 2025 01:45:47 main.py INFO 		F1-macro is 0.7420, AUC is 0.5000
Mon, 01 Sep 2025 01:45:47 main.py INFO 		Pre-macro is 0.8366, Rec_macro is 0.7518
Mon, 01 Sep 2025 01:45:47 main.py INFO 		For sarcasm, C_M is 
[[1994 1918]
 [  26 4190]]
Mon, 01 Sep 2025 01:45:47 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:45:47 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:45:47 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:45:47 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:45:47 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:45:47 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:45:47 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:45:47 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:45:47 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:45:55 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:45:55 main.py INFO Time of iter training 8.11 s
Mon, 01 Sep 2025 01:45:55 main.py INFO On iter step 29.0:, global step 1856 Loss-step [1.9948 1.6150 1.0000 1.2352]
Mon, 01 Sep 2025 01:45:59 main.py INFO In dataset train: Loss is [0.6784 0.4699 0.0000 0.2085]
Mon, 01 Sep 2025 01:45:59 main.py INFO 		Acc is 0.7567, F1-micro is 0.7567
Mon, 01 Sep 2025 01:45:59 main.py INFO 		F1-macro is 0.7392, AUC is 0.5000
Mon, 01 Sep 2025 01:45:59 main.py INFO 		Pre-macro is 0.8379, Rec_macro is 0.7527
Mon, 01 Sep 2025 01:45:59 main.py INFO 		For sarcasm, C_M is 
[[2515 2459]
 [   1 5137]]
Mon, 01 Sep 2025 01:45:59 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:45:59 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:45:59 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:45:59 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:45:59 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:45:59 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:45:59 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:45:59 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:46:02 main.py INFO In dataset test: Loss is [0.6809 0.4731 0.0000 0.2078]
Mon, 01 Sep 2025 01:46:02 main.py INFO 		Acc is 0.7622, F1-micro is 0.7622
Mon, 01 Sep 2025 01:46:02 main.py INFO 		F1-macro is 0.7427, AUC is 0.5000
Mon, 01 Sep 2025 01:46:02 main.py INFO 		Pre-macro is 0.8428, Rec_macro is 0.7529
Mon, 01 Sep 2025 01:46:02 main.py INFO 		For sarcasm, C_M is 
[[1979 1933]
 [   0 4216]]
Mon, 01 Sep 2025 01:46:02 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:46:02 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:46:02 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:46:02 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:46:02 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:46:02 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:46:02 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:46:02 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:46:02 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:46:10 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:46:10 main.py INFO Time of iter training 7.51 s
Mon, 01 Sep 2025 01:46:10 main.py INFO On iter step 30.0:, global step 1920 Loss-step [1.9757 1.5989 1.0000 1.2357]
Mon, 01 Sep 2025 01:46:13 main.py INFO In dataset train: Loss is [0.6760 0.4676 0.0000 0.2084]
Mon, 01 Sep 2025 01:46:13 main.py INFO 		Acc is 0.7859, F1-micro is 0.7859
Mon, 01 Sep 2025 01:46:13 main.py INFO 		F1-macro is 0.7744, AUC is 0.5000
Mon, 01 Sep 2025 01:46:13 main.py INFO 		Pre-macro is 0.8481, Rec_macro is 0.7824
Mon, 01 Sep 2025 01:46:13 main.py INFO 		For sarcasm, C_M is 
[[2834 2140]
 [  25 5113]]
Mon, 01 Sep 2025 01:46:13 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:46:13 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:46:13 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:46:13 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:46:13 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:46:13 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:46:13 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:46:13 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:46:16 main.py INFO In dataset test: Loss is [0.6805 0.4727 0.0000 0.2078]
Mon, 01 Sep 2025 01:46:16 main.py INFO 		Acc is 0.7862, F1-micro is 0.7862
Mon, 01 Sep 2025 01:46:16 main.py INFO 		F1-macro is 0.7723, AUC is 0.5000
Mon, 01 Sep 2025 01:46:16 main.py INFO 		Pre-macro is 0.8506, Rec_macro is 0.7780
Mon, 01 Sep 2025 01:46:16 main.py INFO 		For sarcasm, C_M is 
[[2192 1720]
 [  18 4198]]
Mon, 01 Sep 2025 01:46:16 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:46:16 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:46:16 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:46:16 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:46:16 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:46:16 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:46:16 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:46:16 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:46:16 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:46:24 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:46:24 main.py INFO Time of iter training 8.12 s
Mon, 01 Sep 2025 01:46:24 main.py INFO On iter step 31.0:, global step 1984 Loss-step [1.9707 1.6008 1.0000 1.2311]
Mon, 01 Sep 2025 01:46:28 main.py INFO In dataset train: Loss is [0.6749 0.4664 0.0000 0.2084]
Mon, 01 Sep 2025 01:46:28 main.py INFO 		Acc is 0.8585, F1-micro is 0.8585
Mon, 01 Sep 2025 01:46:28 main.py INFO 		F1-macro is 0.8550, AUC is 0.5000
Mon, 01 Sep 2025 01:46:28 main.py INFO 		Pre-macro is 0.8902, Rec_macro is 0.8562
Mon, 01 Sep 2025 01:46:28 main.py INFO 		For sarcasm, C_M is 
[[3552 1422]
 [   9 5129]]
Mon, 01 Sep 2025 01:46:28 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:46:28 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:46:28 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:46:28 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:46:28 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:46:28 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:46:28 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:46:28 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:46:31 main.py INFO In dataset test: Loss is [0.6853 0.4775 0.0000 0.2078]
Mon, 01 Sep 2025 01:46:31 main.py INFO 		Acc is 0.8498, F1-micro is 0.8498
Mon, 01 Sep 2025 01:46:31 main.py INFO 		F1-macro is 0.8445, AUC is 0.5000
Mon, 01 Sep 2025 01:46:31 main.py INFO 		Pre-macro is 0.8862, Rec_macro is 0.8440
Mon, 01 Sep 2025 01:46:31 main.py INFO 		For sarcasm, C_M is 
[[2702 1210]
 [  11 4205]]
Mon, 01 Sep 2025 01:46:31 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:46:31 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:46:31 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:46:31 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:46:31 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:46:31 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:46:31 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:46:31 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:46:31 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:46:38 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:46:38 main.py INFO Time of iter training 7.37 s
Mon, 01 Sep 2025 01:46:38 main.py INFO On iter step 32.0:, global step 2048 Loss-step [1.9936 1.6133 1.0000 1.2357]
Mon, 01 Sep 2025 01:46:42 main.py INFO In dataset train: Loss is [0.6773 0.4688 0.0000 0.2085]
Mon, 01 Sep 2025 01:46:42 main.py INFO 		Acc is 0.8371, F1-micro is 0.8371
Mon, 01 Sep 2025 01:46:42 main.py INFO 		F1-macro is 0.8345, AUC is 0.5000
Mon, 01 Sep 2025 01:46:42 main.py INFO 		Pre-macro is 0.8547, Rec_macro is 0.8353
Mon, 01 Sep 2025 01:46:42 main.py INFO 		For sarcasm, C_M is 
[[3599 1375]
 [ 272 4866]]
Mon, 01 Sep 2025 01:46:42 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:46:42 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:46:42 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:46:42 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:46:42 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:46:42 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:46:42 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:46:42 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:46:45 main.py INFO In dataset test: Loss is [0.6849 0.4770 0.0000 0.2079]
Mon, 01 Sep 2025 01:46:45 main.py INFO 		Acc is 0.8305, F1-micro is 0.8305
Mon, 01 Sep 2025 01:46:45 main.py INFO 		F1-macro is 0.8263, AUC is 0.5000
Mon, 01 Sep 2025 01:46:45 main.py INFO 		Pre-macro is 0.8511, Rec_macro is 0.8259
Mon, 01 Sep 2025 01:46:45 main.py INFO 		For sarcasm, C_M is 
[[2749 1163]
 [ 215 4001]]
Mon, 01 Sep 2025 01:46:45 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:46:45 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:46:45 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:46:45 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:46:45 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:46:45 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:46:45 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:46:45 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:46:45 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:46:53 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:46:53 main.py INFO Time of iter training 7.40 s
Mon, 01 Sep 2025 01:46:53 main.py INFO On iter step 33.0:, global step 2112 Loss-step [1.9691 1.5921 1.0001 1.2367]
Mon, 01 Sep 2025 01:46:56 main.py INFO In dataset train: Loss is [0.6806 0.4721 0.0000 0.2084]
Mon, 01 Sep 2025 01:46:56 main.py INFO 		Acc is 0.8397, F1-micro is 0.8397
Mon, 01 Sep 2025 01:46:56 main.py INFO 		F1-macro is 0.8354, AUC is 0.5000
Mon, 01 Sep 2025 01:46:56 main.py INFO 		Pre-macro is 0.8721, Rec_macro is 0.8373
Mon, 01 Sep 2025 01:46:56 main.py INFO 		For sarcasm, C_M is 
[[3430 1544]
 [  77 5061]]
Mon, 01 Sep 2025 01:46:56 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:46:56 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:46:56 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:46:56 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:46:56 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:46:56 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:46:56 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:46:56 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:46:59 main.py INFO In dataset test: Loss is [0.6885 0.4808 0.0000 0.2077]
Mon, 01 Sep 2025 01:46:59 main.py INFO 		Acc is 0.8346, F1-micro is 0.8346
Mon, 01 Sep 2025 01:46:59 main.py INFO 		F1-macro is 0.8286, AUC is 0.5000
Mon, 01 Sep 2025 01:46:59 main.py INFO 		Pre-macro is 0.8708, Rec_macro is 0.8288
Mon, 01 Sep 2025 01:46:59 main.py INFO 		For sarcasm, C_M is 
[[2628 1284]
 [  60 4156]]
Mon, 01 Sep 2025 01:46:59 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:46:59 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:46:59 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:46:59 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:46:59 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:46:59 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:46:59 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:46:59 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:46:59 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:47:06 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:47:06 main.py INFO Time of iter training 7.01 s
Mon, 01 Sep 2025 01:47:06 main.py INFO On iter step 34.0:, global step 2176 Loss-step [1.9935 1.6052 1.0000 1.2418]
Mon, 01 Sep 2025 01:47:10 main.py INFO In dataset train: Loss is [0.6770 0.4686 0.0000 0.2084]
Mon, 01 Sep 2025 01:47:10 main.py INFO 		Acc is 0.8438, F1-micro is 0.8438
Mon, 01 Sep 2025 01:47:10 main.py INFO 		F1-macro is 0.8392, AUC is 0.5000
Mon, 01 Sep 2025 01:47:10 main.py INFO 		Pre-macro is 0.8816, Rec_macro is 0.8413
Mon, 01 Sep 2025 01:47:10 main.py INFO 		For sarcasm, C_M is 
[[3403 1571]
 [   8 5130]]
Mon, 01 Sep 2025 01:47:10 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:47:10 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:47:10 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:47:10 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:47:10 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:47:10 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:47:10 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:47:10 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:47:13 main.py INFO In dataset test: Loss is [0.6812 0.4735 0.0000 0.2077]
Mon, 01 Sep 2025 01:47:13 main.py INFO 		Acc is 0.8408, F1-micro is 0.8408
Mon, 01 Sep 2025 01:47:13 main.py INFO 		F1-macro is 0.8345, AUC is 0.5000
Mon, 01 Sep 2025 01:47:13 main.py INFO 		Pre-macro is 0.8819, Rec_macro is 0.8347
Mon, 01 Sep 2025 01:47:13 main.py INFO 		For sarcasm, C_M is 
[[2623 1289]
 [   5 4211]]
Mon, 01 Sep 2025 01:47:13 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:47:13 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:47:13 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:47:13 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:47:13 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:47:13 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:47:13 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:47:13 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:47:13 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:47:20 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:47:20 main.py INFO Time of iter training 7.54 s
Mon, 01 Sep 2025 01:47:20 main.py INFO On iter step 35.0:, global step 2240 Loss-step [2.0088 1.6226 1.0000 1.2380]
Mon, 01 Sep 2025 01:47:24 main.py INFO In dataset train: Loss is [0.6789 0.4705 0.0000 0.2084]
Mon, 01 Sep 2025 01:47:24 main.py INFO 		Acc is 0.8373, F1-micro is 0.8373
Mon, 01 Sep 2025 01:47:24 main.py INFO 		F1-macro is 0.8320, AUC is 0.5000
Mon, 01 Sep 2025 01:47:24 main.py INFO 		Pre-macro is 0.8778, Rec_macro is 0.8347
Mon, 01 Sep 2025 01:47:24 main.py INFO 		For sarcasm, C_M is 
[[3337 1637]
 [   8 5130]]
Mon, 01 Sep 2025 01:47:24 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:47:24 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:47:24 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:47:24 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:47:24 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:47:24 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:47:24 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:47:24 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:47:27 main.py INFO In dataset test: Loss is [0.6822 0.4744 0.0000 0.2078]
Mon, 01 Sep 2025 01:47:27 main.py INFO 		Acc is 0.8381, F1-micro is 0.8381
Mon, 01 Sep 2025 01:47:27 main.py INFO 		F1-macro is 0.8314, AUC is 0.5000
Mon, 01 Sep 2025 01:47:27 main.py INFO 		Pre-macro is 0.8808, Rec_macro is 0.8318
Mon, 01 Sep 2025 01:47:27 main.py INFO 		For sarcasm, C_M is 
[[2598 1314]
 [   2 4214]]
Mon, 01 Sep 2025 01:47:27 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:47:27 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:47:27 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:47:27 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:47:27 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:47:27 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:47:27 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:47:27 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:47:27 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:47:35 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:47:35 main.py INFO Time of iter training 7.37 s
Mon, 01 Sep 2025 01:47:35 main.py INFO On iter step 36.0:, global step 2304 Loss-step [2.0180 1.6155 1.0000 1.2491]
Mon, 01 Sep 2025 01:47:38 main.py INFO In dataset train: Loss is [0.6788 0.4704 0.0000 0.2084]
Mon, 01 Sep 2025 01:47:38 main.py INFO 		Acc is 0.8516, F1-micro is 0.8516
Mon, 01 Sep 2025 01:47:38 main.py INFO 		F1-macro is 0.8487, AUC is 0.5000
Mon, 01 Sep 2025 01:47:38 main.py INFO 		Pre-macro is 0.8743, Rec_macro is 0.8496
Mon, 01 Sep 2025 01:47:38 main.py INFO 		For sarcasm, C_M is 
[[3613 1361]
 [ 140 4998]]
Mon, 01 Sep 2025 01:47:38 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:47:38 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:47:38 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:47:38 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:47:38 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:47:38 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:47:38 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:47:38 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:47:41 main.py INFO In dataset test: Loss is [0.6836 0.4759 0.0000 0.2077]
Mon, 01 Sep 2025 01:47:41 main.py INFO 		Acc is 0.8465, F1-micro is 0.8465
Mon, 01 Sep 2025 01:47:41 main.py INFO 		F1-macro is 0.8421, AUC is 0.5000
Mon, 01 Sep 2025 01:47:41 main.py INFO 		Pre-macro is 0.8734, Rec_macro is 0.8414
Mon, 01 Sep 2025 01:47:41 main.py INFO 		For sarcasm, C_M is 
[[2765 1147]
 [ 101 4115]]
Mon, 01 Sep 2025 01:47:41 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:47:41 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:47:41 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:47:41 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:47:41 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:47:41 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:47:41 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:47:41 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:47:41 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:47:49 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:47:49 main.py INFO Time of iter training 7.74 s
Mon, 01 Sep 2025 01:47:49 main.py INFO On iter step 37.0:, global step 2368 Loss-step [1.9934 1.6140 1.0000 1.2351]
Mon, 01 Sep 2025 01:47:53 main.py INFO In dataset train: Loss is [0.6769 0.4685 0.0000 0.2084]
Mon, 01 Sep 2025 01:47:53 main.py INFO 		Acc is 0.7869, F1-micro is 0.7869
Mon, 01 Sep 2025 01:47:53 main.py INFO 		F1-macro is 0.7759, AUC is 0.5000
Mon, 01 Sep 2025 01:47:53 main.py INFO 		Pre-macro is 0.8462, Rec_macro is 0.7835
Mon, 01 Sep 2025 01:47:53 main.py INFO 		For sarcasm, C_M is 
[[2861 2113]
 [  42 5096]]
Mon, 01 Sep 2025 01:47:53 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:47:53 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:47:53 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:47:53 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:47:53 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:47:53 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:47:53 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:47:53 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:47:56 main.py INFO In dataset test: Loss is [0.6807 0.4730 0.0000 0.2077]
Mon, 01 Sep 2025 01:47:56 main.py INFO 		Acc is 0.7847, F1-micro is 0.7847
Mon, 01 Sep 2025 01:47:56 main.py INFO 		F1-macro is 0.7713, AUC is 0.5000
Mon, 01 Sep 2025 01:47:56 main.py INFO 		Pre-macro is 0.8453, Rec_macro is 0.7767
Mon, 01 Sep 2025 01:47:56 main.py INFO 		For sarcasm, C_M is 
[[2205 1707]
 [  43 4173]]
Mon, 01 Sep 2025 01:47:56 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:47:56 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:47:56 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:47:56 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:47:56 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:47:56 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:47:56 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:47:56 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:47:56 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:48:03 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:48:03 main.py INFO Time of iter training 7.43 s
Mon, 01 Sep 2025 01:48:03 main.py INFO On iter step 38.0:, global step 2432 Loss-step [2.0030 1.6322 1.0000 1.2272]
Mon, 01 Sep 2025 01:48:07 main.py INFO In dataset train: Loss is [0.6792 0.4708 0.0000 0.2084]
Mon, 01 Sep 2025 01:48:07 main.py INFO 		Acc is 0.7836, F1-micro is 0.7836
Mon, 01 Sep 2025 01:48:07 main.py INFO 		F1-macro is 0.7736, AUC is 0.5000
Mon, 01 Sep 2025 01:48:07 main.py INFO 		Pre-macro is 0.8351, Rec_macro is 0.7804
Mon, 01 Sep 2025 01:48:07 main.py INFO 		For sarcasm, C_M is 
[[2899 2075]
 [ 113 5025]]
Mon, 01 Sep 2025 01:48:07 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:48:07 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:48:07 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:48:07 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:48:07 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:48:07 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:48:07 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:48:07 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:48:10 main.py INFO In dataset test: Loss is [0.6840 0.4763 0.0000 0.2077]
Mon, 01 Sep 2025 01:48:10 main.py INFO 		Acc is 0.7856, F1-micro is 0.7856
Mon, 01 Sep 2025 01:48:10 main.py INFO 		F1-macro is 0.7735, AUC is 0.5000
Mon, 01 Sep 2025 01:48:10 main.py INFO 		Pre-macro is 0.8386, Rec_macro is 0.7780
Mon, 01 Sep 2025 01:48:10 main.py INFO 		For sarcasm, C_M is 
[[2254 1658]
 [  85 4131]]
Mon, 01 Sep 2025 01:48:10 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:48:10 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:48:10 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:48:10 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:48:10 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:48:10 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:48:10 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:48:10 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:48:10 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:48:17 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:48:17 main.py INFO Time of iter training 7.25 s
Mon, 01 Sep 2025 01:48:17 main.py INFO On iter step 39.0:, global step 2496 Loss-step [1.9986 1.6180 1.0000 1.2352]
Mon, 01 Sep 2025 01:48:21 main.py INFO In dataset train: Loss is [0.6790 0.4706 0.0000 0.2085]
Mon, 01 Sep 2025 01:48:21 main.py INFO 		Acc is 0.7758, F1-micro is 0.7758
Mon, 01 Sep 2025 01:48:21 main.py INFO 		F1-macro is 0.7621, AUC is 0.5000
Mon, 01 Sep 2025 01:48:21 main.py INFO 		Pre-macro is 0.8466, Rec_macro is 0.7721
Mon, 01 Sep 2025 01:48:21 main.py INFO 		For sarcasm, C_M is 
[[2709 2265]
 [   2 5136]]
Mon, 01 Sep 2025 01:48:21 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:48:21 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:48:21 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:48:21 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:48:21 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:48:21 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:48:21 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:48:21 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:48:24 main.py INFO In dataset test: Loss is [0.6824 0.4745 0.0000 0.2078]
Mon, 01 Sep 2025 01:48:24 main.py INFO 		Acc is 0.7804, F1-micro is 0.7804
Mon, 01 Sep 2025 01:48:24 main.py INFO 		F1-macro is 0.7649, AUC is 0.5000
Mon, 01 Sep 2025 01:48:24 main.py INFO 		Pre-macro is 0.8511, Rec_macro is 0.7719
Mon, 01 Sep 2025 01:48:24 main.py INFO 		For sarcasm, C_M is 
[[2128 1784]
 [   1 4215]]
Mon, 01 Sep 2025 01:48:24 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:48:24 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:48:24 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:48:24 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:48:24 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:48:24 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:48:24 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:48:24 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:48:24 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:48:32 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:48:32 main.py INFO Time of iter training 8.12 s
Mon, 01 Sep 2025 01:48:32 main.py INFO On iter step 40.0:, global step 2560 Loss-step [1.9731 1.5989 1.0000 1.2340]
Mon, 01 Sep 2025 01:48:36 main.py INFO In dataset train: Loss is [0.6768 0.4684 0.0000 0.2084]
Mon, 01 Sep 2025 01:48:36 main.py INFO 		Acc is 0.8451, F1-micro is 0.8451
Mon, 01 Sep 2025 01:48:36 main.py INFO 		F1-macro is 0.8410, AUC is 0.5000
Mon, 01 Sep 2025 01:48:36 main.py INFO 		Pre-macro is 0.8782, Rec_macro is 0.8427
Mon, 01 Sep 2025 01:48:36 main.py INFO 		For sarcasm, C_M is 
[[3457 1517]
 [  49 5089]]
Mon, 01 Sep 2025 01:48:36 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:48:36 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:48:36 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:48:36 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:48:36 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:48:36 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:48:36 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:48:36 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:48:39 main.py INFO In dataset test: Loss is [0.6824 0.4745 0.0000 0.2078]
Mon, 01 Sep 2025 01:48:39 main.py INFO 		Acc is 0.8401, F1-micro is 0.8401
Mon, 01 Sep 2025 01:48:39 main.py INFO 		F1-macro is 0.8341, AUC is 0.5000
Mon, 01 Sep 2025 01:48:39 main.py INFO 		Pre-macro is 0.8779, Rec_macro is 0.8341
Mon, 01 Sep 2025 01:48:39 main.py INFO 		For sarcasm, C_M is 
[[2643 1269]
 [  31 4185]]
Mon, 01 Sep 2025 01:48:39 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:48:39 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:48:39 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:48:39 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:48:39 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:48:39 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:48:39 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:48:39 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:48:39 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:48:47 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:48:47 main.py INFO Time of iter training 7.92 s
Mon, 01 Sep 2025 01:48:47 main.py INFO On iter step 41.0:, global step 2624 Loss-step [1.9714 1.6005 1.0000 1.2317]
Mon, 01 Sep 2025 01:48:51 main.py INFO In dataset train: Loss is [0.6725 0.4641 0.0000 0.2084]
Mon, 01 Sep 2025 01:48:51 main.py INFO 		Acc is 0.8561, F1-micro is 0.8561
Mon, 01 Sep 2025 01:48:51 main.py INFO 		F1-macro is 0.8523, AUC is 0.5000
Mon, 01 Sep 2025 01:48:51 main.py INFO 		Pre-macro is 0.8896, Rec_macro is 0.8537
Mon, 01 Sep 2025 01:48:51 main.py INFO 		For sarcasm, C_M is 
[[3520 1454]
 [   1 5137]]
Mon, 01 Sep 2025 01:48:51 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:48:51 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:48:51 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:48:51 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:48:51 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:48:51 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:48:51 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:48:51 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:48:54 main.py INFO In dataset test: Loss is [0.6827 0.4750 0.0000 0.2078]
Mon, 01 Sep 2025 01:48:54 main.py INFO 		Acc is 0.8461, F1-micro is 0.8461
Mon, 01 Sep 2025 01:48:54 main.py INFO 		F1-macro is 0.8403, AUC is 0.5000
Mon, 01 Sep 2025 01:48:54 main.py INFO 		Pre-macro is 0.8848, Rec_macro is 0.8402
Mon, 01 Sep 2025 01:48:54 main.py INFO 		For sarcasm, C_M is 
[[2667 1245]
 [   6 4210]]
Mon, 01 Sep 2025 01:48:54 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:48:54 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:48:54 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:48:54 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:48:54 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:48:54 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:48:54 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:48:54 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:48:54 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:49:01 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:49:01 main.py INFO Time of iter training 7.41 s
Mon, 01 Sep 2025 01:49:01 main.py INFO On iter step 42.0:, global step 2688 Loss-step [1.9903 1.6091 1.0000 1.2369]
Mon, 01 Sep 2025 01:49:05 main.py INFO In dataset train: Loss is [0.6748 0.4663 0.0000 0.2085]
Mon, 01 Sep 2025 01:49:05 main.py INFO 		Acc is 0.8534, F1-micro is 0.8534
Mon, 01 Sep 2025 01:49:05 main.py INFO 		F1-macro is 0.8499, AUC is 0.5000
Mon, 01 Sep 2025 01:49:05 main.py INFO 		Pre-macro is 0.8834, Rec_macro is 0.8512
Mon, 01 Sep 2025 01:49:05 main.py INFO 		For sarcasm, C_M is 
[[3540 1434]
 [  48 5090]]
Mon, 01 Sep 2025 01:49:05 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:49:05 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:49:05 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:49:05 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:49:05 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:49:05 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:49:05 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:49:05 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:49:08 main.py INFO In dataset test: Loss is [0.6819 0.4740 0.0000 0.2078]
Mon, 01 Sep 2025 01:49:08 main.py INFO 		Acc is 0.8438, F1-micro is 0.8438
Mon, 01 Sep 2025 01:49:08 main.py INFO 		F1-macro is 0.8383, AUC is 0.5000
Mon, 01 Sep 2025 01:49:08 main.py INFO 		Pre-macro is 0.8786, Rec_macro is 0.8381
Mon, 01 Sep 2025 01:49:08 main.py INFO 		For sarcasm, C_M is 
[[2684 1228]
 [  42 4174]]
Mon, 01 Sep 2025 01:49:08 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:49:08 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:49:08 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:49:08 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:49:08 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:49:08 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:49:08 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:49:08 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:49:08 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:49:16 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:49:16 main.py INFO Time of iter training 7.91 s
Mon, 01 Sep 2025 01:49:16 main.py INFO On iter step 43.0:, global step 2752 Loss-step [1.9689 1.5905 1.0000 1.2379]
Mon, 01 Sep 2025 01:49:20 main.py INFO In dataset train: Loss is [0.6784 0.4700 0.0000 0.2084]
Mon, 01 Sep 2025 01:49:20 main.py INFO 		Acc is 0.8627, F1-micro is 0.8627
Mon, 01 Sep 2025 01:49:20 main.py INFO 		F1-macro is 0.8596, AUC is 0.5000
Mon, 01 Sep 2025 01:49:20 main.py INFO 		Pre-macro is 0.8913, Rec_macro is 0.8606
Mon, 01 Sep 2025 01:49:20 main.py INFO 		For sarcasm, C_M is 
[[3611 1363]
 [  25 5113]]
Mon, 01 Sep 2025 01:49:20 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:49:20 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:49:20 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:49:20 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:49:20 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:49:20 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:49:20 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:49:20 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:49:23 main.py INFO In dataset test: Loss is [0.6871 0.4793 0.0000 0.2077]
Mon, 01 Sep 2025 01:49:23 main.py INFO 		Acc is 0.8549, F1-micro is 0.8549
Mon, 01 Sep 2025 01:49:23 main.py INFO 		F1-macro is 0.8503, AUC is 0.5000
Mon, 01 Sep 2025 01:49:23 main.py INFO 		Pre-macro is 0.8871, Rec_macro is 0.8496
Mon, 01 Sep 2025 01:49:23 main.py INFO 		For sarcasm, C_M is 
[[2762 1150]
 [  29 4187]]
Mon, 01 Sep 2025 01:49:23 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:49:23 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:49:23 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:49:23 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:49:23 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:49:23 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:49:23 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:49:23 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:49:23 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:49:31 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:49:31 main.py INFO Time of iter training 7.88 s
Mon, 01 Sep 2025 01:49:31 main.py INFO On iter step 44.0:, global step 2816 Loss-step [1.9856 1.6023 1.0000 1.2392]
Mon, 01 Sep 2025 01:49:34 main.py INFO In dataset train: Loss is [0.6779 0.4695 0.0000 0.2084]
Mon, 01 Sep 2025 01:49:34 main.py INFO 		Acc is 0.8209, F1-micro is 0.8209
Mon, 01 Sep 2025 01:49:34 main.py INFO 		F1-macro is 0.8142, AUC is 0.5000
Mon, 01 Sep 2025 01:49:34 main.py INFO 		Pre-macro is 0.8663, Rec_macro is 0.8180
Mon, 01 Sep 2025 01:49:34 main.py INFO 		For sarcasm, C_M is 
[[3191 1783]
 [  28 5110]]
Mon, 01 Sep 2025 01:49:34 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:49:34 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:49:34 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:49:34 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:49:34 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:49:34 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:49:34 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:49:34 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:49:37 main.py INFO In dataset test: Loss is [0.6821 0.4744 0.0000 0.2077]
Mon, 01 Sep 2025 01:49:37 main.py INFO 		Acc is 0.8194, F1-micro is 0.8194
Mon, 01 Sep 2025 01:49:37 main.py INFO 		F1-macro is 0.8107, AUC is 0.5000
Mon, 01 Sep 2025 01:49:37 main.py INFO 		Pre-macro is 0.8688, Rec_macro is 0.8125
Mon, 01 Sep 2025 01:49:37 main.py INFO 		For sarcasm, C_M is 
[[2457 1455]
 [  13 4203]]
Mon, 01 Sep 2025 01:49:37 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:49:37 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:49:37 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:49:37 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:49:37 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:49:37 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:49:37 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:49:37 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:49:37 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:49:45 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:49:45 main.py INFO Time of iter training 7.49 s
Mon, 01 Sep 2025 01:49:45 main.py INFO On iter step 45.0:, global step 2880 Loss-step [2.0106 1.6210 1.0002 1.2401]
Mon, 01 Sep 2025 01:49:49 main.py INFO In dataset train: Loss is [0.6780 0.4695 0.0000 0.2084]
Mon, 01 Sep 2025 01:49:49 main.py INFO 		Acc is 0.8025, F1-micro is 0.8025
Mon, 01 Sep 2025 01:49:49 main.py INFO 		F1-macro is 0.7932, AUC is 0.5000
Mon, 01 Sep 2025 01:49:49 main.py INFO 		Pre-macro is 0.8591, Rec_macro is 0.7993
Mon, 01 Sep 2025 01:49:49 main.py INFO 		For sarcasm, C_M is 
[[2984 1990]
 [   7 5131]]
Mon, 01 Sep 2025 01:49:49 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:49:49 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:49:49 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:49:49 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:49:49 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:49:49 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:49:49 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:49:49 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:49:52 main.py INFO In dataset test: Loss is [0.6814 0.4736 0.0000 0.2078]
Mon, 01 Sep 2025 01:49:52 main.py INFO 		Acc is 0.8075, F1-micro is 0.8075
Mon, 01 Sep 2025 01:49:52 main.py INFO 		F1-macro is 0.7968, AUC is 0.5000
Mon, 01 Sep 2025 01:49:52 main.py INFO 		Pre-macro is 0.8640, Rec_macro is 0.8000
Mon, 01 Sep 2025 01:49:52 main.py INFO 		For sarcasm, C_M is 
[[2351 1561]
 [   4 4212]]
Mon, 01 Sep 2025 01:49:52 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:49:52 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:49:52 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:49:52 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:49:52 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:49:52 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:49:52 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:49:52 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:49:52 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:49:59 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:49:59 main.py INFO Time of iter training 7.91 s
Mon, 01 Sep 2025 01:49:59 main.py INFO On iter step 46.0:, global step 2944 Loss-step [2.0080 1.6092 1.0000 1.2478]
Mon, 01 Sep 2025 01:50:04 main.py INFO In dataset train: Loss is [0.6797 0.4712 0.0000 0.2084]
Mon, 01 Sep 2025 01:50:04 main.py INFO 		Acc is 0.8590, F1-micro is 0.8590
Mon, 01 Sep 2025 01:50:04 main.py INFO 		F1-macro is 0.8559, AUC is 0.5000
Mon, 01 Sep 2025 01:50:04 main.py INFO 		Pre-macro is 0.8862, Rec_macro is 0.8568
Mon, 01 Sep 2025 01:50:04 main.py INFO 		For sarcasm, C_M is 
[[3604 1370]
 [  56 5082]]
Mon, 01 Sep 2025 01:50:04 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:50:04 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:50:04 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:50:04 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:50:04 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:50:04 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:50:04 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:50:04 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:50:07 main.py INFO In dataset test: Loss is [0.6838 0.4760 0.0000 0.2078]
Mon, 01 Sep 2025 01:50:07 main.py INFO 		Acc is 0.8527, F1-micro is 0.8527
Mon, 01 Sep 2025 01:50:07 main.py INFO 		F1-macro is 0.8481, AUC is 0.5000
Mon, 01 Sep 2025 01:50:07 main.py INFO 		Pre-macro is 0.8844, Rec_macro is 0.8474
Mon, 01 Sep 2025 01:50:07 main.py INFO 		For sarcasm, C_M is 
[[2755 1157]
 [  40 4176]]
Mon, 01 Sep 2025 01:50:07 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:50:07 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:50:07 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:50:07 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:50:07 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:50:07 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:50:07 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:50:07 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:50:07 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:50:15 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:50:15 main.py INFO Time of iter training 7.76 s
Mon, 01 Sep 2025 01:50:15 main.py INFO On iter step 47.0:, global step 3008 Loss-step [1.9861 1.6076 1.0000 1.2354]
Mon, 01 Sep 2025 01:50:18 main.py INFO In dataset train: Loss is [0.6768 0.4684 0.0000 0.2084]
Mon, 01 Sep 2025 01:50:18 main.py INFO 		Acc is 0.8239, F1-micro is 0.8239
Mon, 01 Sep 2025 01:50:18 main.py INFO 		F1-macro is 0.8174, AUC is 0.5000
Mon, 01 Sep 2025 01:50:18 main.py INFO 		Pre-macro is 0.8686, Rec_macro is 0.8210
Mon, 01 Sep 2025 01:50:18 main.py INFO 		For sarcasm, C_M is 
[[3216 1758]
 [  23 5115]]
Mon, 01 Sep 2025 01:50:18 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:50:18 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:50:18 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:50:18 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:50:18 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:50:18 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:50:18 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:50:18 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:50:21 main.py INFO In dataset test: Loss is [0.6808 0.4730 0.0000 0.2078]
Mon, 01 Sep 2025 01:50:21 main.py INFO 		Acc is 0.8247, F1-micro is 0.8247
Mon, 01 Sep 2025 01:50:21 main.py INFO 		F1-macro is 0.8166, AUC is 0.5000
Mon, 01 Sep 2025 01:50:21 main.py INFO 		Pre-macro is 0.8715, Rec_macro is 0.8180
Mon, 01 Sep 2025 01:50:21 main.py INFO 		For sarcasm, C_M is 
[[2501 1411]
 [  14 4202]]
Mon, 01 Sep 2025 01:50:21 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:50:21 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:50:21 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:50:21 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:50:21 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:50:21 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:50:21 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:50:21 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:50:21 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:50:29 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:50:29 main.py INFO Time of iter training 7.51 s
Mon, 01 Sep 2025 01:50:29 main.py INFO On iter step 48.0:, global step 3072 Loss-step [2.0056 1.6324 1.0000 1.2286]
Mon, 01 Sep 2025 01:50:32 main.py INFO In dataset train: Loss is [0.6774 0.4690 0.0000 0.2084]
Mon, 01 Sep 2025 01:50:32 main.py INFO 		Acc is 0.7938, F1-micro is 0.7938
Mon, 01 Sep 2025 01:50:32 main.py INFO 		F1-macro is 0.7848, AUC is 0.5000
Mon, 01 Sep 2025 01:50:32 main.py INFO 		Pre-macro is 0.8435, Rec_macro is 0.7907
Mon, 01 Sep 2025 01:50:32 main.py INFO 		For sarcasm, C_M is 
[[2981 1993]
 [  92 5046]]
Mon, 01 Sep 2025 01:50:32 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:50:32 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:50:32 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:50:32 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:50:32 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:50:32 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:50:32 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:50:32 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:50:35 main.py INFO In dataset test: Loss is [0.6827 0.4750 0.0000 0.2077]
Mon, 01 Sep 2025 01:50:35 main.py INFO 		Acc is 0.7979, F1-micro is 0.7979
Mon, 01 Sep 2025 01:50:35 main.py INFO 		F1-macro is 0.7872, AUC is 0.5000
Mon, 01 Sep 2025 01:50:35 main.py INFO 		Pre-macro is 0.8487, Rec_macro is 0.7906
Mon, 01 Sep 2025 01:50:35 main.py INFO 		For sarcasm, C_M is 
[[2334 1578]
 [  65 4151]]
Mon, 01 Sep 2025 01:50:35 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:50:35 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:50:35 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:50:35 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:50:35 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:50:35 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:50:35 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:50:35 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:50:35 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:50:43 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:50:43 main.py INFO Time of iter training 7.37 s
Mon, 01 Sep 2025 01:50:43 main.py INFO On iter step 49.0:, global step 3136 Loss-step [1.9906 1.6130 1.0000 1.2341]
Mon, 01 Sep 2025 01:50:46 main.py INFO In dataset train: Loss is [0.6773 0.4689 0.0000 0.2084]
Mon, 01 Sep 2025 01:50:46 main.py INFO 		Acc is 0.7994, F1-micro is 0.7994
Mon, 01 Sep 2025 01:50:46 main.py INFO 		F1-macro is 0.7897, AUC is 0.5000
Mon, 01 Sep 2025 01:50:46 main.py INFO 		Pre-macro is 0.8571, Rec_macro is 0.7962
Mon, 01 Sep 2025 01:50:46 main.py INFO 		For sarcasm, C_M is 
[[2956 2018]
 [  10 5128]]
Mon, 01 Sep 2025 01:50:46 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:50:46 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:50:46 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:50:46 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:50:46 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:50:46 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:50:46 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:50:46 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:50:49 main.py INFO In dataset test: Loss is [0.6815 0.4737 0.0000 0.2078]
Mon, 01 Sep 2025 01:50:49 main.py INFO 		Acc is 0.7976, F1-micro is 0.7976
Mon, 01 Sep 2025 01:50:49 main.py INFO 		F1-macro is 0.7856, AUC is 0.5000
Mon, 01 Sep 2025 01:50:49 main.py INFO 		Pre-macro is 0.8575, Rec_macro is 0.7899
Mon, 01 Sep 2025 01:50:49 main.py INFO 		For sarcasm, C_M is 
[[2279 1633]
 [  12 4204]]
Mon, 01 Sep 2025 01:50:49 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:50:49 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:50:49 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:50:49 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:50:49 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:50:49 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:50:49 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:50:49 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:50:49 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:50:57 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:50:57 main.py INFO Time of iter training 7.52 s
Mon, 01 Sep 2025 01:50:57 main.py INFO On iter step 50.0:, global step 3200 Loss-step [1.9840 1.6086 1.0000 1.2334]
Mon, 01 Sep 2025 01:51:00 main.py INFO In dataset train: Loss is [0.6768 0.4683 0.0000 0.2085]
Mon, 01 Sep 2025 01:51:00 main.py INFO 		Acc is 0.8349, F1-micro is 0.8349
Mon, 01 Sep 2025 01:51:00 main.py INFO 		F1-macro is 0.8323, AUC is 0.5000
Mon, 01 Sep 2025 01:51:00 main.py INFO 		Pre-macro is 0.8527, Rec_macro is 0.8331
Mon, 01 Sep 2025 01:51:00 main.py INFO 		For sarcasm, C_M is 
[[3583 1391]
 [ 278 4860]]
Mon, 01 Sep 2025 01:51:00 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:51:00 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:51:00 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:51:00 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:51:00 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:51:00 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:51:00 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:51:00 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:51:03 main.py INFO In dataset test: Loss is [0.6850 0.4771 0.0000 0.2078]
Mon, 01 Sep 2025 01:51:04 main.py INFO 		Acc is 0.8289, F1-micro is 0.8289
Mon, 01 Sep 2025 01:51:04 main.py INFO 		F1-macro is 0.8247, AUC is 0.5000
Mon, 01 Sep 2025 01:51:04 main.py INFO 		Pre-macro is 0.8494, Rec_macro is 0.8243
Mon, 01 Sep 2025 01:51:04 main.py INFO 		For sarcasm, C_M is 
[[2743 1169]
 [ 222 3994]]
Mon, 01 Sep 2025 01:51:04 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:51:04 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:51:04 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:51:04 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:51:04 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:51:04 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:51:04 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:51:04 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:51:04 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:51:11 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:51:11 main.py INFO Time of iter training 7.32 s
Mon, 01 Sep 2025 01:51:11 main.py INFO On iter step 51.0:, global step 3264 Loss-step [1.9722 1.6032 1.0000 1.2302]
Mon, 01 Sep 2025 01:51:14 main.py INFO In dataset train: Loss is [0.6731 0.4647 0.0000 0.2084]
Mon, 01 Sep 2025 01:51:14 main.py INFO 		Acc is 0.8650, F1-micro is 0.8650
Mon, 01 Sep 2025 01:51:14 main.py INFO 		F1-macro is 0.8619, AUC is 0.5000
Mon, 01 Sep 2025 01:51:14 main.py INFO 		Pre-macro is 0.8947, Rec_macro is 0.8628
Mon, 01 Sep 2025 01:51:14 main.py INFO 		For sarcasm, C_M is 
[[3613 1361]
 [   4 5134]]
Mon, 01 Sep 2025 01:51:14 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:51:14 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:51:14 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:51:14 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:51:14 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:51:14 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:51:14 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:51:14 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:51:17 main.py INFO In dataset test: Loss is [0.6849 0.4771 0.0000 0.2078]
Mon, 01 Sep 2025 01:51:17 main.py INFO 		Acc is 0.8565, F1-micro is 0.8565
Mon, 01 Sep 2025 01:51:17 main.py INFO 		F1-macro is 0.8519, AUC is 0.5000
Mon, 01 Sep 2025 01:51:17 main.py INFO 		Pre-macro is 0.8893, Rec_macro is 0.8511
Mon, 01 Sep 2025 01:51:17 main.py INFO 		For sarcasm, C_M is 
[[2765 1147]
 [  19 4197]]
Mon, 01 Sep 2025 01:51:17 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:51:17 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:51:17 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:51:17 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:51:17 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:51:17 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:51:17 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:51:17 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:51:17 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:51:26 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:51:26 main.py INFO Time of iter training 8.39 s
Mon, 01 Sep 2025 01:51:26 main.py INFO On iter step 52.0:, global step 3328 Loss-step [1.9898 1.6071 1.0000 1.2381]
Mon, 01 Sep 2025 01:51:30 main.py INFO In dataset train: Loss is [0.6731 0.4646 0.0000 0.2084]
Mon, 01 Sep 2025 01:51:30 main.py INFO 		Acc is 0.8476, F1-micro is 0.8476
Mon, 01 Sep 2025 01:51:30 main.py INFO 		F1-macro is 0.8438, AUC is 0.5000
Mon, 01 Sep 2025 01:51:30 main.py INFO 		Pre-macro is 0.8787, Rec_macro is 0.8453
Mon, 01 Sep 2025 01:51:30 main.py INFO 		For sarcasm, C_M is 
[[3493 1481]
 [  60 5078]]
Mon, 01 Sep 2025 01:51:30 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:51:30 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:51:30 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:51:30 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:51:30 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:51:30 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:51:30 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:51:30 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:51:33 main.py INFO In dataset test: Loss is [0.6823 0.4745 0.0000 0.2078]
Mon, 01 Sep 2025 01:51:33 main.py INFO 		Acc is 0.8360, F1-micro is 0.8360
Mon, 01 Sep 2025 01:51:33 main.py INFO 		F1-macro is 0.8300, AUC is 0.5000
Mon, 01 Sep 2025 01:51:33 main.py INFO 		Pre-macro is 0.8722, Rec_macro is 0.8301
Mon, 01 Sep 2025 01:51:33 main.py INFO 		For sarcasm, C_M is 
[[2635 1277]
 [  56 4160]]
Mon, 01 Sep 2025 01:51:33 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:51:33 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:51:33 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:51:33 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:51:33 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:51:33 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:51:33 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:51:33 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:51:33 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:51:41 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:51:41 main.py INFO Time of iter training 8.75 s
Mon, 01 Sep 2025 01:51:41 main.py INFO On iter step 53.0:, global step 3392 Loss-step [1.9614 1.5824 1.0000 1.2395]
Mon, 01 Sep 2025 01:51:46 main.py INFO In dataset train: Loss is [0.6771 0.4687 0.0000 0.2084]
Mon, 01 Sep 2025 01:51:46 main.py INFO 		Acc is 0.8600, F1-micro is 0.8600
Mon, 01 Sep 2025 01:51:46 main.py INFO 		F1-macro is 0.8569, AUC is 0.5000
Mon, 01 Sep 2025 01:51:46 main.py INFO 		Pre-macro is 0.8871, Rec_macro is 0.8578
Mon, 01 Sep 2025 01:51:46 main.py INFO 		For sarcasm, C_M is 
[[3611 1363]
 [  53 5085]]
Mon, 01 Sep 2025 01:51:46 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:51:46 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:51:46 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:51:46 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:51:46 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:51:46 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:51:46 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:51:46 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:51:49 main.py INFO In dataset test: Loss is [0.6865 0.4788 0.0000 0.2077]
Mon, 01 Sep 2025 01:51:49 main.py INFO 		Acc is 0.8517, F1-micro is 0.8517
Mon, 01 Sep 2025 01:51:49 main.py INFO 		F1-macro is 0.8472, AUC is 0.5000
Mon, 01 Sep 2025 01:51:49 main.py INFO 		Pre-macro is 0.8824, Rec_macro is 0.8465
Mon, 01 Sep 2025 01:51:49 main.py INFO 		For sarcasm, C_M is 
[[2758 1154]
 [  51 4165]]
Mon, 01 Sep 2025 01:51:49 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:51:49 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:51:49 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:51:49 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:51:49 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:51:49 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:51:49 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:51:49 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:51:49 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:51:57 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:51:57 main.py INFO Time of iter training 7.71 s
Mon, 01 Sep 2025 01:51:57 main.py INFO On iter step 54.0:, global step 3456 Loss-step [1.9871 1.6040 1.0000 1.2389]
Mon, 01 Sep 2025 01:52:01 main.py INFO In dataset train: Loss is [0.6784 0.4699 0.0000 0.2084]
Mon, 01 Sep 2025 01:52:01 main.py INFO 		Acc is 0.8219, F1-micro is 0.8219
Mon, 01 Sep 2025 01:52:01 main.py INFO 		F1-macro is 0.8152, AUC is 0.5000
Mon, 01 Sep 2025 01:52:01 main.py INFO 		Pre-macro is 0.8677, Rec_macro is 0.8190
Mon, 01 Sep 2025 01:52:01 main.py INFO 		For sarcasm, C_M is 
[[3194 1780]
 [  21 5117]]
Mon, 01 Sep 2025 01:52:01 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:52:01 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:52:01 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:52:01 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:52:01 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:52:01 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:52:01 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:52:01 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:52:04 main.py INFO In dataset test: Loss is [0.6842 0.4765 0.0000 0.2077]
Mon, 01 Sep 2025 01:52:04 main.py INFO 		Acc is 0.8175, F1-micro is 0.8175
Mon, 01 Sep 2025 01:52:04 main.py INFO 		F1-macro is 0.8086, AUC is 0.5000
Mon, 01 Sep 2025 01:52:04 main.py INFO 		Pre-macro is 0.8672, Rec_macro is 0.8106
Mon, 01 Sep 2025 01:52:04 main.py INFO 		For sarcasm, C_M is 
[[2446 1466]
 [  17 4199]]
Mon, 01 Sep 2025 01:52:04 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:52:04 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:52:04 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:52:04 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:52:04 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:52:04 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:52:04 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:52:04 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:52:04 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:52:11 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:52:11 main.py INFO Time of iter training 7.84 s
Mon, 01 Sep 2025 01:52:11 main.py INFO On iter step 55.0:, global step 3520 Loss-step [2.0117 1.6238 1.0000 1.2389]
Mon, 01 Sep 2025 01:52:15 main.py INFO In dataset train: Loss is [0.6775 0.4690 0.0000 0.2084]
Mon, 01 Sep 2025 01:52:15 main.py INFO 		Acc is 0.7930, F1-micro is 0.7930
Mon, 01 Sep 2025 01:52:15 main.py INFO 		F1-macro is 0.7823, AUC is 0.5000
Mon, 01 Sep 2025 01:52:15 main.py INFO 		Pre-macro is 0.8541, Rec_macro is 0.7896
Mon, 01 Sep 2025 01:52:15 main.py INFO 		For sarcasm, C_M is 
[[2889 2085]
 [   8 5130]]
Mon, 01 Sep 2025 01:52:15 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:52:15 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:52:15 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:52:15 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:52:15 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:52:15 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:52:15 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:52:15 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:52:18 main.py INFO In dataset test: Loss is [0.6812 0.4734 0.0000 0.2078]
Mon, 01 Sep 2025 01:52:18 main.py INFO 		Acc is 0.7977, F1-micro is 0.7977
Mon, 01 Sep 2025 01:52:18 main.py INFO 		F1-macro is 0.7856, AUC is 0.5000
Mon, 01 Sep 2025 01:52:18 main.py INFO 		Pre-macro is 0.8583, Rec_macro is 0.7900
Mon, 01 Sep 2025 01:52:18 main.py INFO 		For sarcasm, C_M is 
[[2276 1636]
 [   8 4208]]
Mon, 01 Sep 2025 01:52:18 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:52:18 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:52:18 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:52:18 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:52:18 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:52:18 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:52:18 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:52:18 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:52:18 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:52:25 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:52:25 main.py INFO Time of iter training 7.25 s
Mon, 01 Sep 2025 01:52:25 main.py INFO On iter step 56.0:, global step 3584 Loss-step [1.9968 1.6028 1.0000 1.2458]
Mon, 01 Sep 2025 01:52:29 main.py INFO In dataset train: Loss is [0.6799 0.4715 0.0000 0.2084]
Mon, 01 Sep 2025 01:52:29 main.py INFO 		Acc is 0.8471, F1-micro is 0.8471
Mon, 01 Sep 2025 01:52:29 main.py INFO 		F1-macro is 0.8437, AUC is 0.5000
Mon, 01 Sep 2025 01:52:29 main.py INFO 		Pre-macro is 0.8741, Rec_macro is 0.8449
Mon, 01 Sep 2025 01:52:29 main.py INFO 		For sarcasm, C_M is 
[[3535 1439]
 [ 107 5031]]
Mon, 01 Sep 2025 01:52:29 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:52:29 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:52:29 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:52:29 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:52:29 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:52:29 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:52:29 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:52:29 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:52:32 main.py INFO In dataset test: Loss is [0.6838 0.4761 0.0000 0.2078]
Mon, 01 Sep 2025 01:52:32 main.py INFO 		Acc is 0.8414, F1-micro is 0.8414
Mon, 01 Sep 2025 01:52:32 main.py INFO 		F1-macro is 0.8365, AUC is 0.5000
Mon, 01 Sep 2025 01:52:32 main.py INFO 		Pre-macro is 0.8714, Rec_macro is 0.8361
Mon, 01 Sep 2025 01:52:32 main.py INFO 		For sarcasm, C_M is 
[[2713 1199]
 [  90 4126]]
Mon, 01 Sep 2025 01:52:32 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:52:32 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:52:32 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:52:32 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:52:32 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:52:32 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:52:32 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:52:32 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:52:32 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:52:39 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:52:39 main.py INFO Time of iter training 7.36 s
Mon, 01 Sep 2025 01:52:39 main.py INFO On iter step 57.0:, global step 3648 Loss-step [1.9888 1.6094 1.0000 1.2357]
Mon, 01 Sep 2025 01:52:43 main.py INFO In dataset train: Loss is [0.6779 0.4695 0.0000 0.2084]
Mon, 01 Sep 2025 01:52:43 main.py INFO 		Acc is 0.7994, F1-micro is 0.7994
Mon, 01 Sep 2025 01:52:43 main.py INFO 		F1-macro is 0.7903, AUC is 0.5000
Mon, 01 Sep 2025 01:52:43 main.py INFO 		Pre-macro is 0.8529, Rec_macro is 0.7963
Mon, 01 Sep 2025 01:52:43 main.py INFO 		For sarcasm, C_M is 
[[2988 1986]
 [  42 5096]]
Mon, 01 Sep 2025 01:52:43 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:52:43 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:52:43 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:52:43 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:52:43 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:52:43 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:52:43 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:52:43 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:52:46 main.py INFO In dataset test: Loss is [0.6817 0.4739 0.0000 0.2078]
Mon, 01 Sep 2025 01:52:46 main.py INFO 		Acc is 0.8028, F1-micro is 0.8028
Mon, 01 Sep 2025 01:52:46 main.py INFO 		F1-macro is 0.7921, AUC is 0.5000
Mon, 01 Sep 2025 01:52:46 main.py INFO 		Pre-macro is 0.8568, Rec_macro is 0.7954
Mon, 01 Sep 2025 01:52:46 main.py INFO 		For sarcasm, C_M is 
[[2341 1571]
 [  32 4184]]
Mon, 01 Sep 2025 01:52:46 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:52:46 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:52:46 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:52:46 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:52:46 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:52:46 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:52:46 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:52:46 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:52:46 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:52:54 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:52:54 main.py INFO Time of iter training 7.76 s
Mon, 01 Sep 2025 01:52:54 main.py INFO On iter step 58.0:, global step 3712 Loss-step [2.0032 1.6295 1.0000 1.2293]
Mon, 01 Sep 2025 01:52:57 main.py INFO In dataset train: Loss is [0.6779 0.4695 0.0000 0.2084]
Mon, 01 Sep 2025 01:52:57 main.py INFO 		Acc is 0.7853, F1-micro is 0.7853
Mon, 01 Sep 2025 01:52:57 main.py INFO 		F1-macro is 0.7745, AUC is 0.5000
Mon, 01 Sep 2025 01:52:57 main.py INFO 		Pre-macro is 0.8429, Rec_macro is 0.7820
Mon, 01 Sep 2025 01:52:57 main.py INFO 		For sarcasm, C_M is 
[[2863 2111]
 [  60 5078]]
Mon, 01 Sep 2025 01:52:57 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:52:57 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:52:57 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:52:57 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:52:57 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:52:57 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:52:57 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:52:57 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:53:00 main.py INFO In dataset test: Loss is [0.6826 0.4748 0.0000 0.2078]
Mon, 01 Sep 2025 01:53:00 main.py INFO 		Acc is 0.7863, F1-micro is 0.7863
Mon, 01 Sep 2025 01:53:00 main.py INFO 		F1-macro is 0.7738, AUC is 0.5000
Mon, 01 Sep 2025 01:53:00 main.py INFO 		Pre-macro is 0.8422, Rec_macro is 0.7786
Mon, 01 Sep 2025 01:53:00 main.py INFO 		For sarcasm, C_M is 
[[2241 1671]
 [  66 4150]]
Mon, 01 Sep 2025 01:53:00 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:53:00 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:53:00 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:53:00 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:53:00 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:53:00 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:53:00 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:53:00 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:53:00 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:53:08 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:53:08 main.py INFO Time of iter training 7.79 s
Mon, 01 Sep 2025 01:53:08 main.py INFO On iter step 59.0:, global step 3776 Loss-step [1.9958 1.6157 1.0000 1.2352]
Mon, 01 Sep 2025 01:53:13 main.py INFO In dataset train: Loss is [0.6765 0.4680 0.0000 0.2084]
Mon, 01 Sep 2025 01:53:13 main.py INFO 		Acc is 0.7945, F1-micro is 0.7945
Mon, 01 Sep 2025 01:53:13 main.py INFO 		F1-macro is 0.7842, AUC is 0.5000
Mon, 01 Sep 2025 01:53:13 main.py INFO 		Pre-macro is 0.8539, Rec_macro is 0.7912
Mon, 01 Sep 2025 01:53:13 main.py INFO 		For sarcasm, C_M is 
[[2911 2063]
 [  15 5123]]
Mon, 01 Sep 2025 01:53:13 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:53:13 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:53:13 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:53:13 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:53:13 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:53:13 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:53:13 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:53:13 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:53:16 main.py INFO In dataset test: Loss is [0.6814 0.4735 0.0000 0.2078]
Mon, 01 Sep 2025 01:53:16 main.py INFO 		Acc is 0.7934, F1-micro is 0.7934
Mon, 01 Sep 2025 01:53:16 main.py INFO 		F1-macro is 0.7809, AUC is 0.5000
Mon, 01 Sep 2025 01:53:16 main.py INFO 		Pre-macro is 0.8543, Rec_macro is 0.7856
Mon, 01 Sep 2025 01:53:16 main.py INFO 		For sarcasm, C_M is 
[[2251 1661]
 [  18 4198]]
Mon, 01 Sep 2025 01:53:16 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:53:16 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:53:16 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:53:16 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:53:16 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:53:16 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:53:16 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:53:16 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:53:16 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:53:23 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:53:23 main.py INFO Time of iter training 7.41 s
Mon, 01 Sep 2025 01:53:23 main.py INFO On iter step 60.0:, global step 3840 Loss-step [1.9616 1.5907 1.0000 1.2332]
Mon, 01 Sep 2025 01:53:27 main.py INFO In dataset train: Loss is [0.6743 0.4659 0.0000 0.2085]
Mon, 01 Sep 2025 01:53:27 main.py INFO 		Acc is 0.8361, F1-micro is 0.8361
Mon, 01 Sep 2025 01:53:27 main.py INFO 		F1-macro is 0.8314, AUC is 0.5000
Mon, 01 Sep 2025 01:53:27 main.py INFO 		Pre-macro is 0.8714, Rec_macro is 0.8336
Mon, 01 Sep 2025 01:53:27 main.py INFO 		For sarcasm, C_M is 
[[3379 1595]
 [  62 5076]]
Mon, 01 Sep 2025 01:53:27 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:53:27 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:53:27 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:53:27 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:53:27 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:53:27 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:53:27 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:53:27 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:53:30 main.py INFO In dataset test: Loss is [0.6820 0.4742 0.0000 0.2078]
Mon, 01 Sep 2025 01:53:30 main.py INFO 		Acc is 0.8289, F1-micro is 0.8289
Mon, 01 Sep 2025 01:53:30 main.py INFO 		F1-macro is 0.8221, AUC is 0.5000
Mon, 01 Sep 2025 01:53:30 main.py INFO 		Pre-macro is 0.8682, Rec_macro is 0.8227
Mon, 01 Sep 2025 01:53:30 main.py INFO 		For sarcasm, C_M is 
[[2575 1337]
 [  54 4162]]
Mon, 01 Sep 2025 01:53:30 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:53:30 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:53:30 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:53:30 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:53:30 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:53:30 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:53:30 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:53:30 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:53:30 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:53:37 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:53:37 main.py INFO Time of iter training 7.31 s
Mon, 01 Sep 2025 01:53:37 main.py INFO On iter step 61.0:, global step 3904 Loss-step [1.9703 1.6029 1.0000 1.2292]
Mon, 01 Sep 2025 01:53:41 main.py INFO In dataset train: Loss is [0.6713 0.4629 0.0000 0.2084]
Mon, 01 Sep 2025 01:53:41 main.py INFO 		Acc is 0.8458, F1-micro is 0.8458
Mon, 01 Sep 2025 01:53:41 main.py INFO 		F1-macro is 0.8415, AUC is 0.5000
Mon, 01 Sep 2025 01:53:41 main.py INFO 		Pre-macro is 0.8813, Rec_macro is 0.8434
Mon, 01 Sep 2025 01:53:41 main.py INFO 		For sarcasm, C_M is 
[[3437 1537]
 [  22 5116]]
Mon, 01 Sep 2025 01:53:41 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:53:41 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:53:41 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:53:41 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:53:41 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:53:41 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:53:41 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:53:41 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:53:44 main.py INFO In dataset test: Loss is [0.6823 0.4745 0.0000 0.2078]
Mon, 01 Sep 2025 01:53:44 main.py INFO 		Acc is 0.8359, F1-micro is 0.8359
Mon, 01 Sep 2025 01:53:44 main.py INFO 		F1-macro is 0.8293, AUC is 0.5000
Mon, 01 Sep 2025 01:53:44 main.py INFO 		Pre-macro is 0.8764, Rec_macro is 0.8297
Mon, 01 Sep 2025 01:53:44 main.py INFO 		For sarcasm, C_M is 
[[2602 1310]
 [  24 4192]]
Mon, 01 Sep 2025 01:53:44 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:53:44 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:53:44 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:53:44 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:53:44 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:53:44 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:53:44 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:53:44 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:53:44 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:53:52 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:53:52 main.py INFO Time of iter training 7.97 s
Mon, 01 Sep 2025 01:53:52 main.py INFO On iter step 62.0:, global step 3968 Loss-step [1.9871 1.6028 1.0000 1.2398]
Mon, 01 Sep 2025 01:53:55 main.py INFO In dataset train: Loss is [0.6734 0.4649 0.0000 0.2084]
Mon, 01 Sep 2025 01:53:55 main.py INFO 		Acc is 0.8390, F1-micro is 0.8390
Mon, 01 Sep 2025 01:53:55 main.py INFO 		F1-macro is 0.8343, AUC is 0.5000
Mon, 01 Sep 2025 01:53:55 main.py INFO 		Pre-macro is 0.8748, Rec_macro is 0.8365
Mon, 01 Sep 2025 01:53:55 main.py INFO 		For sarcasm, C_M is 
[[3392 1582]
 [  46 5092]]
Mon, 01 Sep 2025 01:53:55 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:53:55 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:53:55 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:53:55 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:53:55 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:53:55 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:53:55 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:53:55 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:53:58 main.py INFO In dataset test: Loss is [0.6836 0.4758 0.0000 0.2078]
Mon, 01 Sep 2025 01:53:58 main.py INFO 		Acc is 0.8296, F1-micro is 0.8296
Mon, 01 Sep 2025 01:53:58 main.py INFO 		F1-macro is 0.8227, AUC is 0.5000
Mon, 01 Sep 2025 01:53:58 main.py INFO 		Pre-macro is 0.8702, Rec_macro is 0.8234
Mon, 01 Sep 2025 01:53:58 main.py INFO 		For sarcasm, C_M is 
[[2569 1343]
 [  42 4174]]
Mon, 01 Sep 2025 01:53:58 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:53:58 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:53:58 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:53:58 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:53:58 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:53:58 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:53:58 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:53:58 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:53:58 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:54:05 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:54:05 main.py INFO Time of iter training 7.13 s
Mon, 01 Sep 2025 01:54:05 main.py INFO On iter step 63.0:, global step 4032 Loss-step [1.9625 1.5826 1.0000 1.2401]
Mon, 01 Sep 2025 01:54:09 main.py INFO In dataset train: Loss is [0.6763 0.4678 0.0000 0.2084]
Mon, 01 Sep 2025 01:54:09 main.py INFO 		Acc is 0.8584, F1-micro is 0.8584
Mon, 01 Sep 2025 01:54:09 main.py INFO 		F1-macro is 0.8554, AUC is 0.5000
Mon, 01 Sep 2025 01:54:09 main.py INFO 		Pre-macro is 0.8842, Rec_macro is 0.8563
Mon, 01 Sep 2025 01:54:09 main.py INFO 		For sarcasm, C_M is 
[[3616 1358]
 [  74 5064]]
Mon, 01 Sep 2025 01:54:09 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:54:09 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:54:09 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:54:09 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:54:09 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:54:09 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:54:09 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:54:09 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:54:12 main.py INFO In dataset test: Loss is [0.6862 0.4785 0.0000 0.2077]
Mon, 01 Sep 2025 01:54:12 main.py INFO 		Acc is 0.8506, F1-micro is 0.8506
Mon, 01 Sep 2025 01:54:12 main.py INFO 		F1-macro is 0.8461, AUC is 0.5000
Mon, 01 Sep 2025 01:54:12 main.py INFO 		Pre-macro is 0.8805, Rec_macro is 0.8454
Mon, 01 Sep 2025 01:54:12 main.py INFO 		For sarcasm, C_M is 
[[2760 1152]
 [  62 4154]]
Mon, 01 Sep 2025 01:54:12 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:54:12 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:54:12 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:54:12 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:54:12 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:54:12 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:54:12 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:54:12 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:54:12 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:54:20 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:54:20 main.py INFO Time of iter training 7.98 s
Mon, 01 Sep 2025 01:54:20 main.py INFO On iter step 64.0:, global step 4096 Loss-step [1.9894 1.6084 1.0000 1.2369]
Mon, 01 Sep 2025 01:54:24 main.py INFO In dataset train: Loss is [0.6765 0.4681 0.0000 0.2084]
Mon, 01 Sep 2025 01:54:24 main.py INFO 		Acc is 0.8500, F1-micro is 0.8500
Mon, 01 Sep 2025 01:54:24 main.py INFO 		F1-macro is 0.8461, AUC is 0.5000
Mon, 01 Sep 2025 01:54:24 main.py INFO 		Pre-macro is 0.8822, Rec_macro is 0.8476
Mon, 01 Sep 2025 01:54:24 main.py INFO 		For sarcasm, C_M is 
[[3495 1479]
 [  38 5100]]
Mon, 01 Sep 2025 01:54:24 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:54:24 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:54:24 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:54:24 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:54:24 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:54:24 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:54:24 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:54:24 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:54:27 main.py INFO In dataset test: Loss is [0.6832 0.4754 0.0000 0.2078]
Mon, 01 Sep 2025 01:54:27 main.py INFO 		Acc is 0.8447, F1-micro is 0.8447
Mon, 01 Sep 2025 01:54:27 main.py INFO 		F1-macro is 0.8392, AUC is 0.5000
Mon, 01 Sep 2025 01:54:27 main.py INFO 		Pre-macro is 0.8809, Rec_macro is 0.8390
Mon, 01 Sep 2025 01:54:27 main.py INFO 		For sarcasm, C_M is 
[[2679 1233]
 [  29 4187]]
Mon, 01 Sep 2025 01:54:27 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:54:27 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:54:27 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:54:27 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:54:27 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:54:27 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:54:27 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:54:27 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:54:27 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:54:34 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:54:34 main.py INFO Time of iter training 7.52 s
Mon, 01 Sep 2025 01:54:34 main.py INFO On iter step 65.0:, global step 4160 Loss-step [2.0107 1.6214 1.0000 1.2401]
Mon, 01 Sep 2025 01:54:38 main.py INFO In dataset train: Loss is [0.6781 0.4697 0.0000 0.2084]
Mon, 01 Sep 2025 01:54:38 main.py INFO 		Acc is 0.7701, F1-micro is 0.7701
Mon, 01 Sep 2025 01:54:38 main.py INFO 		F1-macro is 0.7555, AUC is 0.5000
Mon, 01 Sep 2025 01:54:38 main.py INFO 		Pre-macro is 0.8428, Rec_macro is 0.7663
Mon, 01 Sep 2025 01:54:38 main.py INFO 		For sarcasm, C_M is 
[[2658 2316]
 [   9 5129]]
Mon, 01 Sep 2025 01:54:38 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:54:38 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:54:38 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:54:38 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:54:38 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:54:38 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:54:38 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:54:38 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:54:41 main.py INFO In dataset test: Loss is [0.6825 0.4748 0.0000 0.2078]
Mon, 01 Sep 2025 01:54:41 main.py INFO 		Acc is 0.7750, F1-micro is 0.7750
Mon, 01 Sep 2025 01:54:41 main.py INFO 		F1-macro is 0.7586, AUC is 0.5000
Mon, 01 Sep 2025 01:54:41 main.py INFO 		Pre-macro is 0.8469, Rec_macro is 0.7663
Mon, 01 Sep 2025 01:54:41 main.py INFO 		For sarcasm, C_M is 
[[2092 1820]
 [   9 4207]]
Mon, 01 Sep 2025 01:54:41 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:54:41 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:54:41 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:54:41 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:54:41 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:54:41 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:54:41 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:54:41 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:54:41 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:54:49 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:54:49 main.py INFO Time of iter training 7.40 s
Mon, 01 Sep 2025 01:54:49 main.py INFO On iter step 66.0:, global step 4224 Loss-step [1.9969 1.6012 1.0000 1.2471]
Mon, 01 Sep 2025 01:54:52 main.py INFO In dataset train: Loss is [0.6778 0.4694 0.0000 0.2084]
Mon, 01 Sep 2025 01:54:52 main.py INFO 		Acc is 0.8532, F1-micro is 0.8532
Mon, 01 Sep 2025 01:54:52 main.py INFO 		F1-macro is 0.8497, AUC is 0.5000
Mon, 01 Sep 2025 01:54:52 main.py INFO 		Pre-macro is 0.8830, Rec_macro is 0.8510
Mon, 01 Sep 2025 01:54:52 main.py INFO 		For sarcasm, C_M is 
[[3541 1433]
 [  51 5087]]
Mon, 01 Sep 2025 01:54:52 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:54:52 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:54:52 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:54:52 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:54:52 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:54:52 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:54:52 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:54:52 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:54:55 main.py INFO In dataset test: Loss is [0.6823 0.4746 0.0000 0.2078]
Mon, 01 Sep 2025 01:54:55 main.py INFO 		Acc is 0.8472, F1-micro is 0.8472
Mon, 01 Sep 2025 01:54:55 main.py INFO 		F1-macro is 0.8421, AUC is 0.5000
Mon, 01 Sep 2025 01:54:55 main.py INFO 		Pre-macro is 0.8804, Rec_macro is 0.8417
Mon, 01 Sep 2025 01:54:55 main.py INFO 		For sarcasm, C_M is 
[[2715 1197]
 [  45 4171]]
Mon, 01 Sep 2025 01:54:55 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:54:55 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:54:55 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:54:55 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:54:55 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:54:55 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:54:55 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:54:55 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:54:55 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:55:02 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:55:02 main.py INFO Time of iter training 7.18 s
Mon, 01 Sep 2025 01:55:02 main.py INFO On iter step 67.0:, global step 4288 Loss-step [1.9908 1.6150 1.0000 1.2328]
Mon, 01 Sep 2025 01:55:06 main.py INFO In dataset train: Loss is [0.6773 0.4689 0.0000 0.2084]
Mon, 01 Sep 2025 01:55:06 main.py INFO 		Acc is 0.8059, F1-micro is 0.8059
Mon, 01 Sep 2025 01:55:06 main.py INFO 		F1-macro is 0.7974, AUC is 0.5000
Mon, 01 Sep 2025 01:55:06 main.py INFO 		Pre-macro is 0.8578, Rec_macro is 0.8028
Mon, 01 Sep 2025 01:55:06 main.py INFO 		For sarcasm, C_M is 
[[3041 1933]
 [  30 5108]]
Mon, 01 Sep 2025 01:55:06 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:55:06 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:55:06 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:55:06 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:55:06 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:55:06 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:55:06 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:55:06 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:55:09 main.py INFO In dataset test: Loss is [0.6830 0.4752 0.0000 0.2078]
Mon, 01 Sep 2025 01:55:09 main.py INFO 		Acc is 0.8055, F1-micro is 0.8055
Mon, 01 Sep 2025 01:55:09 main.py INFO 		F1-macro is 0.7951, AUC is 0.5000
Mon, 01 Sep 2025 01:55:09 main.py INFO 		Pre-macro is 0.8589, Rec_macro is 0.7982
Mon, 01 Sep 2025 01:55:09 main.py INFO 		For sarcasm, C_M is 
[[2359 1553]
 [  28 4188]]
Mon, 01 Sep 2025 01:55:09 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:55:09 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:55:09 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:55:09 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:55:09 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:55:09 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:55:09 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:55:09 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:55:09 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:55:18 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:55:18 main.py INFO Time of iter training 8.53 s
Mon, 01 Sep 2025 01:55:18 main.py INFO On iter step 68.0:, global step 4352 Loss-step [2.0052 1.6293 1.0000 1.2307]
Mon, 01 Sep 2025 01:55:21 main.py INFO In dataset train: Loss is [0.6781 0.4697 0.0000 0.2084]
Mon, 01 Sep 2025 01:55:21 main.py INFO 		Acc is 0.8016, F1-micro is 0.8016
Mon, 01 Sep 2025 01:55:21 main.py INFO 		F1-macro is 0.7999, AUC is 0.5000
Mon, 01 Sep 2025 01:55:21 main.py INFO 		Pre-macro is 0.8089, Rec_macro is 0.8003
Mon, 01 Sep 2025 01:55:21 main.py INFO 		For sarcasm, C_M is 
[[3589 1385]
 [ 621 4517]]
Mon, 01 Sep 2025 01:55:21 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:55:21 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:55:21 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:55:21 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:55:21 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:55:21 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:55:21 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:55:21 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:55:24 main.py INFO In dataset test: Loss is [0.6861 0.4783 0.0000 0.2078]
Mon, 01 Sep 2025 01:55:24 main.py INFO 		Acc is 0.7915, F1-micro is 0.7915
Mon, 01 Sep 2025 01:55:24 main.py INFO 		F1-macro is 0.7887, AUC is 0.5000
Mon, 01 Sep 2025 01:55:24 main.py INFO 		Pre-macro is 0.7990, Rec_macro is 0.7883
Mon, 01 Sep 2025 01:55:24 main.py INFO 		For sarcasm, C_M is 
[[2748 1164]
 [ 531 3685]]
Mon, 01 Sep 2025 01:55:24 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:55:24 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:55:24 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:55:24 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:55:24 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:55:24 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:55:24 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:55:24 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:55:24 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:55:33 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:55:33 main.py INFO Time of iter training 8.31 s
Mon, 01 Sep 2025 01:55:33 main.py INFO On iter step 69.0:, global step 4416 Loss-step [1.9940 1.6133 1.0000 1.2360]
Mon, 01 Sep 2025 01:55:36 main.py INFO In dataset train: Loss is [0.6764 0.4680 0.0000 0.2085]
Mon, 01 Sep 2025 01:55:36 main.py INFO 		Acc is 0.7866, F1-micro is 0.7866
Mon, 01 Sep 2025 01:55:36 main.py INFO 		F1-macro is 0.7754, AUC is 0.5000
Mon, 01 Sep 2025 01:55:36 main.py INFO 		Pre-macro is 0.8476, Rec_macro is 0.7832
Mon, 01 Sep 2025 01:55:36 main.py INFO 		For sarcasm, C_M is 
[[2847 2127]
 [  31 5107]]
Mon, 01 Sep 2025 01:55:36 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:55:36 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:55:36 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:55:36 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:55:36 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:55:36 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:55:36 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:55:36 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:55:39 main.py INFO In dataset test: Loss is [0.6817 0.4738 0.0000 0.2078]
Mon, 01 Sep 2025 01:55:39 main.py INFO 		Acc is 0.7880, F1-micro is 0.7880
Mon, 01 Sep 2025 01:55:39 main.py INFO 		F1-macro is 0.7749, AUC is 0.5000
Mon, 01 Sep 2025 01:55:39 main.py INFO 		Pre-macro is 0.8492, Rec_macro is 0.7801
Mon, 01 Sep 2025 01:55:39 main.py INFO 		For sarcasm, C_M is 
[[2220 1692]
 [  31 4185]]
Mon, 01 Sep 2025 01:55:39 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:55:39 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:55:39 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:55:39 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:55:39 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:55:39 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:55:39 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:55:39 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:55:39 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:55:48 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:55:48 main.py INFO Time of iter training 8.58 s
Mon, 01 Sep 2025 01:55:48 main.py INFO On iter step 70.0:, global step 4480 Loss-step [1.9576 1.5894 1.0000 1.2316]
Mon, 01 Sep 2025 01:55:52 main.py INFO In dataset train: Loss is [0.6735 0.4651 0.0000 0.2084]
Mon, 01 Sep 2025 01:55:52 main.py INFO 		Acc is 0.8396, F1-micro is 0.8396
Mon, 01 Sep 2025 01:55:52 main.py INFO 		F1-macro is 0.8350, AUC is 0.5000
Mon, 01 Sep 2025 01:55:52 main.py INFO 		Pre-macro is 0.8745, Rec_macro is 0.8371
Mon, 01 Sep 2025 01:55:52 main.py INFO 		For sarcasm, C_M is 
[[3404 1570]
 [  52 5086]]
Mon, 01 Sep 2025 01:55:52 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:55:52 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:55:52 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:55:52 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:55:52 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:55:52 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:55:52 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:55:52 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:55:55 main.py INFO In dataset test: Loss is [0.6824 0.4746 0.0000 0.2078]
Mon, 01 Sep 2025 01:55:55 main.py INFO 		Acc is 0.8326, F1-micro is 0.8326
Mon, 01 Sep 2025 01:55:55 main.py INFO 		F1-macro is 0.8262, AUC is 0.5000
Mon, 01 Sep 2025 01:55:55 main.py INFO 		Pre-macro is 0.8702, Rec_macro is 0.8266
Mon, 01 Sep 2025 01:55:55 main.py INFO 		For sarcasm, C_M is 
[[2606 1306]
 [  55 4161]]
Mon, 01 Sep 2025 01:55:55 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:55:55 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:55:55 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:55:55 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:55:55 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:55:55 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:55:55 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:55:55 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:55:55 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:56:03 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:56:03 main.py INFO Time of iter training 8.23 s
Mon, 01 Sep 2025 01:56:03 main.py INFO On iter step 71.0:, global step 4544 Loss-step [1.9732 1.6034 1.0000 1.2306]
Mon, 01 Sep 2025 01:56:07 main.py INFO In dataset train: Loss is [0.6712 0.4627 0.0000 0.2084]
Mon, 01 Sep 2025 01:56:07 main.py INFO 		Acc is 0.8225, F1-micro is 0.8225
Mon, 01 Sep 2025 01:56:07 main.py INFO 		F1-macro is 0.8157, AUC is 0.5000
Mon, 01 Sep 2025 01:56:07 main.py INFO 		Pre-macro is 0.8696, Rec_macro is 0.8196
Mon, 01 Sep 2025 01:56:07 main.py INFO 		For sarcasm, C_M is 
[[3187 1787]
 [   8 5130]]
Mon, 01 Sep 2025 01:56:07 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:56:07 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:56:07 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:56:07 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:56:07 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:56:07 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:56:07 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:56:07 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:56:10 main.py INFO In dataset test: Loss is [0.6817 0.4739 0.0000 0.2078]
Mon, 01 Sep 2025 01:56:10 main.py INFO 		Acc is 0.8178, F1-micro is 0.8178
Mon, 01 Sep 2025 01:56:10 main.py INFO 		F1-macro is 0.8088, AUC is 0.5000
Mon, 01 Sep 2025 01:56:10 main.py INFO 		Pre-macro is 0.8686, Rec_macro is 0.8108
Mon, 01 Sep 2025 01:56:10 main.py INFO 		For sarcasm, C_M is 
[[2440 1472]
 [   9 4207]]
Mon, 01 Sep 2025 01:56:10 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:56:10 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:56:10 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:56:10 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:56:10 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:56:10 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:56:10 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:56:10 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:56:10 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:56:18 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:56:18 main.py INFO Time of iter training 7.66 s
Mon, 01 Sep 2025 01:56:18 main.py INFO On iter step 72.0:, global step 4608 Loss-step [1.9858 1.6044 1.0000 1.2377]
Mon, 01 Sep 2025 01:56:21 main.py INFO In dataset train: Loss is [0.6724 0.4639 0.0000 0.2084]
Mon, 01 Sep 2025 01:56:21 main.py INFO 		Acc is 0.8456, F1-micro is 0.8456
Mon, 01 Sep 2025 01:56:21 main.py INFO 		F1-macro is 0.8413, AUC is 0.5000
Mon, 01 Sep 2025 01:56:21 main.py INFO 		Pre-macro is 0.8810, Rec_macro is 0.8432
Mon, 01 Sep 2025 01:56:21 main.py INFO 		For sarcasm, C_M is 
[[3437 1537]
 [  24 5114]]
Mon, 01 Sep 2025 01:56:21 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:56:21 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:56:21 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:56:21 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:56:21 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:56:21 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:56:21 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:56:21 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:56:24 main.py INFO In dataset test: Loss is [0.6835 0.4757 0.0000 0.2078]
Mon, 01 Sep 2025 01:56:24 main.py INFO 		Acc is 0.8376, F1-micro is 0.8376
Mon, 01 Sep 2025 01:56:24 main.py INFO 		F1-macro is 0.8312, AUC is 0.5000
Mon, 01 Sep 2025 01:56:24 main.py INFO 		Pre-macro is 0.8777, Rec_macro is 0.8315
Mon, 01 Sep 2025 01:56:24 main.py INFO 		For sarcasm, C_M is 
[[2614 1298]
 [  22 4194]]
Mon, 01 Sep 2025 01:56:24 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:56:24 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:56:24 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:56:24 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:56:24 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:56:24 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:56:24 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:56:24 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:56:24 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:56:32 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:56:32 main.py INFO Time of iter training 7.48 s
Mon, 01 Sep 2025 01:56:32 main.py INFO On iter step 73.0:, global step 4672 Loss-step [1.9673 1.5852 1.0000 1.2410]
Mon, 01 Sep 2025 01:56:36 main.py INFO In dataset train: Loss is [0.6739 0.4655 0.0000 0.2084]
Mon, 01 Sep 2025 01:56:36 main.py INFO 		Acc is 0.8610, F1-micro is 0.8610
Mon, 01 Sep 2025 01:56:36 main.py INFO 		F1-macro is 0.8579, AUC is 0.5000
Mon, 01 Sep 2025 01:56:36 main.py INFO 		Pre-macro is 0.8883, Rec_macro is 0.8588
Mon, 01 Sep 2025 01:56:36 main.py INFO 		For sarcasm, C_M is 
[[3614 1360]
 [  46 5092]]
Mon, 01 Sep 2025 01:56:36 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:56:36 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:56:36 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:56:36 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:56:36 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:56:36 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:56:36 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:56:36 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:56:39 main.py INFO In dataset test: Loss is [0.6841 0.4764 0.0000 0.2077]
Mon, 01 Sep 2025 01:56:39 main.py INFO 		Acc is 0.8530, F1-micro is 0.8530
Mon, 01 Sep 2025 01:56:39 main.py INFO 		F1-macro is 0.8484, AUC is 0.5000
Mon, 01 Sep 2025 01:56:39 main.py INFO 		Pre-macro is 0.8842, Rec_macro is 0.8477
Mon, 01 Sep 2025 01:56:39 main.py INFO 		For sarcasm, C_M is 
[[2760 1152]
 [  43 4173]]
Mon, 01 Sep 2025 01:56:39 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:56:39 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:56:39 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:56:39 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:56:39 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:56:39 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:56:39 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:56:39 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:56:39 main.py INFO testacc: 0.8590
Mon, 01 Sep 2025 01:56:47 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 01:56:47 main.py INFO Time of iter training 8.52 s
Mon, 01 Sep 2025 01:56:47 main.py INFO On iter step 74.0:, global step 4736 Loss-step [1.9919 1.6116 1.0000 1.2360]
Mon, 01 Sep 2025 01:56:51 main.py INFO In dataset train: Loss is [0.6766 0.4682 0.0000 0.2084]
Mon, 01 Sep 2025 01:56:51 main.py INFO 		Acc is 0.8169, F1-micro is 0.8169
Mon, 01 Sep 2025 01:56:51 main.py INFO 		F1-macro is 0.8097, AUC is 0.5000
Mon, 01 Sep 2025 01:56:51 main.py INFO 		Pre-macro is 0.8644, Rec_macro is 0.8139
Mon, 01 Sep 2025 01:56:51 main.py INFO 		For sarcasm, C_M is 
[[3147 1827]
 [  25 5113]]
Mon, 01 Sep 2025 01:56:51 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:56:51 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:56:51 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:56:51 main.py INFO 		For literal, C_M is 
[[2673    0]
 [   0 7439]]
Mon, 01 Sep 2025 01:56:51 main.py INFO 		Acc is 0.8538, F1-micro is 0.8538
Mon, 01 Sep 2025 01:56:51 main.py INFO 		F1-macro is 0.8506, AUC is 0.5000
Mon, 01 Sep 2025 01:56:51 main.py INFO 		Pre-macro is 0.8870, Rec_macro is 0.8538
Mon, 01 Sep 2025 01:56:51 main.py INFO 		For deep, C_M is 
[[3575 1478]
 [   0 5059]]
Mon, 01 Sep 2025 01:56:54 main.py INFO In dataset test: Loss is [0.6821 0.4744 0.0000 0.2078]
Mon, 01 Sep 2025 01:56:54 main.py INFO 		Acc is 0.8121, F1-micro is 0.8121
Mon, 01 Sep 2025 01:56:54 main.py INFO 		F1-macro is 0.8025, AUC is 0.5000
Mon, 01 Sep 2025 01:56:54 main.py INFO 		Pre-macro is 0.8644, Rec_macro is 0.8050
Mon, 01 Sep 2025 01:56:54 main.py INFO 		For sarcasm, C_M is 
[[2401 1511]
 [  16 4200]]
Mon, 01 Sep 2025 01:56:54 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 01:56:54 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 01:56:54 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 01:56:54 main.py INFO 		For literal, C_M is 
[[2232    0]
 [   0 5896]]
Mon, 01 Sep 2025 01:56:54 main.py INFO 		Acc is 0.8531, F1-micro is 0.8531
Mon, 01 Sep 2025 01:56:54 main.py INFO 		F1-macro is 0.8505, AUC is 0.5000
Mon, 01 Sep 2025 01:56:54 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8554
Mon, 01 Sep 2025 01:56:54 main.py INFO 		For deep, C_M is 
[[2936 1194]
 [   0 3998]]
Mon, 01 Sep 2025 01:56:54 main.py INFO testacc: 0.8590
