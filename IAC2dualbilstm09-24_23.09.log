Wed, 24 Sep 2025 23:11:44 dataUtils.py INFO 构建词汇表...
Wed, 24 Sep 2025 23:11:44 main.py INFO model parameters: Namespace(batch_size=128, bidirectional=1, breakpoint=-1, cell_dropout_rate=0.5, data_dir='./IAC2/spacy/', device=device(type='cuda'), dim_bert=768, dim_hidden=256, dim_input=300, embed_dropout_rate=0.5, final_dropout_rate=0.5, iter_num=4800, lambda1=0.5, learning_rate=0.001, linear_dropout_rate=0.1, lr_bert=5e-05, lr_word_vector=0.0001, margin=0.5, max_length_sen=100, model_dir='models/IAC2_dualbilstm/', multi_dim=20, n_class=2, n_layers=3, name_dataset='IAC2', name_model='dualbilstm', optim_type='Adam', path_wordvec='glove.840B.300d.txt', per_checkpoint=64, predict=0, predict_dir='./predict/', rnn_type='LSTM', save_model=0, seed=2021, supcon=1, t_sne=0, tokenizer='spacy', voc_size=30000, weight_decay=0)
Wed, 24 Sep 2025 23:11:44 main.py INFO Use device: cuda
Wed, 24 Sep 2025 23:11:45 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:11:45 main.py INFO Time of iter training 0.00 s
Wed, 24 Sep 2025 23:11:45 main.py INFO On iter step 0.0:, global step 0 Loss-step [2.7183 2.7183 2.7183 2.7183]
Wed, 24 Sep 2025 23:11:49 main.py INFO In dataset train: Loss is [2.0857 0.6949 0.6959 0.6949]
Wed, 24 Sep 2025 23:11:49 main.py INFO 		Acc is 0.4971, F1-micro is 0.4971
Wed, 24 Sep 2025 23:11:49 main.py INFO 		F1-macro is 0.3364, AUC is 0.5000
Wed, 24 Sep 2025 23:11:49 main.py INFO 		Pre-macro is 0.4078, Rec_macro is 0.4971
Wed, 24 Sep 2025 23:11:49 main.py INFO 		For sarcasm, C_M is 
[[  13 2595]
 [  28 2580]]
Wed, 24 Sep 2025 23:11:49 main.py INFO 		Acc is 0.2929, F1-micro is 0.2929
Wed, 24 Sep 2025 23:11:49 main.py INFO 		F1-macro is 0.2266, AUC is 0.5000
Wed, 24 Sep 2025 23:11:49 main.py INFO 		Pre-macro is 0.1465, Rec_macro is 0.5000
Wed, 24 Sep 2025 23:11:49 main.py INFO 		For literal, C_M is 
[[1528    0]
 [3688    0]]
Wed, 24 Sep 2025 23:11:49 main.py INFO 		Acc is 0.4889, F1-micro is 0.4889
Wed, 24 Sep 2025 23:11:49 main.py INFO 		F1-macro is 0.3284, AUC is 0.5000
Wed, 24 Sep 2025 23:11:49 main.py INFO 		Pre-macro is 0.2444, Rec_macro is 0.5000
Wed, 24 Sep 2025 23:11:49 main.py INFO 		For deep, C_M is 
[[2550    0]
 [2666    0]]
Wed, 24 Sep 2025 23:11:49 main.py INFO In dataset test: Loss is [2.0847 0.6941 0.6962 0.6944]
Wed, 24 Sep 2025 23:11:49 main.py INFO 		Acc is 0.4976, F1-micro is 0.4976
Wed, 24 Sep 2025 23:11:49 main.py INFO 		F1-macro is 0.3373, AUC is 0.5000
Wed, 24 Sep 2025 23:11:49 main.py INFO 		Pre-macro is 0.4162, Rec_macro is 0.4971
Wed, 24 Sep 2025 23:11:49 main.py INFO 		For sarcasm, C_M is 
[[  3 518]
 [  6 516]]
Wed, 24 Sep 2025 23:11:49 main.py INFO 		Acc is 0.2713, F1-micro is 0.2713
Wed, 24 Sep 2025 23:11:49 main.py INFO 		F1-macro is 0.2134, AUC is 0.5000
Wed, 24 Sep 2025 23:11:49 main.py INFO 		Pre-macro is 0.1357, Rec_macro is 0.5000
Wed, 24 Sep 2025 23:11:49 main.py INFO 		For literal, C_M is 
[[283   0]
 [760   0]]
Wed, 24 Sep 2025 23:11:49 main.py INFO 		Acc is 0.4976, F1-micro is 0.4976
Wed, 24 Sep 2025 23:11:49 main.py INFO 		F1-macro is 0.3323, AUC is 0.5000
Wed, 24 Sep 2025 23:11:49 main.py INFO 		Pre-macro is 0.2488, Rec_macro is 0.5000
Wed, 24 Sep 2025 23:11:49 main.py INFO 		For deep, C_M is 
[[519   0]
 [524   0]]
Wed, 24 Sep 2025 23:11:49 main.py INFO testacc: 0.4976
Wed, 24 Sep 2025 23:12:06 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:12:06 main.py INFO Time of iter training 16.10 s
Wed, 24 Sep 2025 23:12:06 main.py INFO On iter step 1.0:, global step 64 Loss-step [2.4053 1.7693 1.1016 1.2341]
Wed, 24 Sep 2025 23:12:09 main.py INFO In dataset train: Loss is [0.5859 0.4660 0.0001 0.1198]
Wed, 24 Sep 2025 23:12:09 main.py INFO 		Acc is 0.8083, F1-micro is 0.8083
Wed, 24 Sep 2025 23:12:09 main.py INFO 		F1-macro is 0.8082, AUC is 0.5000
Wed, 24 Sep 2025 23:12:09 main.py INFO 		Pre-macro is 0.8086, Rec_macro is 0.8083
Wed, 24 Sep 2025 23:12:09 main.py INFO 		For sarcasm, C_M is 
[[2066  542]
 [ 458 2150]]
Wed, 24 Sep 2025 23:12:09 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:12:09 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:12:09 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:12:09 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:12:09 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:12:09 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:12:09 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:12:09 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:12:10 main.py INFO In dataset test: Loss is [0.5813 0.4702 0.0001 0.1110]
Wed, 24 Sep 2025 23:12:10 main.py INFO 		Acc is 0.7996, F1-micro is 0.7996
Wed, 24 Sep 2025 23:12:10 main.py INFO 		F1-macro is 0.7995, AUC is 0.5000
Wed, 24 Sep 2025 23:12:10 main.py INFO 		Pre-macro is 0.8000, Rec_macro is 0.7996
Wed, 24 Sep 2025 23:12:10 main.py INFO 		For sarcasm, C_M is 
[[407 114]
 [ 95 427]]
Wed, 24 Sep 2025 23:12:10 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:12:10 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:12:10 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:12:10 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:12:10 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:12:10 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:12:10 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:12:10 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:12:10 main.py INFO testacc: 0.7996
Wed, 24 Sep 2025 23:12:26 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:12:26 main.py INFO Time of iter training 15.60 s
Wed, 24 Sep 2025 23:12:26 main.py INFO On iter step 2.0:, global step 128 Loss-step [1.8287 1.6193 1.0001 1.1293]
Wed, 24 Sep 2025 23:12:29 main.py INFO In dataset train: Loss is [0.5865 0.4659 0.0001 0.1205]
Wed, 24 Sep 2025 23:12:29 main.py INFO 		Acc is 0.8466, F1-micro is 0.8466
Wed, 24 Sep 2025 23:12:29 main.py INFO 		F1-macro is 0.8465, AUC is 0.5000
Wed, 24 Sep 2025 23:12:29 main.py INFO 		Pre-macro is 0.8476, Rec_macro is 0.8466
Wed, 24 Sep 2025 23:12:29 main.py INFO 		For sarcasm, C_M is 
[[2140  468]
 [ 332 2276]]
Wed, 24 Sep 2025 23:12:29 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:12:29 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:12:29 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:12:29 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:12:29 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:12:29 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:12:29 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:12:29 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:12:30 main.py INFO In dataset test: Loss is [0.5985 0.4872 0.0001 0.1112]
Wed, 24 Sep 2025 23:12:30 main.py INFO 		Acc is 0.8265, F1-micro is 0.8265
Wed, 24 Sep 2025 23:12:30 main.py INFO 		F1-macro is 0.8264, AUC is 0.5000
Wed, 24 Sep 2025 23:12:30 main.py INFO 		Pre-macro is 0.8272, Rec_macro is 0.8264
Wed, 24 Sep 2025 23:12:30 main.py INFO 		For sarcasm, C_M is 
[[418 103]
 [ 78 444]]
Wed, 24 Sep 2025 23:12:30 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:12:30 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:12:30 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:12:30 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:12:30 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:12:30 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:12:30 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:12:30 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:12:30 main.py INFO testacc: 0.8265
Wed, 24 Sep 2025 23:12:46 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:12:46 main.py INFO Time of iter training 15.45 s
Wed, 24 Sep 2025 23:12:46 main.py INFO On iter step 3.0:, global step 192 Loss-step [1.8286 1.6210 1.0002 1.1279]
Wed, 24 Sep 2025 23:12:49 main.py INFO In dataset train: Loss is [0.5476 0.4279 0.0001 0.1196]
Wed, 24 Sep 2025 23:12:49 main.py INFO 		Acc is 0.8436, F1-micro is 0.8436
Wed, 24 Sep 2025 23:12:49 main.py INFO 		F1-macro is 0.8433, AUC is 0.5000
Wed, 24 Sep 2025 23:12:49 main.py INFO 		Pre-macro is 0.8461, Rec_macro is 0.8436
Wed, 24 Sep 2025 23:12:49 main.py INFO 		For sarcasm, C_M is 
[[2312  296]
 [ 520 2088]]
Wed, 24 Sep 2025 23:12:49 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:12:49 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:12:49 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:12:49 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:12:49 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:12:49 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:12:49 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:12:49 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:12:50 main.py INFO In dataset test: Loss is [0.5636 0.4523 0.0001 0.1112]
Wed, 24 Sep 2025 23:12:50 main.py INFO 		Acc is 0.8207, F1-micro is 0.8207
Wed, 24 Sep 2025 23:12:50 main.py INFO 		F1-macro is 0.8204, AUC is 0.5000
Wed, 24 Sep 2025 23:12:50 main.py INFO 		Pre-macro is 0.8227, Rec_macro is 0.8207
Wed, 24 Sep 2025 23:12:50 main.py INFO 		For sarcasm, C_M is 
[[448  73]
 [114 408]]
Wed, 24 Sep 2025 23:12:50 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:12:50 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:12:50 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:12:50 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:12:50 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:12:50 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:12:50 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:12:50 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:12:50 main.py INFO testacc: 0.8265
Wed, 24 Sep 2025 23:13:06 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:13:06 main.py INFO Time of iter training 15.36 s
Wed, 24 Sep 2025 23:13:06 main.py INFO On iter step 4.0:, global step 256 Loss-step [1.7484 1.5497 1.0001 1.1282]
Wed, 24 Sep 2025 23:13:09 main.py INFO In dataset train: Loss is [0.5062 0.3867 0.0000 0.1194]
Wed, 24 Sep 2025 23:13:09 main.py INFO 		Acc is 0.8723, F1-micro is 0.8723
Wed, 24 Sep 2025 23:13:09 main.py INFO 		F1-macro is 0.8722, AUC is 0.5000
Wed, 24 Sep 2025 23:13:09 main.py INFO 		Pre-macro is 0.8734, Rec_macro is 0.8723
Wed, 24 Sep 2025 23:13:09 main.py INFO 		For sarcasm, C_M is 
[[2344  264]
 [ 402 2206]]
Wed, 24 Sep 2025 23:13:09 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:13:09 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:13:09 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:13:09 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:13:09 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:13:09 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:13:09 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:13:09 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:13:10 main.py INFO In dataset test: Loss is [0.5611 0.4505 0.0000 0.1106]
Wed, 24 Sep 2025 23:13:10 main.py INFO 		Acc is 0.8428, F1-micro is 0.8428
Wed, 24 Sep 2025 23:13:10 main.py INFO 		F1-macro is 0.8427, AUC is 0.5000
Wed, 24 Sep 2025 23:13:10 main.py INFO 		Pre-macro is 0.8434, Rec_macro is 0.8428
Wed, 24 Sep 2025 23:13:10 main.py INFO 		For sarcasm, C_M is 
[[450  71]
 [ 93 429]]
Wed, 24 Sep 2025 23:13:10 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:13:10 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:13:10 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:13:10 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:13:10 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:13:10 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:13:10 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:13:10 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:13:10 main.py INFO testacc: 0.8428
Wed, 24 Sep 2025 23:13:26 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:13:26 main.py INFO Time of iter training 15.66 s
Wed, 24 Sep 2025 23:13:26 main.py INFO On iter step 5.0:, global step 320 Loss-step [1.7240 1.5285 1.0001 1.1278]
Wed, 24 Sep 2025 23:13:29 main.py INFO In dataset train: Loss is [0.4893 0.3693 0.0001 0.1198]
Wed, 24 Sep 2025 23:13:29 main.py INFO 		Acc is 0.8786, F1-micro is 0.8786
Wed, 24 Sep 2025 23:13:29 main.py INFO 		F1-macro is 0.8786, AUC is 0.5000
Wed, 24 Sep 2025 23:13:29 main.py INFO 		Pre-macro is 0.8789, Rec_macro is 0.8786
Wed, 24 Sep 2025 23:13:29 main.py INFO 		For sarcasm, C_M is 
[[2326  282]
 [ 351 2257]]
Wed, 24 Sep 2025 23:13:29 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:13:29 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:13:29 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:13:29 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:13:29 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:13:29 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:13:29 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:13:29 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:13:30 main.py INFO In dataset test: Loss is [0.5415 0.4300 0.0001 0.1114]
Wed, 24 Sep 2025 23:13:30 main.py INFO 		Acc is 0.8408, F1-micro is 0.8408
Wed, 24 Sep 2025 23:13:30 main.py INFO 		F1-macro is 0.8408, AUC is 0.5000
Wed, 24 Sep 2025 23:13:30 main.py INFO 		Pre-macro is 0.8413, Rec_macro is 0.8409
Wed, 24 Sep 2025 23:13:30 main.py INFO 		For sarcasm, C_M is 
[[448  73]
 [ 93 429]]
Wed, 24 Sep 2025 23:13:30 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:13:30 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:13:30 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:13:30 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:13:30 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:13:30 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:13:30 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:13:30 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:13:30 main.py INFO testacc: 0.8428
Wed, 24 Sep 2025 23:13:46 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:13:46 main.py INFO Time of iter training 15.34 s
Wed, 24 Sep 2025 23:13:46 main.py INFO On iter step 6.0:, global step 384 Loss-step [1.6733 1.4832 1.0001 1.1281]
Wed, 24 Sep 2025 23:13:49 main.py INFO In dataset train: Loss is [0.4354 0.3158 0.0000 0.1195]
Wed, 24 Sep 2025 23:13:49 main.py INFO 		Acc is 0.9107, F1-micro is 0.9107
Wed, 24 Sep 2025 23:13:49 main.py INFO 		F1-macro is 0.9107, AUC is 0.5000
Wed, 24 Sep 2025 23:13:49 main.py INFO 		Pre-macro is 0.9107, Rec_macro is 0.9107
Wed, 24 Sep 2025 23:13:49 main.py INFO 		For sarcasm, C_M is 
[[2384  224]
 [ 242 2366]]
Wed, 24 Sep 2025 23:13:49 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:13:49 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:13:49 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:13:49 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:13:49 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:13:49 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:13:49 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:13:49 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:13:50 main.py INFO In dataset test: Loss is [0.5272 0.4166 0.0000 0.1106]
Wed, 24 Sep 2025 23:13:50 main.py INFO 		Acc is 0.8600, F1-micro is 0.8600
Wed, 24 Sep 2025 23:13:50 main.py INFO 		F1-macro is 0.8600, AUC is 0.5000
Wed, 24 Sep 2025 23:13:50 main.py INFO 		Pre-macro is 0.8601, Rec_macro is 0.8600
Wed, 24 Sep 2025 23:13:50 main.py INFO 		For sarcasm, C_M is 
[[453  68]
 [ 78 444]]
Wed, 24 Sep 2025 23:13:50 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:13:50 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:13:50 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:13:50 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:13:50 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:13:50 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:13:50 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:13:50 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:13:50 main.py INFO testacc: 0.8600
Wed, 24 Sep 2025 23:14:06 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:14:06 main.py INFO Time of iter training 15.44 s
Wed, 24 Sep 2025 23:14:06 main.py INFO On iter step 7.0:, global step 448 Loss-step [1.6469 1.4619 1.0001 1.1264]
Wed, 24 Sep 2025 23:14:09 main.py INFO In dataset train: Loss is [0.4287 0.3089 0.0001 0.1197]
Wed, 24 Sep 2025 23:14:09 main.py INFO 		Acc is 0.9030, F1-micro is 0.9030
Wed, 24 Sep 2025 23:14:09 main.py INFO 		F1-macro is 0.9027, AUC is 0.5000
Wed, 24 Sep 2025 23:14:09 main.py INFO 		Pre-macro is 0.9082, Rec_macro is 0.9030
Wed, 24 Sep 2025 23:14:09 main.py INFO 		For sarcasm, C_M is 
[[2208  400]
 [ 106 2502]]
Wed, 24 Sep 2025 23:14:09 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:14:09 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:14:09 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:14:09 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:14:09 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:14:09 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:14:09 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:14:09 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:14:10 main.py INFO In dataset test: Loss is [0.5540 0.4427 0.0001 0.1113]
Wed, 24 Sep 2025 23:14:10 main.py INFO 		Acc is 0.8466, F1-micro is 0.8466
Wed, 24 Sep 2025 23:14:10 main.py INFO 		F1-macro is 0.8456, AUC is 0.5000
Wed, 24 Sep 2025 23:14:10 main.py INFO 		Pre-macro is 0.8559, Rec_macro is 0.8465
Wed, 24 Sep 2025 23:14:10 main.py INFO 		For sarcasm, C_M is 
[[399 122]
 [ 38 484]]
Wed, 24 Sep 2025 23:14:10 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:14:10 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:14:10 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:14:10 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:14:10 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:14:10 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:14:10 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:14:10 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:14:10 main.py INFO testacc: 0.8600
Wed, 24 Sep 2025 23:14:25 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:14:25 main.py INFO Time of iter training 15.35 s
Wed, 24 Sep 2025 23:14:25 main.py INFO On iter step 8.0:, global step 512 Loss-step [1.6037 1.4209 1.0001 1.1286]
Wed, 24 Sep 2025 23:14:29 main.py INFO In dataset train: Loss is [0.4141 0.2945 0.0001 0.1195]
Wed, 24 Sep 2025 23:14:29 main.py INFO 		Acc is 0.9022, F1-micro is 0.9022
Wed, 24 Sep 2025 23:14:29 main.py INFO 		F1-macro is 0.9020, AUC is 0.5000
Wed, 24 Sep 2025 23:14:29 main.py INFO 		Pre-macro is 0.9053, Rec_macro is 0.9022
Wed, 24 Sep 2025 23:14:29 main.py INFO 		For sarcasm, C_M is 
[[2466  142]
 [ 368 2240]]
Wed, 24 Sep 2025 23:14:29 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:14:29 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:14:29 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:14:29 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:14:29 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:14:29 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:14:29 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:14:29 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:14:30 main.py INFO In dataset test: Loss is [0.5125 0.4017 0.0001 0.1106]
Wed, 24 Sep 2025 23:14:30 main.py INFO 		Acc is 0.8514, F1-micro is 0.8514
Wed, 24 Sep 2025 23:14:30 main.py INFO 		F1-macro is 0.8510, AUC is 0.5000
Wed, 24 Sep 2025 23:14:30 main.py INFO 		Pre-macro is 0.8548, Rec_macro is 0.8514
Wed, 24 Sep 2025 23:14:30 main.py INFO 		For sarcasm, C_M is 
[[469  52]
 [103 419]]
Wed, 24 Sep 2025 23:14:30 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:14:30 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:14:30 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:14:30 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:14:30 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:14:30 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:14:30 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:14:30 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:14:30 main.py INFO testacc: 0.8600
Wed, 24 Sep 2025 23:14:45 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:14:45 main.py INFO Time of iter training 15.47 s
Wed, 24 Sep 2025 23:14:45 main.py INFO On iter step 9.0:, global step 576 Loss-step [1.5417 1.3672 1.0001 1.1275]
Wed, 24 Sep 2025 23:14:49 main.py INFO In dataset train: Loss is [0.3332 0.2138 0.0001 0.1193]
Wed, 24 Sep 2025 23:14:49 main.py INFO 		Acc is 0.9339, F1-micro is 0.9339
Wed, 24 Sep 2025 23:14:49 main.py INFO 		F1-macro is 0.9338, AUC is 0.5000
Wed, 24 Sep 2025 23:14:49 main.py INFO 		Pre-macro is 0.9345, Rec_macro is 0.9339
Wed, 24 Sep 2025 23:14:49 main.py INFO 		For sarcasm, C_M is 
[[2485  123]
 [ 222 2386]]
Wed, 24 Sep 2025 23:14:49 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:14:49 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:14:49 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:14:49 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:14:49 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:14:49 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:14:49 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:14:49 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:14:50 main.py INFO In dataset test: Loss is [0.6267 0.5159 0.0001 0.1107]
Wed, 24 Sep 2025 23:14:50 main.py INFO 		Acc is 0.8696, F1-micro is 0.8696
Wed, 24 Sep 2025 23:14:50 main.py INFO 		F1-macro is 0.8696, AUC is 0.5000
Wed, 24 Sep 2025 23:14:50 main.py INFO 		Pre-macro is 0.8703, Rec_macro is 0.8696
Wed, 24 Sep 2025 23:14:50 main.py INFO 		For sarcasm, C_M is 
[[464  57]
 [ 79 443]]
Wed, 24 Sep 2025 23:14:50 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:14:50 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:14:50 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:14:50 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:14:50 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:14:50 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:14:50 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:14:50 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:14:50 main.py INFO testacc: 0.8696
Wed, 24 Sep 2025 23:15:05 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:15:05 main.py INFO Time of iter training 15.46 s
Wed, 24 Sep 2025 23:15:05 main.py INFO On iter step 10.0:, global step 640 Loss-step [1.5197 1.3488 1.0003 1.1264]
Wed, 24 Sep 2025 23:15:09 main.py INFO In dataset train: Loss is [0.3690 0.2494 0.0002 0.1194]
Wed, 24 Sep 2025 23:15:09 main.py INFO 		Acc is 0.9022, F1-micro is 0.9022
Wed, 24 Sep 2025 23:15:09 main.py INFO 		F1-macro is 0.9018, AUC is 0.5000
Wed, 24 Sep 2025 23:15:09 main.py INFO 		Pre-macro is 0.9099, Rec_macro is 0.9022
Wed, 24 Sep 2025 23:15:09 main.py INFO 		For sarcasm, C_M is 
[[2532   76]
 [ 434 2174]]
Wed, 24 Sep 2025 23:15:09 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:15:09 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:15:09 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:15:09 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:15:09 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:15:09 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:15:09 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:15:09 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:15:10 main.py INFO In dataset test: Loss is [0.5153 0.4045 0.0002 0.1106]
Wed, 24 Sep 2025 23:15:10 main.py INFO 		Acc is 0.8399, F1-micro is 0.8399
Wed, 24 Sep 2025 23:15:10 main.py INFO 		F1-macro is 0.8386, AUC is 0.5000
Wed, 24 Sep 2025 23:15:10 main.py INFO 		Pre-macro is 0.8510, Rec_macro is 0.8400
Wed, 24 Sep 2025 23:15:10 main.py INFO 		For sarcasm, C_M is 
[[484  37]
 [130 392]]
Wed, 24 Sep 2025 23:15:10 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:15:10 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:15:10 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:15:10 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:15:10 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:15:10 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:15:10 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:15:10 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:15:10 main.py INFO testacc: 0.8696
Wed, 24 Sep 2025 23:15:25 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:15:25 main.py INFO Time of iter training 15.26 s
Wed, 24 Sep 2025 23:15:25 main.py INFO On iter step 11.0:, global step 704 Loss-step [1.4762 1.3075 1.0003 1.1287]
Wed, 24 Sep 2025 23:15:29 main.py INFO In dataset train: Loss is [0.2829 0.1635 0.0001 0.1194]
Wed, 24 Sep 2025 23:15:29 main.py INFO 		Acc is 0.9576, F1-micro is 0.9576
Wed, 24 Sep 2025 23:15:29 main.py INFO 		F1-macro is 0.9576, AUC is 0.5000
Wed, 24 Sep 2025 23:15:29 main.py INFO 		Pre-macro is 0.9578, Rec_macro is 0.9576
Wed, 24 Sep 2025 23:15:29 main.py INFO 		For sarcasm, C_M is 
[[2475  133]
 [  88 2520]]
Wed, 24 Sep 2025 23:15:29 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:15:29 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:15:29 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:15:29 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:15:29 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:15:29 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:15:29 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:15:29 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:15:30 main.py INFO In dataset test: Loss is [0.6571 0.5464 0.0001 0.1106]
Wed, 24 Sep 2025 23:15:30 main.py INFO 		Acc is 0.8811, F1-micro is 0.8811
Wed, 24 Sep 2025 23:15:30 main.py INFO 		F1-macro is 0.8811, AUC is 0.5000
Wed, 24 Sep 2025 23:15:30 main.py INFO 		Pre-macro is 0.8813, Rec_macro is 0.8811
Wed, 24 Sep 2025 23:15:30 main.py INFO 		For sarcasm, C_M is 
[[453  68]
 [ 56 466]]
Wed, 24 Sep 2025 23:15:30 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:15:30 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:15:30 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:15:30 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:15:30 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:15:30 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:15:30 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:15:30 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:15:30 main.py INFO testacc: 0.8811
Wed, 24 Sep 2025 23:15:45 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:15:45 main.py INFO Time of iter training 15.71 s
Wed, 24 Sep 2025 23:15:45 main.py INFO On iter step 12.0:, global step 768 Loss-step [1.4539 1.2899 1.0004 1.1267]
Wed, 24 Sep 2025 23:15:49 main.py INFO In dataset train: Loss is [0.2909 0.1714 0.0002 0.1193]
Wed, 24 Sep 2025 23:15:49 main.py INFO 		Acc is 0.9360, F1-micro is 0.9360
Wed, 24 Sep 2025 23:15:49 main.py INFO 		F1-macro is 0.9359, AUC is 0.5000
Wed, 24 Sep 2025 23:15:49 main.py INFO 		Pre-macro is 0.9387, Rec_macro is 0.9360
Wed, 24 Sep 2025 23:15:49 main.py INFO 		For sarcasm, C_M is 
[[2544   64]
 [ 270 2338]]
Wed, 24 Sep 2025 23:15:49 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:15:49 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:15:49 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:15:49 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:15:49 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:15:49 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:15:49 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:15:49 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:15:50 main.py INFO In dataset test: Loss is [0.5872 0.4765 0.0002 0.1106]
Wed, 24 Sep 2025 23:15:50 main.py INFO 		Acc is 0.8466, F1-micro is 0.8466
Wed, 24 Sep 2025 23:15:50 main.py INFO 		F1-macro is 0.8461, AUC is 0.5000
Wed, 24 Sep 2025 23:15:50 main.py INFO 		Pre-macro is 0.8512, Rec_macro is 0.8467
Wed, 24 Sep 2025 23:15:50 main.py INFO 		For sarcasm, C_M is 
[[471  50]
 [110 412]]
Wed, 24 Sep 2025 23:15:50 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:15:50 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:15:50 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:15:50 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:15:50 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:15:50 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:15:50 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:15:50 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:15:50 main.py INFO testacc: 0.8811
Wed, 24 Sep 2025 23:16:05 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:16:05 main.py INFO Time of iter training 15.29 s
Wed, 24 Sep 2025 23:16:05 main.py INFO On iter step 13.0:, global step 832 Loss-step [1.4338 1.2711 1.0001 1.1278]
Wed, 24 Sep 2025 23:16:09 main.py INFO In dataset train: Loss is [0.2404 0.1208 0.0001 0.1194]
Wed, 24 Sep 2025 23:16:09 main.py INFO 		Acc is 0.9634, F1-micro is 0.9634
Wed, 24 Sep 2025 23:16:09 main.py INFO 		F1-macro is 0.9634, AUC is 0.5000
Wed, 24 Sep 2025 23:16:09 main.py INFO 		Pre-macro is 0.9637, Rec_macro is 0.9634
Wed, 24 Sep 2025 23:16:09 main.py INFO 		For sarcasm, C_M is 
[[2477  131]
 [  60 2548]]
Wed, 24 Sep 2025 23:16:09 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:16:09 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:16:09 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:16:09 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:16:09 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:16:09 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:16:09 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:16:09 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:16:10 main.py INFO In dataset test: Loss is [0.6102 0.4994 0.0001 0.1106]
Wed, 24 Sep 2025 23:16:10 main.py INFO 		Acc is 0.8706, F1-micro is 0.8706
Wed, 24 Sep 2025 23:16:10 main.py INFO 		F1-macro is 0.8704, AUC is 0.5000
Wed, 24 Sep 2025 23:16:10 main.py INFO 		Pre-macro is 0.8727, Rec_macro is 0.8705
Wed, 24 Sep 2025 23:16:10 main.py INFO 		For sarcasm, C_M is 
[[434  87]
 [ 48 474]]
Wed, 24 Sep 2025 23:16:10 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:16:10 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:16:10 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:16:10 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:16:10 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:16:10 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:16:10 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:16:10 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:16:10 main.py INFO testacc: 0.8811
Wed, 24 Sep 2025 23:16:25 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:16:25 main.py INFO Time of iter training 15.39 s
Wed, 24 Sep 2025 23:16:25 main.py INFO On iter step 14.0:, global step 896 Loss-step [1.4054 1.2477 1.0001 1.1262]
Wed, 24 Sep 2025 23:16:29 main.py INFO In dataset train: Loss is [0.2305 0.1111 0.0001 0.1193]
Wed, 24 Sep 2025 23:16:29 main.py INFO 		Acc is 0.9659, F1-micro is 0.9659
Wed, 24 Sep 2025 23:16:29 main.py INFO 		F1-macro is 0.9659, AUC is 0.5000
Wed, 24 Sep 2025 23:16:29 main.py INFO 		Pre-macro is 0.9663, Rec_macro is 0.9659
Wed, 24 Sep 2025 23:16:29 main.py INFO 		For sarcasm, C_M is 
[[2481  127]
 [  51 2557]]
Wed, 24 Sep 2025 23:16:29 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:16:29 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:16:29 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:16:29 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:16:29 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:16:29 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:16:29 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:16:29 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:16:29 main.py INFO In dataset test: Loss is [0.5822 0.4714 0.0001 0.1107]
Wed, 24 Sep 2025 23:16:29 main.py INFO 		Acc is 0.8648, F1-micro is 0.8648
Wed, 24 Sep 2025 23:16:29 main.py INFO 		F1-macro is 0.8647, AUC is 0.5000
Wed, 24 Sep 2025 23:16:29 main.py INFO 		Pre-macro is 0.8663, Rec_macro is 0.8648
Wed, 24 Sep 2025 23:16:29 main.py INFO 		For sarcasm, C_M is 
[[434  87]
 [ 54 468]]
Wed, 24 Sep 2025 23:16:29 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:16:29 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:16:29 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:16:29 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:16:29 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:16:29 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:16:29 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:16:29 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:16:29 main.py INFO testacc: 0.8811
Wed, 24 Sep 2025 23:16:45 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:16:45 main.py INFO Time of iter training 15.35 s
Wed, 24 Sep 2025 23:16:45 main.py INFO On iter step 15.0:, global step 960 Loss-step [1.3427 1.1897 1.0001 1.1286]
Wed, 24 Sep 2025 23:16:48 main.py INFO In dataset train: Loss is [0.2117 0.0923 0.0001 0.1194]
Wed, 24 Sep 2025 23:16:48 main.py INFO 		Acc is 0.9749, F1-micro is 0.9749
Wed, 24 Sep 2025 23:16:48 main.py INFO 		F1-macro is 0.9749, AUC is 0.5000
Wed, 24 Sep 2025 23:16:48 main.py INFO 		Pre-macro is 0.9749, Rec_macro is 0.9749
Wed, 24 Sep 2025 23:16:48 main.py INFO 		For sarcasm, C_M is 
[[2555   53]
 [  78 2530]]
Wed, 24 Sep 2025 23:16:48 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:16:48 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:16:48 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:16:48 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:16:48 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:16:48 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:16:48 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:16:48 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:16:49 main.py INFO In dataset test: Loss is [0.6234 0.5128 0.0001 0.1105]
Wed, 24 Sep 2025 23:16:49 main.py INFO 		Acc is 0.8773, F1-micro is 0.8773
Wed, 24 Sep 2025 23:16:49 main.py INFO 		F1-macro is 0.8773, AUC is 0.5000
Wed, 24 Sep 2025 23:16:49 main.py INFO 		Pre-macro is 0.8773, Rec_macro is 0.8773
Wed, 24 Sep 2025 23:16:49 main.py INFO 		For sarcasm, C_M is 
[[458  63]
 [ 65 457]]
Wed, 24 Sep 2025 23:16:49 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:16:49 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:16:49 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:16:49 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:16:49 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:16:49 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:16:49 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:16:49 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:16:49 main.py INFO testacc: 0.8811
Wed, 24 Sep 2025 23:17:05 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:17:05 main.py INFO Time of iter training 15.34 s
Wed, 24 Sep 2025 23:17:05 main.py INFO On iter step 16.0:, global step 1024 Loss-step [1.3336 1.1846 1.0001 1.1257]
Wed, 24 Sep 2025 23:17:08 main.py INFO In dataset train: Loss is [0.1939 0.0744 0.0002 0.1193]
Wed, 24 Sep 2025 23:17:08 main.py INFO 		Acc is 0.9766, F1-micro is 0.9766
Wed, 24 Sep 2025 23:17:08 main.py INFO 		F1-macro is 0.9766, AUC is 0.5000
Wed, 24 Sep 2025 23:17:08 main.py INFO 		Pre-macro is 0.9767, Rec_macro is 0.9766
Wed, 24 Sep 2025 23:17:08 main.py INFO 		For sarcasm, C_M is 
[[2569   39]
 [  83 2525]]
Wed, 24 Sep 2025 23:17:08 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:17:08 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:17:08 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:17:08 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:17:08 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:17:08 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:17:08 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:17:08 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:17:09 main.py INFO In dataset test: Loss is [0.6404 0.5295 0.0001 0.1107]
Wed, 24 Sep 2025 23:17:09 main.py INFO 		Acc is 0.8869, F1-micro is 0.8869
Wed, 24 Sep 2025 23:17:09 main.py INFO 		F1-macro is 0.8868, AUC is 0.5000
Wed, 24 Sep 2025 23:17:09 main.py INFO 		Pre-macro is 0.8874, Rec_macro is 0.8869
Wed, 24 Sep 2025 23:17:09 main.py INFO 		For sarcasm, C_M is 
[[472  49]
 [ 69 453]]
Wed, 24 Sep 2025 23:17:09 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:17:09 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:17:09 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:17:09 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:17:09 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:17:09 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:17:09 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:17:09 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:17:09 main.py INFO testacc: 0.8869
Wed, 24 Sep 2025 23:17:25 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:17:25 main.py INFO Time of iter training 15.86 s
Wed, 24 Sep 2025 23:17:25 main.py INFO On iter step 17.0:, global step 1088 Loss-step [1.3442 1.1931 1.0001 1.1266]
Wed, 24 Sep 2025 23:17:29 main.py INFO In dataset train: Loss is [0.2310 0.1116 0.0000 0.1194]
Wed, 24 Sep 2025 23:17:29 main.py INFO 		Acc is 0.9678, F1-micro is 0.9678
Wed, 24 Sep 2025 23:17:29 main.py INFO 		F1-macro is 0.9678, AUC is 0.5000
Wed, 24 Sep 2025 23:17:29 main.py INFO 		Pre-macro is 0.9684, Rec_macro is 0.9678
Wed, 24 Sep 2025 23:17:29 main.py INFO 		For sarcasm, C_M is 
[[2476  132]
 [  36 2572]]
Wed, 24 Sep 2025 23:17:29 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:17:29 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:17:29 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:17:29 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:17:29 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:17:29 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:17:29 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:17:29 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:17:29 main.py INFO In dataset test: Loss is [0.6907 0.5801 0.0000 0.1105]
Wed, 24 Sep 2025 23:17:29 main.py INFO 		Acc is 0.8562, F1-micro is 0.8562
Wed, 24 Sep 2025 23:17:29 main.py INFO 		F1-macro is 0.8557, AUC is 0.5000
Wed, 24 Sep 2025 23:17:29 main.py INFO 		Pre-macro is 0.8610, Rec_macro is 0.8561
Wed, 24 Sep 2025 23:17:29 main.py INFO 		For sarcasm, C_M is 
[[416 105]
 [ 45 477]]
Wed, 24 Sep 2025 23:17:29 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:17:29 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:17:29 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:17:29 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:17:29 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:17:29 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:17:29 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:17:29 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:17:29 main.py INFO testacc: 0.8869
Wed, 24 Sep 2025 23:17:45 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:17:45 main.py INFO Time of iter training 15.32 s
Wed, 24 Sep 2025 23:17:45 main.py INFO On iter step 18.0:, global step 1152 Loss-step [1.3470 1.1945 1.0001 1.1276]
Wed, 24 Sep 2025 23:17:48 main.py INFO In dataset train: Loss is [0.1832 0.0637 0.0002 0.1193]
Wed, 24 Sep 2025 23:17:48 main.py INFO 		Acc is 0.9797, F1-micro is 0.9797
Wed, 24 Sep 2025 23:17:48 main.py INFO 		F1-macro is 0.9797, AUC is 0.5000
Wed, 24 Sep 2025 23:17:48 main.py INFO 		Pre-macro is 0.9798, Rec_macro is 0.9797
Wed, 24 Sep 2025 23:17:48 main.py INFO 		For sarcasm, C_M is 
[[2534   74]
 [  32 2576]]
Wed, 24 Sep 2025 23:17:48 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:17:48 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:17:48 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:17:48 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:17:48 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:17:48 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:17:48 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:17:48 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:17:49 main.py INFO In dataset test: Loss is [0.6647 0.5540 0.0002 0.1105]
Wed, 24 Sep 2025 23:17:49 main.py INFO 		Acc is 0.8792, F1-micro is 0.8792
Wed, 24 Sep 2025 23:17:49 main.py INFO 		F1-macro is 0.8791, AUC is 0.5000
Wed, 24 Sep 2025 23:17:49 main.py INFO 		Pre-macro is 0.8800, Rec_macro is 0.8792
Wed, 24 Sep 2025 23:17:49 main.py INFO 		For sarcasm, C_M is 
[[446  75]
 [ 51 471]]
Wed, 24 Sep 2025 23:17:49 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:17:49 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:17:49 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:17:49 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:17:49 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:17:49 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:17:49 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:17:49 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:17:49 main.py INFO testacc: 0.8869
Wed, 24 Sep 2025 23:18:05 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:18:05 main.py INFO Time of iter training 15.43 s
Wed, 24 Sep 2025 23:18:05 main.py INFO On iter step 19.0:, global step 1216 Loss-step [1.2792 1.1344 1.0001 1.1275]
Wed, 24 Sep 2025 23:18:08 main.py INFO In dataset train: Loss is [0.1909 0.0715 0.0001 0.1193]
Wed, 24 Sep 2025 23:18:08 main.py INFO 		Acc is 0.9814, F1-micro is 0.9814
Wed, 24 Sep 2025 23:18:08 main.py INFO 		F1-macro is 0.9814, AUC is 0.5000
Wed, 24 Sep 2025 23:18:08 main.py INFO 		Pre-macro is 0.9814, Rec_macro is 0.9814
Wed, 24 Sep 2025 23:18:08 main.py INFO 		For sarcasm, C_M is 
[[2559   49]
 [  48 2560]]
Wed, 24 Sep 2025 23:18:08 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:18:08 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:18:08 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:18:08 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:18:08 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:18:08 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:18:08 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:18:08 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:18:09 main.py INFO In dataset test: Loss is [0.6399 0.5294 0.0000 0.1105]
Wed, 24 Sep 2025 23:18:09 main.py INFO 		Acc is 0.8619, F1-micro is 0.8619
Wed, 24 Sep 2025 23:18:09 main.py INFO 		F1-macro is 0.8619, AUC is 0.5000
Wed, 24 Sep 2025 23:18:09 main.py INFO 		Pre-macro is 0.8626, Rec_macro is 0.8619
Wed, 24 Sep 2025 23:18:09 main.py INFO 		For sarcasm, C_M is 
[[438  83]
 [ 61 461]]
Wed, 24 Sep 2025 23:18:09 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:18:09 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:18:09 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:18:09 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:18:09 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:18:09 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:18:09 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:18:09 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:18:09 main.py INFO testacc: 0.8869
Wed, 24 Sep 2025 23:18:25 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:18:25 main.py INFO Time of iter training 15.53 s
Wed, 24 Sep 2025 23:18:25 main.py INFO On iter step 20.0:, global step 1280 Loss-step [1.2675 1.1244 1.0001 1.1272]
Wed, 24 Sep 2025 23:18:28 main.py INFO In dataset train: Loss is [0.1633 0.0440 0.0000 0.1193]
Wed, 24 Sep 2025 23:18:28 main.py INFO 		Acc is 0.9862, F1-micro is 0.9862
Wed, 24 Sep 2025 23:18:28 main.py INFO 		F1-macro is 0.9862, AUC is 0.5000
Wed, 24 Sep 2025 23:18:28 main.py INFO 		Pre-macro is 0.9862, Rec_macro is 0.9862
Wed, 24 Sep 2025 23:18:28 main.py INFO 		For sarcasm, C_M is 
[[2585   23]
 [  49 2559]]
Wed, 24 Sep 2025 23:18:28 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:18:28 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:18:28 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:18:28 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:18:28 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:18:28 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:18:28 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:18:28 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:18:29 main.py INFO In dataset test: Loss is [0.8013 0.6908 0.0000 0.1105]
Wed, 24 Sep 2025 23:18:29 main.py INFO 		Acc is 0.8849, F1-micro is 0.8849
Wed, 24 Sep 2025 23:18:29 main.py INFO 		F1-macro is 0.8849, AUC is 0.5000
Wed, 24 Sep 2025 23:18:29 main.py INFO 		Pre-macro is 0.8850, Rec_macro is 0.8850
Wed, 24 Sep 2025 23:18:29 main.py INFO 		For sarcasm, C_M is 
[[464  57]
 [ 63 459]]
Wed, 24 Sep 2025 23:18:29 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:18:29 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:18:29 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:18:29 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:18:29 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:18:29 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:18:29 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:18:29 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:18:29 main.py INFO testacc: 0.8869
Wed, 24 Sep 2025 23:18:44 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:18:44 main.py INFO Time of iter training 15.36 s
Wed, 24 Sep 2025 23:18:44 main.py INFO On iter step 21.0:, global step 1344 Loss-step [1.2728 1.1299 1.0001 1.1264]
Wed, 24 Sep 2025 23:18:48 main.py INFO In dataset train: Loss is [0.2302 0.1108 0.0001 0.1193]
Wed, 24 Sep 2025 23:18:48 main.py INFO 		Acc is 0.9632, F1-micro is 0.9632
Wed, 24 Sep 2025 23:18:48 main.py INFO 		F1-macro is 0.9632, AUC is 0.5000
Wed, 24 Sep 2025 23:18:48 main.py INFO 		Pre-macro is 0.9636, Rec_macro is 0.9632
Wed, 24 Sep 2025 23:18:48 main.py INFO 		For sarcasm, C_M is 
[[2553   55]
 [ 137 2471]]
Wed, 24 Sep 2025 23:18:48 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:18:48 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:18:48 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:18:48 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:18:48 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:18:48 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:18:48 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:18:48 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:18:49 main.py INFO In dataset test: Loss is [0.5723 0.4617 0.0001 0.1106]
Wed, 24 Sep 2025 23:18:49 main.py INFO 		Acc is 0.8447, F1-micro is 0.8447
Wed, 24 Sep 2025 23:18:49 main.py INFO 		F1-macro is 0.8447, AUC is 0.5000
Wed, 24 Sep 2025 23:18:49 main.py INFO 		Pre-macro is 0.8448, Rec_macro is 0.8447
Wed, 24 Sep 2025 23:18:49 main.py INFO 		For sarcasm, C_M is 
[[445  76]
 [ 86 436]]
Wed, 24 Sep 2025 23:18:49 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:18:49 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:18:49 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:18:49 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:18:49 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:18:49 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:18:49 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:18:49 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:18:49 main.py INFO testacc: 0.8869
Wed, 24 Sep 2025 23:19:04 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:19:04 main.py INFO Time of iter training 15.26 s
Wed, 24 Sep 2025 23:19:04 main.py INFO On iter step 22.0:, global step 1408 Loss-step [1.2660 1.1230 1.0001 1.1272]
Wed, 24 Sep 2025 23:19:08 main.py INFO In dataset train: Loss is [0.1534 0.0341 0.0000 0.1193]
Wed, 24 Sep 2025 23:19:08 main.py INFO 		Acc is 0.9916, F1-micro is 0.9916
Wed, 24 Sep 2025 23:19:08 main.py INFO 		F1-macro is 0.9916, AUC is 0.5000
Wed, 24 Sep 2025 23:19:08 main.py INFO 		Pre-macro is 0.9916, Rec_macro is 0.9916
Wed, 24 Sep 2025 23:19:08 main.py INFO 		For sarcasm, C_M is 
[[2600    8]
 [  36 2572]]
Wed, 24 Sep 2025 23:19:08 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:19:08 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:19:08 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:19:08 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:19:08 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:19:08 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:19:08 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:19:08 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:19:09 main.py INFO In dataset test: Loss is [0.9532 0.8426 0.0000 0.1105]
Wed, 24 Sep 2025 23:19:09 main.py INFO 		Acc is 0.8830, F1-micro is 0.8830
Wed, 24 Sep 2025 23:19:09 main.py INFO 		F1-macro is 0.8830, AUC is 0.5000
Wed, 24 Sep 2025 23:19:09 main.py INFO 		Pre-macro is 0.8831, Rec_macro is 0.8830
Wed, 24 Sep 2025 23:19:09 main.py INFO 		For sarcasm, C_M is 
[[456  65]
 [ 57 465]]
Wed, 24 Sep 2025 23:19:09 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:19:09 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:19:09 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:19:09 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:19:09 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:19:09 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:19:09 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:19:09 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:19:09 main.py INFO testacc: 0.8869
Wed, 24 Sep 2025 23:19:24 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:19:24 main.py INFO Time of iter training 15.43 s
Wed, 24 Sep 2025 23:19:24 main.py INFO On iter step 23.0:, global step 1472 Loss-step [1.2629 1.1216 1.0000 1.1259]
Wed, 24 Sep 2025 23:19:28 main.py INFO In dataset train: Loss is [0.2751 0.1557 0.0001 0.1193]
Wed, 24 Sep 2025 23:19:28 main.py INFO 		Acc is 0.9356, F1-micro is 0.9356
Wed, 24 Sep 2025 23:19:28 main.py INFO 		F1-macro is 0.9354, AUC is 0.5000
Wed, 24 Sep 2025 23:19:28 main.py INFO 		Pre-macro is 0.9404, Rec_macro is 0.9356
Wed, 24 Sep 2025 23:19:28 main.py INFO 		For sarcasm, C_M is 
[[2576   32]
 [ 304 2304]]
Wed, 24 Sep 2025 23:19:28 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:19:28 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:19:28 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:19:28 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:19:28 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:19:28 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:19:28 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:19:28 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:19:29 main.py INFO In dataset test: Loss is [0.7433 0.6327 0.0001 0.1105]
Wed, 24 Sep 2025 23:19:29 main.py INFO 		Acc is 0.8341, F1-micro is 0.8341
Wed, 24 Sep 2025 23:19:29 main.py INFO 		F1-macro is 0.8322, AUC is 0.5000
Wed, 24 Sep 2025 23:19:29 main.py INFO 		Pre-macro is 0.8505, Rec_macro is 0.8342
Wed, 24 Sep 2025 23:19:29 main.py INFO 		For sarcasm, C_M is 
[[491  30]
 [143 379]]
Wed, 24 Sep 2025 23:19:29 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:19:29 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:19:29 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:19:29 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:19:29 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:19:29 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:19:29 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:19:29 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:19:29 main.py INFO testacc: 0.8869
Wed, 24 Sep 2025 23:19:44 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:19:44 main.py INFO Time of iter training 15.29 s
Wed, 24 Sep 2025 23:19:44 main.py INFO On iter step 24.0:, global step 1536 Loss-step [1.2568 1.1134 1.0001 1.1287]
Wed, 24 Sep 2025 23:19:48 main.py INFO In dataset train: Loss is [0.1447 0.0253 0.0001 0.1193]
Wed, 24 Sep 2025 23:19:48 main.py INFO 		Acc is 0.9941, F1-micro is 0.9941
Wed, 24 Sep 2025 23:19:48 main.py INFO 		F1-macro is 0.9941, AUC is 0.5000
Wed, 24 Sep 2025 23:19:48 main.py INFO 		Pre-macro is 0.9941, Rec_macro is 0.9941
Wed, 24 Sep 2025 23:19:48 main.py INFO 		For sarcasm, C_M is 
[[2603    5]
 [  26 2582]]
Wed, 24 Sep 2025 23:19:48 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:19:48 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:19:48 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:19:48 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:19:48 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:19:48 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:19:48 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:19:48 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:19:48 main.py INFO In dataset test: Loss is [0.8317 0.7211 0.0001 0.1105]
Wed, 24 Sep 2025 23:19:48 main.py INFO 		Acc is 0.8773, F1-micro is 0.8773
Wed, 24 Sep 2025 23:19:48 main.py INFO 		F1-macro is 0.8773, AUC is 0.5000
Wed, 24 Sep 2025 23:19:48 main.py INFO 		Pre-macro is 0.8773, Rec_macro is 0.8773
Wed, 24 Sep 2025 23:19:48 main.py INFO 		For sarcasm, C_M is 
[[454  67]
 [ 61 461]]
Wed, 24 Sep 2025 23:19:48 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:19:48 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:19:48 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:19:48 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:19:48 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:19:48 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:19:48 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:19:48 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:19:48 main.py INFO testacc: 0.8869
Wed, 24 Sep 2025 23:20:04 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:20:04 main.py INFO Time of iter training 15.41 s
Wed, 24 Sep 2025 23:20:04 main.py INFO On iter step 25.0:, global step 1600 Loss-step [1.2345 1.0960 1.0000 1.1263]
Wed, 24 Sep 2025 23:20:07 main.py INFO In dataset train: Loss is [0.1484 0.0291 0.0000 0.1193]
Wed, 24 Sep 2025 23:20:07 main.py INFO 		Acc is 0.9908, F1-micro is 0.9908
Wed, 24 Sep 2025 23:20:07 main.py INFO 		F1-macro is 0.9908, AUC is 0.5000
Wed, 24 Sep 2025 23:20:07 main.py INFO 		Pre-macro is 0.9909, Rec_macro is 0.9908
Wed, 24 Sep 2025 23:20:07 main.py INFO 		For sarcasm, C_M is 
[[2604    4]
 [  44 2564]]
Wed, 24 Sep 2025 23:20:07 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:20:07 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:20:07 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:20:07 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:20:07 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:20:07 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:20:07 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:20:07 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:20:08 main.py INFO In dataset test: Loss is [0.7591 0.6486 0.0000 0.1105]
Wed, 24 Sep 2025 23:20:08 main.py INFO 		Acc is 0.8821, F1-micro is 0.8821
Wed, 24 Sep 2025 23:20:08 main.py INFO 		F1-macro is 0.8820, AUC is 0.5000
Wed, 24 Sep 2025 23:20:08 main.py INFO 		Pre-macro is 0.8826, Rec_macro is 0.8821
Wed, 24 Sep 2025 23:20:08 main.py INFO 		For sarcasm, C_M is 
[[469  52]
 [ 71 451]]
Wed, 24 Sep 2025 23:20:08 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:20:08 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:20:08 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:20:08 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:20:08 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:20:08 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:20:08 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:20:08 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:20:08 main.py INFO testacc: 0.8869
Wed, 24 Sep 2025 23:20:24 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:20:24 main.py INFO Time of iter training 15.37 s
Wed, 24 Sep 2025 23:20:24 main.py INFO On iter step 26.0:, global step 1664 Loss-step [1.2145 1.0790 1.0000 1.1255]
Wed, 24 Sep 2025 23:20:27 main.py INFO In dataset train: Loss is [0.1401 0.0208 0.0000 0.1193]
Wed, 24 Sep 2025 23:20:27 main.py INFO 		Acc is 0.9948, F1-micro is 0.9948
Wed, 24 Sep 2025 23:20:27 main.py INFO 		F1-macro is 0.9948, AUC is 0.5000
Wed, 24 Sep 2025 23:20:27 main.py INFO 		Pre-macro is 0.9949, Rec_macro is 0.9948
Wed, 24 Sep 2025 23:20:27 main.py INFO 		For sarcasm, C_M is 
[[2605    3]
 [  24 2584]]
Wed, 24 Sep 2025 23:20:27 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:20:27 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:20:27 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:20:27 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:20:27 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:20:27 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:20:27 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:20:27 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:20:28 main.py INFO In dataset test: Loss is [0.9496 0.8391 0.0000 0.1105]
Wed, 24 Sep 2025 23:20:28 main.py INFO 		Acc is 0.8897, F1-micro is 0.8897
Wed, 24 Sep 2025 23:20:28 main.py INFO 		F1-macro is 0.8897, AUC is 0.5000
Wed, 24 Sep 2025 23:20:28 main.py INFO 		Pre-macro is 0.8898, Rec_macro is 0.8897
Wed, 24 Sep 2025 23:20:28 main.py INFO 		For sarcasm, C_M is 
[[467  54]
 [ 61 461]]
Wed, 24 Sep 2025 23:20:28 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:20:28 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:20:28 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:20:28 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:20:28 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:20:28 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:20:28 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:20:28 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:20:28 main.py INFO testacc: 0.8897
Wed, 24 Sep 2025 23:20:43 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:20:43 main.py INFO Time of iter training 15.33 s
Wed, 24 Sep 2025 23:20:43 main.py INFO On iter step 27.0:, global step 1728 Loss-step [1.2147 1.0772 1.0000 1.1276]
Wed, 24 Sep 2025 23:20:47 main.py INFO In dataset train: Loss is [0.1445 0.0252 0.0000 0.1193]
Wed, 24 Sep 2025 23:20:47 main.py INFO 		Acc is 0.9931, F1-micro is 0.9931
Wed, 24 Sep 2025 23:20:47 main.py INFO 		F1-macro is 0.9931, AUC is 0.5000
Wed, 24 Sep 2025 23:20:47 main.py INFO 		Pre-macro is 0.9932, Rec_macro is 0.9931
Wed, 24 Sep 2025 23:20:47 main.py INFO 		For sarcasm, C_M is 
[[2604    4]
 [  32 2576]]
Wed, 24 Sep 2025 23:20:47 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:20:47 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:20:47 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:20:47 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:20:47 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:20:47 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:20:47 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:20:47 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:20:48 main.py INFO In dataset test: Loss is [0.9682 0.8577 0.0000 0.1105]
Wed, 24 Sep 2025 23:20:48 main.py INFO 		Acc is 0.8763, F1-micro is 0.8763
Wed, 24 Sep 2025 23:20:48 main.py INFO 		F1-macro is 0.8763, AUC is 0.5000
Wed, 24 Sep 2025 23:20:48 main.py INFO 		Pre-macro is 0.8768, Rec_macro is 0.8763
Wed, 24 Sep 2025 23:20:48 main.py INFO 		For sarcasm, C_M is 
[[466  55]
 [ 74 448]]
Wed, 24 Sep 2025 23:20:48 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:20:48 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:20:48 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:20:48 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:20:48 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:20:48 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:20:48 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:20:48 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:20:48 main.py INFO testacc: 0.8897
Wed, 24 Sep 2025 23:21:03 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:21:03 main.py INFO Time of iter training 15.27 s
Wed, 24 Sep 2025 23:21:03 main.py INFO On iter step 28.0:, global step 1792 Loss-step [1.2008 1.0657 1.0000 1.1267]
Wed, 24 Sep 2025 23:21:07 main.py INFO In dataset train: Loss is [0.1493 0.0300 0.0000 0.1193]
Wed, 24 Sep 2025 23:21:07 main.py INFO 		Acc is 0.9896, F1-micro is 0.9896
Wed, 24 Sep 2025 23:21:07 main.py INFO 		F1-macro is 0.9896, AUC is 0.5000
Wed, 24 Sep 2025 23:21:07 main.py INFO 		Pre-macro is 0.9896, Rec_macro is 0.9896
Wed, 24 Sep 2025 23:21:07 main.py INFO 		For sarcasm, C_M is 
[[2581   27]
 [  27 2581]]
Wed, 24 Sep 2025 23:21:07 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:21:07 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:21:07 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:21:07 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:21:07 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:21:07 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:21:07 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:21:07 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:21:08 main.py INFO In dataset test: Loss is [0.9933 0.8828 0.0000 0.1105]
Wed, 24 Sep 2025 23:21:08 main.py INFO 		Acc is 0.8725, F1-micro is 0.8725
Wed, 24 Sep 2025 23:21:08 main.py INFO 		F1-macro is 0.8725, AUC is 0.5000
Wed, 24 Sep 2025 23:21:08 main.py INFO 		Pre-macro is 0.8726, Rec_macro is 0.8725
Wed, 24 Sep 2025 23:21:08 main.py INFO 		For sarcasm, C_M is 
[[460  61]
 [ 72 450]]
Wed, 24 Sep 2025 23:21:08 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:21:08 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:21:08 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:21:08 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:21:08 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:21:08 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:21:08 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:21:08 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:21:08 main.py INFO testacc: 0.8897
Wed, 24 Sep 2025 23:21:23 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:21:23 main.py INFO Time of iter training 15.31 s
Wed, 24 Sep 2025 23:21:23 main.py INFO On iter step 29.0:, global step 1856 Loss-step [1.1996 1.0645 1.0000 1.1269]
Wed, 24 Sep 2025 23:21:27 main.py INFO In dataset train: Loss is [0.1709 0.0516 0.0000 0.1193]
Wed, 24 Sep 2025 23:21:27 main.py INFO 		Acc is 0.9921, F1-micro is 0.9921
Wed, 24 Sep 2025 23:21:27 main.py INFO 		F1-macro is 0.9921, AUC is 0.5000
Wed, 24 Sep 2025 23:21:27 main.py INFO 		Pre-macro is 0.9922, Rec_macro is 0.9921
Wed, 24 Sep 2025 23:21:27 main.py INFO 		For sarcasm, C_M is 
[[2574   34]
 [   7 2601]]
Wed, 24 Sep 2025 23:21:27 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:21:27 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:21:27 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:21:27 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:21:27 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:21:27 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:21:27 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:21:27 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:21:27 main.py INFO In dataset test: Loss is [1.2759 1.1654 0.0000 0.1105]
Wed, 24 Sep 2025 23:21:27 main.py INFO 		Acc is 0.8725, F1-micro is 0.8725
Wed, 24 Sep 2025 23:21:27 main.py INFO 		F1-macro is 0.8721, AUC is 0.5000
Wed, 24 Sep 2025 23:21:27 main.py INFO 		Pre-macro is 0.8764, Rec_macro is 0.8724
Wed, 24 Sep 2025 23:21:27 main.py INFO 		For sarcasm, C_M is 
[[428  93]
 [ 40 482]]
Wed, 24 Sep 2025 23:21:27 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:21:27 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:21:27 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:21:27 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:21:27 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:21:27 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:21:27 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:21:27 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:21:27 main.py INFO testacc: 0.8897
Wed, 24 Sep 2025 23:21:43 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:21:43 main.py INFO Time of iter training 15.42 s
Wed, 24 Sep 2025 23:21:43 main.py INFO On iter step 30.0:, global step 1920 Loss-step [1.1981 1.0637 1.0000 1.1263]
Wed, 24 Sep 2025 23:21:47 main.py INFO In dataset train: Loss is [0.1429 0.0236 0.0000 0.1193]
Wed, 24 Sep 2025 23:21:47 main.py INFO 		Acc is 0.9935, F1-micro is 0.9935
Wed, 24 Sep 2025 23:21:47 main.py INFO 		F1-macro is 0.9935, AUC is 0.5000
Wed, 24 Sep 2025 23:21:47 main.py INFO 		Pre-macro is 0.9935, Rec_macro is 0.9935
Wed, 24 Sep 2025 23:21:47 main.py INFO 		For sarcasm, C_M is 
[[2596   12]
 [  22 2586]]
Wed, 24 Sep 2025 23:21:47 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:21:47 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:21:47 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:21:47 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:21:47 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:21:47 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:21:47 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:21:47 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:21:47 main.py INFO In dataset test: Loss is [0.8155 0.7049 0.0000 0.1105]
Wed, 24 Sep 2025 23:21:47 main.py INFO 		Acc is 0.8677, F1-micro is 0.8677
Wed, 24 Sep 2025 23:21:47 main.py INFO 		F1-macro is 0.8677, AUC is 0.5000
Wed, 24 Sep 2025 23:21:47 main.py INFO 		Pre-macro is 0.8677, Rec_macro is 0.8677
Wed, 24 Sep 2025 23:21:47 main.py INFO 		For sarcasm, C_M is 
[[451  70]
 [ 68 454]]
Wed, 24 Sep 2025 23:21:47 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:21:47 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:21:47 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:21:47 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:21:47 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:21:47 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:21:47 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:21:47 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:21:47 main.py INFO testacc: 0.8897
Wed, 24 Sep 2025 23:22:03 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:22:03 main.py INFO Time of iter training 15.89 s
Wed, 24 Sep 2025 23:22:03 main.py INFO On iter step 31.0:, global step 1984 Loss-step [1.1907 1.0564 1.0000 1.1271]
Wed, 24 Sep 2025 23:22:07 main.py INFO In dataset train: Loss is [0.1287 0.0093 0.0000 0.1193]
Wed, 24 Sep 2025 23:22:07 main.py INFO 		Acc is 0.9977, F1-micro is 0.9977
Wed, 24 Sep 2025 23:22:07 main.py INFO 		F1-macro is 0.9977, AUC is 0.5000
Wed, 24 Sep 2025 23:22:07 main.py INFO 		Pre-macro is 0.9977, Rec_macro is 0.9977
Wed, 24 Sep 2025 23:22:07 main.py INFO 		For sarcasm, C_M is 
[[2603    5]
 [   7 2601]]
Wed, 24 Sep 2025 23:22:07 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:22:07 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:22:07 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:22:07 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:22:07 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:22:07 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:22:07 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:22:07 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:22:08 main.py INFO In dataset test: Loss is [1.1242 1.0137 0.0000 0.1105]
Wed, 24 Sep 2025 23:22:08 main.py INFO 		Acc is 0.8840, F1-micro is 0.8840
Wed, 24 Sep 2025 23:22:08 main.py INFO 		F1-macro is 0.8839, AUC is 0.5000
Wed, 24 Sep 2025 23:22:08 main.py INFO 		Pre-macro is 0.8854, Rec_macro is 0.8840
Wed, 24 Sep 2025 23:22:08 main.py INFO 		For sarcasm, C_M is 
[[445  76]
 [ 45 477]]
Wed, 24 Sep 2025 23:22:08 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:22:08 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:22:08 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:22:08 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:22:08 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:22:08 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:22:08 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:22:08 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:22:08 main.py INFO testacc: 0.8897
Wed, 24 Sep 2025 23:22:23 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:22:23 main.py INFO Time of iter training 15.56 s
Wed, 24 Sep 2025 23:22:23 main.py INFO On iter step 32.0:, global step 2048 Loss-step [1.1814 1.0482 1.0010 1.1260]
Wed, 24 Sep 2025 23:22:27 main.py INFO In dataset train: Loss is [0.1297 0.0105 0.0000 0.1193]
Wed, 24 Sep 2025 23:22:27 main.py INFO 		Acc is 0.9981, F1-micro is 0.9981
Wed, 24 Sep 2025 23:22:27 main.py INFO 		F1-macro is 0.9981, AUC is 0.5000
Wed, 24 Sep 2025 23:22:27 main.py INFO 		Pre-macro is 0.9981, Rec_macro is 0.9981
Wed, 24 Sep 2025 23:22:27 main.py INFO 		For sarcasm, C_M is 
[[2603    5]
 [   5 2603]]
Wed, 24 Sep 2025 23:22:27 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:22:27 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:22:27 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:22:27 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:22:27 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:22:27 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:22:27 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:22:27 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:22:28 main.py INFO In dataset test: Loss is [1.0190 0.9085 0.0000 0.1105]
Wed, 24 Sep 2025 23:22:28 main.py INFO 		Acc is 0.8725, F1-micro is 0.8725
Wed, 24 Sep 2025 23:22:28 main.py INFO 		F1-macro is 0.8724, AUC is 0.5000
Wed, 24 Sep 2025 23:22:28 main.py INFO 		Pre-macro is 0.8729, Rec_macro is 0.8725
Wed, 24 Sep 2025 23:22:28 main.py INFO 		For sarcasm, C_M is 
[[446  75]
 [ 58 464]]
Wed, 24 Sep 2025 23:22:28 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:22:28 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:22:28 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:22:28 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:22:28 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:22:28 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:22:28 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:22:28 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:22:28 main.py INFO testacc: 0.8897
Wed, 24 Sep 2025 23:22:43 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:22:43 main.py INFO Time of iter training 15.33 s
Wed, 24 Sep 2025 23:22:43 main.py INFO On iter step 33.0:, global step 2112 Loss-step [1.1802 1.0472 1.0001 1.1269]
Wed, 24 Sep 2025 23:22:47 main.py INFO In dataset train: Loss is [0.1242 0.0049 0.0000 0.1193]
Wed, 24 Sep 2025 23:22:47 main.py INFO 		Acc is 0.9992, F1-micro is 0.9992
Wed, 24 Sep 2025 23:22:47 main.py INFO 		F1-macro is 0.9992, AUC is 0.5000
Wed, 24 Sep 2025 23:22:47 main.py INFO 		Pre-macro is 0.9992, Rec_macro is 0.9992
Wed, 24 Sep 2025 23:22:47 main.py INFO 		For sarcasm, C_M is 
[[2608    0]
 [   4 2604]]
Wed, 24 Sep 2025 23:22:47 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:22:47 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:22:47 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:22:47 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:22:47 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:22:47 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:22:47 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:22:47 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:22:48 main.py INFO In dataset test: Loss is [1.1189 1.0084 0.0000 0.1105]
Wed, 24 Sep 2025 23:22:48 main.py INFO 		Acc is 0.8802, F1-micro is 0.8802
Wed, 24 Sep 2025 23:22:48 main.py INFO 		F1-macro is 0.8801, AUC is 0.5000
Wed, 24 Sep 2025 23:22:48 main.py INFO 		Pre-macro is 0.8802, Rec_macro is 0.8801
Wed, 24 Sep 2025 23:22:48 main.py INFO 		For sarcasm, C_M is 
[[455  66]
 [ 59 463]]
Wed, 24 Sep 2025 23:22:48 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:22:48 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:22:48 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:22:48 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:22:48 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:22:48 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:22:48 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:22:48 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:22:48 main.py INFO testacc: 0.8897
Wed, 24 Sep 2025 23:23:03 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:23:03 main.py INFO Time of iter training 15.69 s
Wed, 24 Sep 2025 23:23:03 main.py INFO On iter step 34.0:, global step 2176 Loss-step [1.1824 1.0493 1.0000 1.1269]
Wed, 24 Sep 2025 23:23:07 main.py INFO In dataset train: Loss is [0.1567 0.0375 0.0000 0.1192]
Wed, 24 Sep 2025 23:23:07 main.py INFO 		Acc is 0.9893, F1-micro is 0.9893
Wed, 24 Sep 2025 23:23:07 main.py INFO 		F1-macro is 0.9893, AUC is 0.5000
Wed, 24 Sep 2025 23:23:07 main.py INFO 		Pre-macro is 0.9894, Rec_macro is 0.9893
Wed, 24 Sep 2025 23:23:07 main.py INFO 		For sarcasm, C_M is 
[[2600    8]
 [  48 2560]]
Wed, 24 Sep 2025 23:23:07 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:23:07 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:23:07 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:23:07 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:23:07 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:23:07 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:23:07 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:23:07 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:23:08 main.py INFO In dataset test: Loss is [1.4503 1.3398 0.0000 0.1105]
Wed, 24 Sep 2025 23:23:08 main.py INFO 		Acc is 0.8734, F1-micro is 0.8734
Wed, 24 Sep 2025 23:23:08 main.py INFO 		F1-macro is 0.8729, AUC is 0.5000
Wed, 24 Sep 2025 23:23:08 main.py INFO 		Pre-macro is 0.8803, Rec_macro is 0.8735
Wed, 24 Sep 2025 23:23:08 main.py INFO 		For sarcasm, C_M is 
[[490  31]
 [101 421]]
Wed, 24 Sep 2025 23:23:08 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:23:08 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:23:08 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:23:08 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:23:08 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:23:08 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:23:08 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:23:08 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:23:08 main.py INFO testacc: 0.8897
Wed, 24 Sep 2025 23:23:23 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:23:23 main.py INFO Time of iter training 15.30 s
Wed, 24 Sep 2025 23:23:23 main.py INFO On iter step 35.0:, global step 2240 Loss-step [1.1847 1.0520 1.0000 1.1261]
Wed, 24 Sep 2025 23:23:27 main.py INFO In dataset train: Loss is [0.1260 0.0067 0.0000 0.1192]
Wed, 24 Sep 2025 23:23:27 main.py INFO 		Acc is 0.9992, F1-micro is 0.9992
Wed, 24 Sep 2025 23:23:27 main.py INFO 		F1-macro is 0.9992, AUC is 0.5000
Wed, 24 Sep 2025 23:23:27 main.py INFO 		Pre-macro is 0.9992, Rec_macro is 0.9992
Wed, 24 Sep 2025 23:23:27 main.py INFO 		For sarcasm, C_M is 
[[2608    0]
 [   4 2604]]
Wed, 24 Sep 2025 23:23:27 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:23:27 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:23:27 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:23:27 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:23:27 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:23:27 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:23:27 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:23:27 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:23:28 main.py INFO In dataset test: Loss is [1.0648 0.9542 0.0000 0.1105]
Wed, 24 Sep 2025 23:23:28 main.py INFO 		Acc is 0.8773, F1-micro is 0.8773
Wed, 24 Sep 2025 23:23:28 main.py INFO 		F1-macro is 0.8772, AUC is 0.5000
Wed, 24 Sep 2025 23:23:28 main.py INFO 		Pre-macro is 0.8782, Rec_macro is 0.8773
Wed, 24 Sep 2025 23:23:28 main.py INFO 		For sarcasm, C_M is 
[[470  51]
 [ 77 445]]
Wed, 24 Sep 2025 23:23:28 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:23:28 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:23:28 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:23:28 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:23:28 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:23:28 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:23:28 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:23:28 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:23:28 main.py INFO testacc: 0.8897
Wed, 24 Sep 2025 23:23:43 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:23:43 main.py INFO Time of iter training 15.56 s
Wed, 24 Sep 2025 23:23:43 main.py INFO On iter step 36.0:, global step 2304 Loss-step [1.1721 1.0386 1.0001 1.1284]
Wed, 24 Sep 2025 23:23:47 main.py INFO In dataset train: Loss is [0.1234 0.0042 0.0000 0.1193]
Wed, 24 Sep 2025 23:23:47 main.py INFO 		Acc is 0.9994, F1-micro is 0.9994
Wed, 24 Sep 2025 23:23:47 main.py INFO 		F1-macro is 0.9994, AUC is 0.5000
Wed, 24 Sep 2025 23:23:47 main.py INFO 		Pre-macro is 0.9994, Rec_macro is 0.9994
Wed, 24 Sep 2025 23:23:47 main.py INFO 		For sarcasm, C_M is 
[[2608    0]
 [   3 2605]]
Wed, 24 Sep 2025 23:23:47 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:23:47 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:23:47 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:23:47 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:23:47 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:23:47 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:23:47 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:23:47 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:23:47 main.py INFO In dataset test: Loss is [1.0688 0.9583 0.0000 0.1105]
Wed, 24 Sep 2025 23:23:47 main.py INFO 		Acc is 0.8725, F1-micro is 0.8725
Wed, 24 Sep 2025 23:23:47 main.py INFO 		F1-macro is 0.8725, AUC is 0.5000
Wed, 24 Sep 2025 23:23:47 main.py INFO 		Pre-macro is 0.8725, Rec_macro is 0.8725
Wed, 24 Sep 2025 23:23:47 main.py INFO 		For sarcasm, C_M is 
[[457  64]
 [ 69 453]]
Wed, 24 Sep 2025 23:23:47 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:23:47 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:23:47 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:23:47 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:23:47 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:23:47 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:23:47 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:23:47 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:23:47 main.py INFO testacc: 0.8897
Wed, 24 Sep 2025 23:24:03 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:24:03 main.py INFO Time of iter training 15.27 s
Wed, 24 Sep 2025 23:24:03 main.py INFO On iter step 37.0:, global step 2368 Loss-step [1.1667 1.0361 1.0000 1.1260]
Wed, 24 Sep 2025 23:24:07 main.py INFO In dataset train: Loss is [0.1288 0.0095 0.0000 0.1193]
Wed, 24 Sep 2025 23:24:07 main.py INFO 		Acc is 0.9979, F1-micro is 0.9979
Wed, 24 Sep 2025 23:24:07 main.py INFO 		F1-macro is 0.9979, AUC is 0.5000
Wed, 24 Sep 2025 23:24:07 main.py INFO 		Pre-macro is 0.9979, Rec_macro is 0.9979
Wed, 24 Sep 2025 23:24:07 main.py INFO 		For sarcasm, C_M is 
[[2603    5]
 [   6 2602]]
Wed, 24 Sep 2025 23:24:07 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:24:07 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:24:07 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:24:07 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:24:07 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:24:07 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:24:07 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:24:07 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:24:07 main.py INFO In dataset test: Loss is [1.1699 1.0593 0.0000 0.1105]
Wed, 24 Sep 2025 23:24:07 main.py INFO 		Acc is 0.8792, F1-micro is 0.8792
Wed, 24 Sep 2025 23:24:07 main.py INFO 		F1-macro is 0.8791, AUC is 0.5000
Wed, 24 Sep 2025 23:24:07 main.py INFO 		Pre-macro is 0.8803, Rec_macro is 0.8792
Wed, 24 Sep 2025 23:24:07 main.py INFO 		For sarcasm, C_M is 
[[444  77]
 [ 49 473]]
Wed, 24 Sep 2025 23:24:07 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:24:07 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:24:07 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:24:07 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:24:07 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:24:07 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:24:07 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:24:07 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:24:07 main.py INFO testacc: 0.8897
Wed, 24 Sep 2025 23:24:23 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:24:23 main.py INFO Time of iter training 15.63 s
Wed, 24 Sep 2025 23:24:23 main.py INFO On iter step 38.0:, global step 2432 Loss-step [1.1847 1.0509 1.0000 1.1272]
Wed, 24 Sep 2025 23:24:27 main.py INFO In dataset train: Loss is [0.1260 0.0067 0.0000 0.1193]
Wed, 24 Sep 2025 23:24:27 main.py INFO 		Acc is 0.9990, F1-micro is 0.9990
Wed, 24 Sep 2025 23:24:27 main.py INFO 		F1-macro is 0.9990, AUC is 0.5000
Wed, 24 Sep 2025 23:24:27 main.py INFO 		Pre-macro is 0.9990, Rec_macro is 0.9990
Wed, 24 Sep 2025 23:24:27 main.py INFO 		For sarcasm, C_M is 
[[2605    3]
 [   2 2606]]
Wed, 24 Sep 2025 23:24:27 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:24:27 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:24:27 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:24:27 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:24:27 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:24:27 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:24:27 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:24:27 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:24:27 main.py INFO In dataset test: Loss is [0.9942 0.8837 0.0000 0.1105]
Wed, 24 Sep 2025 23:24:27 main.py INFO 		Acc is 0.8878, F1-micro is 0.8878
Wed, 24 Sep 2025 23:24:27 main.py INFO 		F1-macro is 0.8878, AUC is 0.5000
Wed, 24 Sep 2025 23:24:27 main.py INFO 		Pre-macro is 0.8885, Rec_macro is 0.8878
Wed, 24 Sep 2025 23:24:27 main.py INFO 		For sarcasm, C_M is 
[[452  69]
 [ 48 474]]
Wed, 24 Sep 2025 23:24:27 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:24:27 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:24:27 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:24:27 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:24:27 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:24:27 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:24:27 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:24:27 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:24:27 main.py INFO testacc: 0.8897
Wed, 24 Sep 2025 23:24:43 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:24:43 main.py INFO Time of iter training 15.81 s
Wed, 24 Sep 2025 23:24:43 main.py INFO On iter step 39.0:, global step 2496 Loss-step [1.1661 1.0362 1.0000 1.1254]
Wed, 24 Sep 2025 23:24:47 main.py INFO In dataset train: Loss is [0.1311 0.0118 0.0000 0.1193]
Wed, 24 Sep 2025 23:24:47 main.py INFO 		Acc is 0.9981, F1-micro is 0.9981
Wed, 24 Sep 2025 23:24:47 main.py INFO 		F1-macro is 0.9981, AUC is 0.5000
Wed, 24 Sep 2025 23:24:47 main.py INFO 		Pre-macro is 0.9981, Rec_macro is 0.9981
Wed, 24 Sep 2025 23:24:47 main.py INFO 		For sarcasm, C_M is 
[[2604    4]
 [   6 2602]]
Wed, 24 Sep 2025 23:24:47 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:24:47 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:24:47 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:24:47 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:24:47 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:24:47 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:24:47 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:24:47 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:24:48 main.py INFO In dataset test: Loss is [0.9138 0.8032 0.0000 0.1105]
Wed, 24 Sep 2025 23:24:48 main.py INFO 		Acc is 0.8802, F1-micro is 0.8802
Wed, 24 Sep 2025 23:24:48 main.py INFO 		F1-macro is 0.8801, AUC is 0.5000
Wed, 24 Sep 2025 23:24:48 main.py INFO 		Pre-macro is 0.8804, Rec_macro is 0.8802
Wed, 24 Sep 2025 23:24:48 main.py INFO 		For sarcasm, C_M is 
[[465  56]
 [ 69 453]]
Wed, 24 Sep 2025 23:24:48 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:24:48 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:24:48 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:24:48 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:24:48 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:24:48 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:24:48 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:24:48 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:24:48 main.py INFO testacc: 0.8897
Wed, 24 Sep 2025 23:25:03 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:25:03 main.py INFO Time of iter training 15.30 s
Wed, 24 Sep 2025 23:25:03 main.py INFO On iter step 40.0:, global step 2560 Loss-step [1.1713 1.0378 1.0000 1.1286]
Wed, 24 Sep 2025 23:25:07 main.py INFO In dataset train: Loss is [0.1226 0.0034 0.0000 0.1193]
Wed, 24 Sep 2025 23:25:07 main.py INFO 		Acc is 0.9998, F1-micro is 0.9998
Wed, 24 Sep 2025 23:25:07 main.py INFO 		F1-macro is 0.9998, AUC is 0.5000
Wed, 24 Sep 2025 23:25:07 main.py INFO 		Pre-macro is 0.9998, Rec_macro is 0.9998
Wed, 24 Sep 2025 23:25:07 main.py INFO 		For sarcasm, C_M is 
[[2608    0]
 [   1 2607]]
Wed, 24 Sep 2025 23:25:07 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:25:07 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:25:07 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:25:07 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:25:07 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:25:07 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:25:07 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:25:07 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:25:07 main.py INFO In dataset test: Loss is [1.1858 1.0753 0.0000 0.1105]
Wed, 24 Sep 2025 23:25:07 main.py INFO 		Acc is 0.8888, F1-micro is 0.8888
Wed, 24 Sep 2025 23:25:07 main.py INFO 		F1-macro is 0.8888, AUC is 0.5000
Wed, 24 Sep 2025 23:25:07 main.py INFO 		Pre-macro is 0.8888, Rec_macro is 0.8888
Wed, 24 Sep 2025 23:25:07 main.py INFO 		For sarcasm, C_M is 
[[463  58]
 [ 58 464]]
Wed, 24 Sep 2025 23:25:07 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:25:07 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:25:07 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:25:07 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:25:07 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:25:07 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:25:07 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:25:07 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:25:07 main.py INFO testacc: 0.8897
Wed, 24 Sep 2025 23:25:23 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:25:23 main.py INFO Time of iter training 15.41 s
Wed, 24 Sep 2025 23:25:23 main.py INFO On iter step 41.0:, global step 2624 Loss-step [1.1746 1.0436 1.0000 1.1255]
Wed, 24 Sep 2025 23:25:26 main.py INFO In dataset train: Loss is [0.1265 0.0073 0.0000 0.1193]
Wed, 24 Sep 2025 23:25:26 main.py INFO 		Acc is 0.9992, F1-micro is 0.9992
Wed, 24 Sep 2025 23:25:26 main.py INFO 		F1-macro is 0.9992, AUC is 0.5000
Wed, 24 Sep 2025 23:25:26 main.py INFO 		Pre-macro is 0.9992, Rec_macro is 0.9992
Wed, 24 Sep 2025 23:25:26 main.py INFO 		For sarcasm, C_M is 
[[2604    4]
 [   0 2608]]
Wed, 24 Sep 2025 23:25:26 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:25:26 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:25:26 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:25:26 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:25:26 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:25:26 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:25:26 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:25:26 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:25:27 main.py INFO In dataset test: Loss is [0.8787 0.7682 0.0000 0.1105]
Wed, 24 Sep 2025 23:25:27 main.py INFO 		Acc is 0.8773, F1-micro is 0.8773
Wed, 24 Sep 2025 23:25:27 main.py INFO 		F1-macro is 0.8772, AUC is 0.5000
Wed, 24 Sep 2025 23:25:27 main.py INFO 		Pre-macro is 0.8784, Rec_macro is 0.8773
Wed, 24 Sep 2025 23:25:27 main.py INFO 		For sarcasm, C_M is 
[[443  78]
 [ 50 472]]
Wed, 24 Sep 2025 23:25:27 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:25:27 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:25:27 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:25:27 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:25:27 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:25:27 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:25:27 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:25:27 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:25:27 main.py INFO testacc: 0.8897
Wed, 24 Sep 2025 23:25:43 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:25:43 main.py INFO Time of iter training 15.80 s
Wed, 24 Sep 2025 23:25:43 main.py INFO On iter step 42.0:, global step 2688 Loss-step [1.1575 1.0281 1.0000 1.1258]
Wed, 24 Sep 2025 23:25:47 main.py INFO In dataset train: Loss is [0.1206 0.0013 0.0000 0.1192]
Wed, 24 Sep 2025 23:25:47 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:25:47 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:25:47 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:25:47 main.py INFO 		For sarcasm, C_M is 
[[2608    0]
 [   0 2608]]
Wed, 24 Sep 2025 23:25:47 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:25:47 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:25:47 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:25:47 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:25:47 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:25:47 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:25:47 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:25:47 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:25:47 main.py INFO In dataset test: Loss is [1.2465 1.1359 0.0000 0.1105]
Wed, 24 Sep 2025 23:25:47 main.py INFO 		Acc is 0.8936, F1-micro is 0.8936
Wed, 24 Sep 2025 23:25:47 main.py INFO 		F1-macro is 0.8936, AUC is 0.5000
Wed, 24 Sep 2025 23:25:47 main.py INFO 		Pre-macro is 0.8936, Rec_macro is 0.8936
Wed, 24 Sep 2025 23:25:47 main.py INFO 		For sarcasm, C_M is 
[[467  54]
 [ 57 465]]
Wed, 24 Sep 2025 23:25:47 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:25:47 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:25:47 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:25:47 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:25:47 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:25:47 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:25:47 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:25:47 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:25:47 main.py INFO testacc: 0.8936
Wed, 24 Sep 2025 23:26:03 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:26:03 main.py INFO Time of iter training 15.30 s
Wed, 24 Sep 2025 23:26:03 main.py INFO On iter step 43.0:, global step 2752 Loss-step [1.1657 1.0339 1.0000 1.1275]
Wed, 24 Sep 2025 23:26:06 main.py INFO In dataset train: Loss is [0.1303 0.0110 0.0000 0.1193]
Wed, 24 Sep 2025 23:26:06 main.py INFO 		Acc is 0.9977, F1-micro is 0.9977
Wed, 24 Sep 2025 23:26:06 main.py INFO 		F1-macro is 0.9977, AUC is 0.5000
Wed, 24 Sep 2025 23:26:06 main.py INFO 		Pre-macro is 0.9977, Rec_macro is 0.9977
Wed, 24 Sep 2025 23:26:06 main.py INFO 		For sarcasm, C_M is 
[[2608    0]
 [  12 2596]]
Wed, 24 Sep 2025 23:26:06 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:26:06 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:26:06 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:26:06 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:26:06 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:26:06 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:26:06 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:26:06 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:26:07 main.py INFO In dataset test: Loss is [1.2385 1.1280 0.0000 0.1105]
Wed, 24 Sep 2025 23:26:07 main.py INFO 		Acc is 0.8821, F1-micro is 0.8821
Wed, 24 Sep 2025 23:26:07 main.py INFO 		F1-macro is 0.8818, AUC is 0.5000
Wed, 24 Sep 2025 23:26:07 main.py INFO 		Pre-macro is 0.8863, Rec_macro is 0.8821
Wed, 24 Sep 2025 23:26:07 main.py INFO 		For sarcasm, C_M is 
[[487  34]
 [ 89 433]]
Wed, 24 Sep 2025 23:26:07 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:26:07 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:26:07 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:26:07 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:26:07 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:26:07 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:26:07 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:26:07 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:26:07 main.py INFO testacc: 0.8936
Wed, 24 Sep 2025 23:26:23 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:26:23 main.py INFO Time of iter training 15.70 s
Wed, 24 Sep 2025 23:26:23 main.py INFO On iter step 44.0:, global step 2816 Loss-step [1.1625 1.0318 1.0000 1.1267]
Wed, 24 Sep 2025 23:26:27 main.py INFO In dataset train: Loss is [0.1213 0.0021 0.0000 0.1193]
Wed, 24 Sep 2025 23:26:27 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:26:27 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:26:27 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:26:27 main.py INFO 		For sarcasm, C_M is 
[[2608    0]
 [   0 2608]]
Wed, 24 Sep 2025 23:26:27 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:26:27 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:26:27 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:26:27 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:26:27 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:26:27 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:26:27 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:26:27 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:26:27 main.py INFO In dataset test: Loss is [1.1595 1.0490 0.0000 0.1105]
Wed, 24 Sep 2025 23:26:27 main.py INFO 		Acc is 0.8849, F1-micro is 0.8849
Wed, 24 Sep 2025 23:26:27 main.py INFO 		F1-macro is 0.8849, AUC is 0.5000
Wed, 24 Sep 2025 23:26:27 main.py INFO 		Pre-macro is 0.8851, Rec_macro is 0.8849
Wed, 24 Sep 2025 23:26:27 main.py INFO 		For sarcasm, C_M is 
[[456  65]
 [ 55 467]]
Wed, 24 Sep 2025 23:26:27 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:26:27 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:26:27 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:26:27 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:26:27 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:26:27 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:26:27 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:26:27 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:26:27 main.py INFO testacc: 0.8936
Wed, 24 Sep 2025 23:26:43 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:26:43 main.py INFO Time of iter training 15.29 s
Wed, 24 Sep 2025 23:26:43 main.py INFO On iter step 45.0:, global step 2880 Loss-step [1.1667 1.0355 1.0000 1.1266]
Wed, 24 Sep 2025 23:26:46 main.py INFO In dataset train: Loss is [0.1239 0.0046 0.0000 0.1192]
Wed, 24 Sep 2025 23:26:46 main.py INFO 		Acc is 0.9994, F1-micro is 0.9994
Wed, 24 Sep 2025 23:26:46 main.py INFO 		F1-macro is 0.9994, AUC is 0.5000
Wed, 24 Sep 2025 23:26:46 main.py INFO 		Pre-macro is 0.9994, Rec_macro is 0.9994
Wed, 24 Sep 2025 23:26:46 main.py INFO 		For sarcasm, C_M is 
[[2607    1]
 [   2 2606]]
Wed, 24 Sep 2025 23:26:46 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:26:46 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:26:46 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:26:46 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:26:46 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:26:46 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:26:46 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:26:46 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:26:47 main.py INFO In dataset test: Loss is [0.9255 0.8150 0.0000 0.1105]
Wed, 24 Sep 2025 23:26:47 main.py INFO 		Acc is 0.8888, F1-micro is 0.8888
Wed, 24 Sep 2025 23:26:47 main.py INFO 		F1-macro is 0.8887, AUC is 0.5000
Wed, 24 Sep 2025 23:26:47 main.py INFO 		Pre-macro is 0.8895, Rec_macro is 0.8888
Wed, 24 Sep 2025 23:26:47 main.py INFO 		For sarcasm, C_M is 
[[474  47]
 [ 69 453]]
Wed, 24 Sep 2025 23:26:47 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:26:47 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:26:47 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:26:47 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:26:47 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:26:47 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:26:47 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:26:47 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:26:47 main.py INFO testacc: 0.8936
Wed, 24 Sep 2025 23:27:03 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:27:03 main.py INFO Time of iter training 15.38 s
Wed, 24 Sep 2025 23:27:03 main.py INFO On iter step 46.0:, global step 2944 Loss-step [1.1594 1.0290 1.0000 1.1267]
Wed, 24 Sep 2025 23:27:06 main.py INFO In dataset train: Loss is [0.1216 0.0023 0.0000 0.1192]
Wed, 24 Sep 2025 23:27:06 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:27:06 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:27:06 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:27:06 main.py INFO 		For sarcasm, C_M is 
[[2608    0]
 [   0 2608]]
Wed, 24 Sep 2025 23:27:06 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:27:06 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:27:06 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:27:06 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:27:06 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:27:06 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:27:06 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:27:06 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:27:07 main.py INFO In dataset test: Loss is [1.0017 0.8911 0.0000 0.1105]
Wed, 24 Sep 2025 23:27:07 main.py INFO 		Acc is 0.8802, F1-micro is 0.8802
Wed, 24 Sep 2025 23:27:07 main.py INFO 		F1-macro is 0.8801, AUC is 0.5000
Wed, 24 Sep 2025 23:27:07 main.py INFO 		Pre-macro is 0.8807, Rec_macro is 0.8801
Wed, 24 Sep 2025 23:27:07 main.py INFO 		For sarcasm, C_M is 
[[449  72]
 [ 53 469]]
Wed, 24 Sep 2025 23:27:07 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:27:07 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:27:07 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:27:07 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:27:07 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:27:07 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:27:07 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:27:07 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:27:07 main.py INFO testacc: 0.8936
Wed, 24 Sep 2025 23:27:22 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:27:22 main.py INFO Time of iter training 15.34 s
Wed, 24 Sep 2025 23:27:22 main.py INFO On iter step 47.0:, global step 3008 Loss-step [1.1556 1.0254 1.0000 1.1269]
Wed, 24 Sep 2025 23:27:26 main.py INFO In dataset train: Loss is [0.1208 0.0016 0.0000 0.1192]
Wed, 24 Sep 2025 23:27:26 main.py INFO 		Acc is 0.9998, F1-micro is 0.9998
Wed, 24 Sep 2025 23:27:26 main.py INFO 		F1-macro is 0.9998, AUC is 0.5000
Wed, 24 Sep 2025 23:27:26 main.py INFO 		Pre-macro is 0.9998, Rec_macro is 0.9998
Wed, 24 Sep 2025 23:27:26 main.py INFO 		For sarcasm, C_M is 
[[2607    1]
 [   0 2608]]
Wed, 24 Sep 2025 23:27:26 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:27:26 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:27:26 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:27:26 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:27:26 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:27:26 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:27:26 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:27:26 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:27:27 main.py INFO In dataset test: Loss is [1.1312 1.0207 0.0000 0.1105]
Wed, 24 Sep 2025 23:27:27 main.py INFO 		Acc is 0.8802, F1-micro is 0.8802
Wed, 24 Sep 2025 23:27:27 main.py INFO 		F1-macro is 0.8801, AUC is 0.5000
Wed, 24 Sep 2025 23:27:27 main.py INFO 		Pre-macro is 0.8804, Rec_macro is 0.8801
Wed, 24 Sep 2025 23:27:27 main.py INFO 		For sarcasm, C_M is 
[[452  69]
 [ 56 466]]
Wed, 24 Sep 2025 23:27:27 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:27:27 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:27:27 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:27:27 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:27:27 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:27:27 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:27:27 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:27:27 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:27:27 main.py INFO testacc: 0.8936
Wed, 24 Sep 2025 23:27:42 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:27:42 main.py INFO Time of iter training 15.50 s
Wed, 24 Sep 2025 23:27:42 main.py INFO On iter step 48.0:, global step 3072 Loss-step [1.1548 1.0256 1.0000 1.1259]
Wed, 24 Sep 2025 23:27:47 main.py INFO In dataset train: Loss is [0.1247 0.0054 0.0000 0.1193]
Wed, 24 Sep 2025 23:27:47 main.py INFO 		Acc is 0.9998, F1-micro is 0.9998
Wed, 24 Sep 2025 23:27:47 main.py INFO 		F1-macro is 0.9998, AUC is 0.5000
Wed, 24 Sep 2025 23:27:47 main.py INFO 		Pre-macro is 0.9998, Rec_macro is 0.9998
Wed, 24 Sep 2025 23:27:47 main.py INFO 		For sarcasm, C_M is 
[[2608    0]
 [   1 2607]]
Wed, 24 Sep 2025 23:27:47 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:27:47 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:27:47 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:27:47 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:27:47 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:27:47 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:27:47 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:27:47 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:27:47 main.py INFO In dataset test: Loss is [0.8556 0.7451 0.0000 0.1105]
Wed, 24 Sep 2025 23:27:47 main.py INFO 		Acc is 0.8802, F1-micro is 0.8802
Wed, 24 Sep 2025 23:27:47 main.py INFO 		F1-macro is 0.8801, AUC is 0.5000
Wed, 24 Sep 2025 23:27:47 main.py INFO 		Pre-macro is 0.8803, Rec_macro is 0.8802
Wed, 24 Sep 2025 23:27:47 main.py INFO 		For sarcasm, C_M is 
[[464  57]
 [ 68 454]]
Wed, 24 Sep 2025 23:27:47 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:27:47 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:27:47 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:27:47 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:27:47 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:27:47 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:27:47 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:27:47 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:27:47 main.py INFO testacc: 0.8936
Wed, 24 Sep 2025 23:28:03 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:28:03 main.py INFO Time of iter training 15.73 s
Wed, 24 Sep 2025 23:28:03 main.py INFO On iter step 49.0:, global step 3136 Loss-step [1.1544 1.0239 1.0000 1.1274]
Wed, 24 Sep 2025 23:28:07 main.py INFO In dataset train: Loss is [0.1250 0.0058 0.0000 0.1193]
Wed, 24 Sep 2025 23:28:07 main.py INFO 		Acc is 0.9992, F1-micro is 0.9992
Wed, 24 Sep 2025 23:28:07 main.py INFO 		F1-macro is 0.9992, AUC is 0.5000
Wed, 24 Sep 2025 23:28:07 main.py INFO 		Pre-macro is 0.9992, Rec_macro is 0.9992
Wed, 24 Sep 2025 23:28:07 main.py INFO 		For sarcasm, C_M is 
[[2608    0]
 [   4 2604]]
Wed, 24 Sep 2025 23:28:07 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:28:07 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:28:07 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:28:07 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:28:07 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:28:07 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:28:07 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:28:07 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:28:08 main.py INFO In dataset test: Loss is [0.9914 0.8809 0.0000 0.1105]
Wed, 24 Sep 2025 23:28:08 main.py INFO 		Acc is 0.8744, F1-micro is 0.8744
Wed, 24 Sep 2025 23:28:08 main.py INFO 		F1-macro is 0.8743, AUC is 0.5000
Wed, 24 Sep 2025 23:28:08 main.py INFO 		Pre-macro is 0.8763, Rec_macro is 0.8744
Wed, 24 Sep 2025 23:28:08 main.py INFO 		For sarcasm, C_M is 
[[474  47]
 [ 84 438]]
Wed, 24 Sep 2025 23:28:08 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:28:08 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:28:08 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:28:08 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:28:08 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:28:08 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:28:08 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:28:08 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:28:08 main.py INFO testacc: 0.8936
Wed, 24 Sep 2025 23:28:23 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:28:23 main.py INFO Time of iter training 15.39 s
Wed, 24 Sep 2025 23:28:23 main.py INFO On iter step 50.0:, global step 3200 Loss-step [1.1542 1.0242 1.0000 1.1270]
Wed, 24 Sep 2025 23:28:27 main.py INFO In dataset train: Loss is [0.1207 0.0015 0.0000 0.1193]
Wed, 24 Sep 2025 23:28:27 main.py INFO 		Acc is 0.9998, F1-micro is 0.9998
Wed, 24 Sep 2025 23:28:27 main.py INFO 		F1-macro is 0.9998, AUC is 0.5000
Wed, 24 Sep 2025 23:28:27 main.py INFO 		Pre-macro is 0.9998, Rec_macro is 0.9998
Wed, 24 Sep 2025 23:28:27 main.py INFO 		For sarcasm, C_M is 
[[2607    1]
 [   0 2608]]
Wed, 24 Sep 2025 23:28:27 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:28:27 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:28:27 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:28:27 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:28:27 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:28:27 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:28:27 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:28:27 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:28:27 main.py INFO In dataset test: Loss is [1.2879 1.1774 0.0000 0.1105]
Wed, 24 Sep 2025 23:28:27 main.py INFO 		Acc is 0.8821, F1-micro is 0.8821
Wed, 24 Sep 2025 23:28:27 main.py INFO 		F1-macro is 0.8819, AUC is 0.5000
Wed, 24 Sep 2025 23:28:27 main.py INFO 		Pre-macro is 0.8842, Rec_macro is 0.8820
Wed, 24 Sep 2025 23:28:27 main.py INFO 		For sarcasm, C_M is 
[[440  81]
 [ 42 480]]
Wed, 24 Sep 2025 23:28:27 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:28:27 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:28:27 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:28:27 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:28:27 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:28:27 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:28:27 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:28:27 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:28:27 main.py INFO testacc: 0.8936
Wed, 24 Sep 2025 23:28:43 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:28:43 main.py INFO Time of iter training 15.36 s
Wed, 24 Sep 2025 23:28:43 main.py INFO On iter step 51.0:, global step 3264 Loss-step [1.1494 1.0213 1.0000 1.1254]
Wed, 24 Sep 2025 23:28:46 main.py INFO In dataset train: Loss is [0.1202 0.0009 0.0000 0.1192]
Wed, 24 Sep 2025 23:28:46 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:28:46 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:28:46 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:28:46 main.py INFO 		For sarcasm, C_M is 
[[2608    0]
 [   0 2608]]
Wed, 24 Sep 2025 23:28:46 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:28:46 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:28:46 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:28:46 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:28:46 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:28:46 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:28:46 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:28:46 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:28:47 main.py INFO In dataset test: Loss is [1.3439 1.2334 0.0000 0.1105]
Wed, 24 Sep 2025 23:28:47 main.py INFO 		Acc is 0.8888, F1-micro is 0.8888
Wed, 24 Sep 2025 23:28:47 main.py INFO 		F1-macro is 0.8888, AUC is 0.5000
Wed, 24 Sep 2025 23:28:47 main.py INFO 		Pre-macro is 0.8890, Rec_macro is 0.8888
Wed, 24 Sep 2025 23:28:47 main.py INFO 		For sarcasm, C_M is 
[[457  64]
 [ 52 470]]
Wed, 24 Sep 2025 23:28:47 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:28:47 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:28:47 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:28:47 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:28:47 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:28:47 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:28:47 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:28:47 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:28:47 main.py INFO testacc: 0.8936
Wed, 24 Sep 2025 23:29:02 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:29:02 main.py INFO Time of iter training 15.20 s
Wed, 24 Sep 2025 23:29:02 main.py INFO On iter step 52.0:, global step 3328 Loss-step [1.1507 1.0196 1.0005 1.1281]
Wed, 24 Sep 2025 23:29:06 main.py INFO In dataset train: Loss is [0.1202 0.0009 0.0000 0.1192]
Wed, 24 Sep 2025 23:29:06 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:29:06 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:29:06 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:29:06 main.py INFO 		For sarcasm, C_M is 
[[2608    0]
 [   0 2608]]
Wed, 24 Sep 2025 23:29:06 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:29:06 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:29:06 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:29:06 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:29:06 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:29:06 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:29:06 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:29:06 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:29:07 main.py INFO In dataset test: Loss is [1.3000 1.1895 0.0000 0.1105]
Wed, 24 Sep 2025 23:29:07 main.py INFO 		Acc is 0.8926, F1-micro is 0.8926
Wed, 24 Sep 2025 23:29:07 main.py INFO 		F1-macro is 0.8926, AUC is 0.5000
Wed, 24 Sep 2025 23:29:07 main.py INFO 		Pre-macro is 0.8926, Rec_macro is 0.8926
Wed, 24 Sep 2025 23:29:07 main.py INFO 		For sarcasm, C_M is 
[[465  56]
 [ 56 466]]
Wed, 24 Sep 2025 23:29:07 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:29:07 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:29:07 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:29:07 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:29:07 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:29:07 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:29:07 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:29:07 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:29:07 main.py INFO testacc: 0.8936
Wed, 24 Sep 2025 23:29:22 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:29:22 main.py INFO Time of iter training 15.41 s
Wed, 24 Sep 2025 23:29:22 main.py INFO On iter step 53.0:, global step 3392 Loss-step [1.1551 1.0234 1.0021 1.1263]
Wed, 24 Sep 2025 23:29:26 main.py INFO In dataset train: Loss is [0.1200 0.0007 0.0000 0.1192]
Wed, 24 Sep 2025 23:29:26 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:29:26 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:29:26 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:29:26 main.py INFO 		For sarcasm, C_M is 
[[2608    0]
 [   0 2608]]
Wed, 24 Sep 2025 23:29:26 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:29:26 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:29:26 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:29:26 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:29:26 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:29:26 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:29:26 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:29:26 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:29:27 main.py INFO In dataset test: Loss is [1.3153 1.2048 0.0000 0.1105]
Wed, 24 Sep 2025 23:29:27 main.py INFO 		Acc is 0.8945, F1-micro is 0.8945
Wed, 24 Sep 2025 23:29:27 main.py INFO 		F1-macro is 0.8945, AUC is 0.5000
Wed, 24 Sep 2025 23:29:27 main.py INFO 		Pre-macro is 0.8949, Rec_macro is 0.8945
Wed, 24 Sep 2025 23:29:27 main.py INFO 		For sarcasm, C_M is 
[[458  63]
 [ 47 475]]
Wed, 24 Sep 2025 23:29:27 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:29:27 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:29:27 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:29:27 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:29:27 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:29:27 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:29:27 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:29:27 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:29:27 main.py INFO testacc: 0.8945
Wed, 24 Sep 2025 23:29:42 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:29:42 main.py INFO Time of iter training 15.33 s
Wed, 24 Sep 2025 23:29:42 main.py INFO On iter step 54.0:, global step 3456 Loss-step [1.1779 1.0449 1.0000 1.1273]
Wed, 24 Sep 2025 23:29:46 main.py INFO In dataset train: Loss is [0.1234 0.0041 0.0001 0.1192]
Wed, 24 Sep 2025 23:29:46 main.py INFO 		Acc is 0.9996, F1-micro is 0.9996
Wed, 24 Sep 2025 23:29:46 main.py INFO 		F1-macro is 0.9996, AUC is 0.5000
Wed, 24 Sep 2025 23:29:46 main.py INFO 		Pre-macro is 0.9996, Rec_macro is 0.9996
Wed, 24 Sep 2025 23:29:46 main.py INFO 		For sarcasm, C_M is 
[[2608    0]
 [   2 2606]]
Wed, 24 Sep 2025 23:29:46 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:29:46 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:29:46 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:29:46 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:29:46 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:29:46 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:29:46 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:29:46 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:29:46 main.py INFO In dataset test: Loss is [0.9022 0.7916 0.0001 0.1105]
Wed, 24 Sep 2025 23:29:46 main.py INFO 		Acc is 0.8917, F1-micro is 0.8917
Wed, 24 Sep 2025 23:29:46 main.py INFO 		F1-macro is 0.8917, AUC is 0.5000
Wed, 24 Sep 2025 23:29:46 main.py INFO 		Pre-macro is 0.8917, Rec_macro is 0.8917
Wed, 24 Sep 2025 23:29:46 main.py INFO 		For sarcasm, C_M is 
[[461  60]
 [ 53 469]]
Wed, 24 Sep 2025 23:29:46 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:29:46 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:29:46 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:29:46 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:29:46 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:29:46 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:29:46 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:29:46 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:29:46 main.py INFO testacc: 0.8945
Wed, 24 Sep 2025 23:30:02 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:30:02 main.py INFO Time of iter training 15.90 s
Wed, 24 Sep 2025 23:30:02 main.py INFO On iter step 55.0:, global step 3520 Loss-step [1.1453 1.0174 1.0000 1.1256]
Wed, 24 Sep 2025 23:30:06 main.py INFO In dataset train: Loss is [0.1199 0.0006 0.0000 0.1192]
Wed, 24 Sep 2025 23:30:06 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:30:06 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:30:06 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:30:06 main.py INFO 		For sarcasm, C_M is 
[[2608    0]
 [   0 2608]]
Wed, 24 Sep 2025 23:30:06 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:30:06 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:30:06 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:30:06 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:30:06 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:30:06 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:30:06 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:30:06 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:30:07 main.py INFO In dataset test: Loss is [1.3623 1.2518 0.0000 0.1105]
Wed, 24 Sep 2025 23:30:07 main.py INFO 		Acc is 0.8869, F1-micro is 0.8869
Wed, 24 Sep 2025 23:30:07 main.py INFO 		F1-macro is 0.8869, AUC is 0.5000
Wed, 24 Sep 2025 23:30:07 main.py INFO 		Pre-macro is 0.8869, Rec_macro is 0.8869
Wed, 24 Sep 2025 23:30:07 main.py INFO 		For sarcasm, C_M is 
[[461  60]
 [ 58 464]]
Wed, 24 Sep 2025 23:30:07 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:30:07 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:30:07 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:30:07 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:30:07 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:30:07 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:30:07 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:30:07 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:30:07 main.py INFO testacc: 0.8945
Wed, 24 Sep 2025 23:30:22 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:30:22 main.py INFO Time of iter training 15.36 s
Wed, 24 Sep 2025 23:30:22 main.py INFO On iter step 56.0:, global step 3584 Loss-step [1.1482 1.0178 1.0000 1.1281]
Wed, 24 Sep 2025 23:30:26 main.py INFO In dataset train: Loss is [0.1199 0.0006 0.0000 0.1193]
Wed, 24 Sep 2025 23:30:26 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:30:26 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:30:26 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:30:26 main.py INFO 		For sarcasm, C_M is 
[[2608    0]
 [   0 2608]]
Wed, 24 Sep 2025 23:30:26 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:30:26 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:30:26 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:30:26 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:30:26 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:30:26 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:30:26 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:30:26 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:30:27 main.py INFO In dataset test: Loss is [1.2768 1.1663 0.0000 0.1105]
Wed, 24 Sep 2025 23:30:27 main.py INFO 		Acc is 0.8849, F1-micro is 0.8849
Wed, 24 Sep 2025 23:30:27 main.py INFO 		F1-macro is 0.8849, AUC is 0.5000
Wed, 24 Sep 2025 23:30:27 main.py INFO 		Pre-macro is 0.8851, Rec_macro is 0.8850
Wed, 24 Sep 2025 23:30:27 main.py INFO 		For sarcasm, C_M is 
[[466  55]
 [ 65 457]]
Wed, 24 Sep 2025 23:30:27 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:30:27 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:30:27 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:30:27 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:30:27 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:30:27 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:30:27 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:30:27 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:30:27 main.py INFO testacc: 0.8945
Wed, 24 Sep 2025 23:30:42 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:30:42 main.py INFO Time of iter training 15.33 s
Wed, 24 Sep 2025 23:30:42 main.py INFO On iter step 57.0:, global step 3648 Loss-step [1.1448 1.0173 1.0000 1.1254]
Wed, 24 Sep 2025 23:30:46 main.py INFO In dataset train: Loss is [0.1219 0.0027 0.0000 0.1192]
Wed, 24 Sep 2025 23:30:46 main.py INFO 		Acc is 0.9998, F1-micro is 0.9998
Wed, 24 Sep 2025 23:30:46 main.py INFO 		F1-macro is 0.9998, AUC is 0.5000
Wed, 24 Sep 2025 23:30:46 main.py INFO 		Pre-macro is 0.9998, Rec_macro is 0.9998
Wed, 24 Sep 2025 23:30:46 main.py INFO 		For sarcasm, C_M is 
[[2608    0]
 [   1 2607]]
Wed, 24 Sep 2025 23:30:46 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:30:46 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:30:46 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:30:46 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:30:46 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:30:46 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:30:46 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:30:46 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:30:46 main.py INFO In dataset test: Loss is [1.0153 0.9048 0.0000 0.1105]
Wed, 24 Sep 2025 23:30:46 main.py INFO 		Acc is 0.8840, F1-micro is 0.8840
Wed, 24 Sep 2025 23:30:46 main.py INFO 		F1-macro is 0.8840, AUC is 0.5000
Wed, 24 Sep 2025 23:30:46 main.py INFO 		Pre-macro is 0.8845, Rec_macro is 0.8840
Wed, 24 Sep 2025 23:30:46 main.py INFO 		For sarcasm, C_M is 
[[470  51]
 [ 70 452]]
Wed, 24 Sep 2025 23:30:46 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:30:46 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:30:46 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:30:46 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:30:46 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:30:46 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:30:46 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:30:46 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:30:46 main.py INFO testacc: 0.8945
Wed, 24 Sep 2025 23:31:02 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:31:02 main.py INFO Time of iter training 15.52 s
Wed, 24 Sep 2025 23:31:02 main.py INFO On iter step 58.0:, global step 3712 Loss-step [1.1499 1.0201 1.0007 1.1265]
Wed, 24 Sep 2025 23:31:06 main.py INFO In dataset train: Loss is [0.1228 0.0036 0.0000 0.1192]
Wed, 24 Sep 2025 23:31:06 main.py INFO 		Acc is 0.9996, F1-micro is 0.9996
Wed, 24 Sep 2025 23:31:06 main.py INFO 		F1-macro is 0.9996, AUC is 0.5000
Wed, 24 Sep 2025 23:31:06 main.py INFO 		Pre-macro is 0.9996, Rec_macro is 0.9996
Wed, 24 Sep 2025 23:31:06 main.py INFO 		For sarcasm, C_M is 
[[2608    0]
 [   2 2606]]
Wed, 24 Sep 2025 23:31:06 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:31:06 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:31:06 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:31:06 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:31:06 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:31:06 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:31:06 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:31:06 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:31:07 main.py INFO In dataset test: Loss is [1.0406 0.9300 0.0000 0.1105]
Wed, 24 Sep 2025 23:31:07 main.py INFO 		Acc is 0.8830, F1-micro is 0.8830
Wed, 24 Sep 2025 23:31:07 main.py INFO 		F1-macro is 0.8829, AUC is 0.5000
Wed, 24 Sep 2025 23:31:07 main.py INFO 		Pre-macro is 0.8845, Rec_macro is 0.8831
Wed, 24 Sep 2025 23:31:07 main.py INFO 		For sarcasm, C_M is 
[[476  45]
 [ 77 445]]
Wed, 24 Sep 2025 23:31:07 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:31:07 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:31:07 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:31:07 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:31:07 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:31:07 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:31:07 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:31:07 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:31:07 main.py INFO testacc: 0.8945
Wed, 24 Sep 2025 23:31:22 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:31:22 main.py INFO Time of iter training 15.32 s
Wed, 24 Sep 2025 23:31:22 main.py INFO On iter step 59.0:, global step 3776 Loss-step [1.1465 1.0172 1.0000 1.1270]
Wed, 24 Sep 2025 23:31:26 main.py INFO In dataset train: Loss is [0.1225 0.0032 0.0000 0.1192]
Wed, 24 Sep 2025 23:31:26 main.py INFO 		Acc is 0.9994, F1-micro is 0.9994
Wed, 24 Sep 2025 23:31:26 main.py INFO 		F1-macro is 0.9994, AUC is 0.5000
Wed, 24 Sep 2025 23:31:26 main.py INFO 		Pre-macro is 0.9994, Rec_macro is 0.9994
Wed, 24 Sep 2025 23:31:26 main.py INFO 		For sarcasm, C_M is 
[[2606    2]
 [   1 2607]]
Wed, 24 Sep 2025 23:31:26 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:31:26 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:31:26 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:31:26 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:31:26 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:31:26 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:31:26 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:31:26 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:31:26 main.py INFO In dataset test: Loss is [1.1118 1.0012 0.0000 0.1105]
Wed, 24 Sep 2025 23:31:26 main.py INFO 		Acc is 0.8744, F1-micro is 0.8744
Wed, 24 Sep 2025 23:31:26 main.py INFO 		F1-macro is 0.8743, AUC is 0.5000
Wed, 24 Sep 2025 23:31:26 main.py INFO 		Pre-macro is 0.8757, Rec_macro is 0.8744
Wed, 24 Sep 2025 23:31:26 main.py INFO 		For sarcasm, C_M is 
[[440  81]
 [ 50 472]]
Wed, 24 Sep 2025 23:31:26 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:31:26 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:31:26 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:31:26 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:31:26 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:31:26 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:31:26 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:31:26 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:31:26 main.py INFO testacc: 0.8945
Wed, 24 Sep 2025 23:31:42 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:31:42 main.py INFO Time of iter training 15.88 s
Wed, 24 Sep 2025 23:31:42 main.py INFO On iter step 60.0:, global step 3840 Loss-step [1.1580 1.0273 1.0000 1.1272]
Wed, 24 Sep 2025 23:31:46 main.py INFO In dataset train: Loss is [0.1200 0.0008 0.0000 0.1192]
Wed, 24 Sep 2025 23:31:46 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:31:46 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:31:46 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:31:46 main.py INFO 		For sarcasm, C_M is 
[[2608    0]
 [   0 2608]]
Wed, 24 Sep 2025 23:31:46 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:31:46 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:31:46 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:31:46 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:31:46 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:31:46 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:31:46 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:31:46 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:31:47 main.py INFO In dataset test: Loss is [1.5346 1.4240 0.0000 0.1105]
Wed, 24 Sep 2025 23:31:47 main.py INFO 		Acc is 0.8821, F1-micro is 0.8821
Wed, 24 Sep 2025 23:31:47 main.py INFO 		F1-macro is 0.8821, AUC is 0.5000
Wed, 24 Sep 2025 23:31:47 main.py INFO 		Pre-macro is 0.8822, Rec_macro is 0.8821
Wed, 24 Sep 2025 23:31:47 main.py INFO 		For sarcasm, C_M is 
[[465  56]
 [ 67 455]]
Wed, 24 Sep 2025 23:31:47 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:31:47 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:31:47 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:31:47 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:31:47 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:31:47 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:31:47 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:31:47 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:31:47 main.py INFO testacc: 0.8945
Wed, 24 Sep 2025 23:32:02 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:32:02 main.py INFO Time of iter training 15.36 s
Wed, 24 Sep 2025 23:32:02 main.py INFO On iter step 61.0:, global step 3904 Loss-step [1.1434 1.0146 1.0000 1.1270]
Wed, 24 Sep 2025 23:32:06 main.py INFO In dataset train: Loss is [0.1203 0.0010 0.0000 0.1192]
Wed, 24 Sep 2025 23:32:06 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:32:06 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:32:06 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:32:06 main.py INFO 		For sarcasm, C_M is 
[[2608    0]
 [   0 2608]]
Wed, 24 Sep 2025 23:32:06 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:32:06 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:32:06 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:32:06 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:32:06 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:32:06 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:32:06 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:32:06 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:32:07 main.py INFO In dataset test: Loss is [1.6373 1.5268 0.0000 0.1105]
Wed, 24 Sep 2025 23:32:07 main.py INFO 		Acc is 0.8782, F1-micro is 0.8782
Wed, 24 Sep 2025 23:32:07 main.py INFO 		F1-macro is 0.8781, AUC is 0.5000
Wed, 24 Sep 2025 23:32:07 main.py INFO 		Pre-macro is 0.8794, Rec_macro is 0.8782
Wed, 24 Sep 2025 23:32:07 main.py INFO 		For sarcasm, C_M is 
[[443  78]
 [ 49 473]]
Wed, 24 Sep 2025 23:32:07 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:32:07 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:32:07 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:32:07 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:32:07 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:32:07 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:32:07 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:32:07 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:32:07 main.py INFO testacc: 0.8945
Wed, 24 Sep 2025 23:32:22 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:32:22 main.py INFO Time of iter training 15.47 s
Wed, 24 Sep 2025 23:32:22 main.py INFO On iter step 62.0:, global step 3968 Loss-step [1.1534 1.0243 1.0000 1.1261]
Wed, 24 Sep 2025 23:32:26 main.py INFO In dataset train: Loss is [0.1216 0.0023 0.0000 0.1192]
Wed, 24 Sep 2025 23:32:26 main.py INFO 		Acc is 0.9998, F1-micro is 0.9998
Wed, 24 Sep 2025 23:32:26 main.py INFO 		F1-macro is 0.9998, AUC is 0.5000
Wed, 24 Sep 2025 23:32:26 main.py INFO 		Pre-macro is 0.9998, Rec_macro is 0.9998
Wed, 24 Sep 2025 23:32:26 main.py INFO 		For sarcasm, C_M is 
[[2607    1]
 [   0 2608]]
Wed, 24 Sep 2025 23:32:26 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:32:26 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:32:26 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:32:26 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:32:26 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:32:26 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:32:26 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:32:26 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:32:27 main.py INFO In dataset test: Loss is [1.0234 0.9129 0.0000 0.1105]
Wed, 24 Sep 2025 23:32:27 main.py INFO 		Acc is 0.8763, F1-micro is 0.8763
Wed, 24 Sep 2025 23:32:27 main.py INFO 		F1-macro is 0.8763, AUC is 0.5000
Wed, 24 Sep 2025 23:32:27 main.py INFO 		Pre-macro is 0.8767, Rec_macro is 0.8763
Wed, 24 Sep 2025 23:32:27 main.py INFO 		For sarcasm, C_M is 
[[448  73]
 [ 56 466]]
Wed, 24 Sep 2025 23:32:27 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:32:27 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:32:27 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:32:27 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:32:27 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:32:27 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:32:27 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:32:27 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:32:27 main.py INFO testacc: 0.8945
Wed, 24 Sep 2025 23:32:42 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:32:42 main.py INFO Time of iter training 15.33 s
Wed, 24 Sep 2025 23:32:42 main.py INFO On iter step 63.0:, global step 4032 Loss-step [1.1509 1.0214 1.0000 1.1268]
Wed, 24 Sep 2025 23:32:46 main.py INFO In dataset train: Loss is [0.1201 0.0009 0.0000 0.1192]
Wed, 24 Sep 2025 23:32:46 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:32:46 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:32:46 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:32:46 main.py INFO 		For sarcasm, C_M is 
[[2608    0]
 [   0 2608]]
Wed, 24 Sep 2025 23:32:46 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:32:46 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:32:46 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:32:46 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:32:46 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:32:46 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:32:46 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:32:46 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:32:46 main.py INFO In dataset test: Loss is [1.5107 1.4002 0.0000 0.1105]
Wed, 24 Sep 2025 23:32:46 main.py INFO 		Acc is 0.8763, F1-micro is 0.8763
Wed, 24 Sep 2025 23:32:46 main.py INFO 		F1-macro is 0.8763, AUC is 0.5000
Wed, 24 Sep 2025 23:32:46 main.py INFO 		Pre-macro is 0.8764, Rec_macro is 0.8763
Wed, 24 Sep 2025 23:32:46 main.py INFO 		For sarcasm, C_M is 
[[452  69]
 [ 60 462]]
Wed, 24 Sep 2025 23:32:46 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:32:46 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:32:46 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:32:46 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:32:46 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:32:46 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:32:46 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:32:46 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:32:46 main.py INFO testacc: 0.8945
Wed, 24 Sep 2025 23:33:03 main.py INFO --------------------------------------------------
Wed, 24 Sep 2025 23:33:03 main.py INFO Time of iter training 16.15 s
Wed, 24 Sep 2025 23:33:03 main.py INFO On iter step 64.0:, global step 4096 Loss-step [1.1520 1.0234 1.0000 1.1257]
Wed, 24 Sep 2025 23:33:06 main.py INFO In dataset train: Loss is [0.1199 0.0006 0.0000 0.1192]
Wed, 24 Sep 2025 23:33:06 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:33:06 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:33:06 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:33:06 main.py INFO 		For sarcasm, C_M is 
[[2608    0]
 [   0 2608]]
Wed, 24 Sep 2025 23:33:06 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:33:06 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:33:06 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:33:06 main.py INFO 		For literal, C_M is 
[[1528    0]
 [   0 3688]]
Wed, 24 Sep 2025 23:33:06 main.py INFO 		Acc is 0.9248, F1-micro is 0.9248
Wed, 24 Sep 2025 23:33:06 main.py INFO 		F1-macro is 0.9246, AUC is 0.5000
Wed, 24 Sep 2025 23:33:06 main.py INFO 		Pre-macro is 0.9334, Rec_macro is 0.9265
Wed, 24 Sep 2025 23:33:06 main.py INFO 		For deep, C_M is 
[[2550    0]
 [ 392 2274]]
Wed, 24 Sep 2025 23:33:07 main.py INFO In dataset test: Loss is [1.2679 1.1574 0.0000 0.1105]
Wed, 24 Sep 2025 23:33:07 main.py INFO 		Acc is 0.8955, F1-micro is 0.8955
Wed, 24 Sep 2025 23:33:07 main.py INFO 		F1-macro is 0.8955, AUC is 0.5000
Wed, 24 Sep 2025 23:33:07 main.py INFO 		Pre-macro is 0.8956, Rec_macro is 0.8955
Wed, 24 Sep 2025 23:33:07 main.py INFO 		For sarcasm, C_M is 
[[463  58]
 [ 51 471]]
Wed, 24 Sep 2025 23:33:07 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Wed, 24 Sep 2025 23:33:07 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Wed, 24 Sep 2025 23:33:07 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Wed, 24 Sep 2025 23:33:07 main.py INFO 		For literal, C_M is 
[[283   0]
 [  0 760]]
Wed, 24 Sep 2025 23:33:07 main.py INFO 		Acc is 0.9319, F1-micro is 0.9319
Wed, 24 Sep 2025 23:33:07 main.py INFO 		F1-macro is 0.9317, AUC is 0.5000
Wed, 24 Sep 2025 23:33:07 main.py INFO 		Pre-macro is 0.9398, Rec_macro is 0.9323
Wed, 24 Sep 2025 23:33:07 main.py INFO 		For deep, C_M is 
[[519   0]
 [ 71 453]]
Wed, 24 Sep 2025 23:33:07 main.py INFO testacc: 0.8955
