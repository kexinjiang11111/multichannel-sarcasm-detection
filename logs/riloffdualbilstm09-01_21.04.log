Mon, 01 Sep 2025 21:05:11 dataUtils.py INFO 构建词汇表...
Mon, 01 Sep 2025 21:05:46 main.py INFO model parameters: Namespace(batch_size=128, bidirectional=1, breakpoint=-1, cell_dropout_rate=0.5, data_dir='./riloff/spacy/', device=device(type='cuda'), dim_bert=768, dim_hidden=256, dim_input=300, embed_dropout_rate=0.5, final_dropout_rate=0.5, iter_num=4800, lambda1=0.5, learning_rate=0.001, linear_dropout_rate=0.1, lr_bert=5e-05, lr_word_vector=0.0001, margin=0.5, max_length_sen=100, model_dir='models/riloff_dualbilstm/', multi_dim=20, n_class=2, n_layers=3, name_dataset='riloff', name_model='dualbilstm', optim_type='Adam', path_wordvec='glove.840B.300d.txt', per_checkpoint=64, predict=0, predict_dir='./predict/', rnn_type='LSTM', save_model=0, seed=2021, supcon=1, t_sne=0, tokenizer='spacy', voc_size=30000, weight_decay=0)
Mon, 01 Sep 2025 21:05:46 main.py INFO Use device: cuda
Mon, 01 Sep 2025 21:05:47 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:05:47 main.py INFO Time of iter training 0.00 s
Mon, 01 Sep 2025 21:05:47 main.py INFO On iter step 0.0:, global step 0 Loss-step [2.7183 2.7183 2.7183 2.7183]
Mon, 01 Sep 2025 21:05:47 main.py INFO In dataset train: Loss is [2.0744 0.6869 0.6928 0.6947]
Mon, 01 Sep 2025 21:05:47 main.py INFO 		Acc is 0.6814, F1-micro is 0.6814
Mon, 01 Sep 2025 21:05:47 main.py INFO 		F1-macro is 0.5102, AUC is 0.5000
Mon, 01 Sep 2025 21:05:47 main.py INFO 		Pre-macro is 0.5107, Rec_macro is 0.5101
Mon, 01 Sep 2025 21:05:47 main.py INFO 		For sarcasm, C_M is 
[[847 202]
 [222  60]]
Mon, 01 Sep 2025 21:05:47 main.py INFO 		Acc is 0.7881, F1-micro is 0.7881
Mon, 01 Sep 2025 21:05:47 main.py INFO 		F1-macro is 0.4408, AUC is 0.5000
Mon, 01 Sep 2025 21:05:47 main.py INFO 		Pre-macro is 0.3941, Rec_macro is 0.5000
Mon, 01 Sep 2025 21:05:47 main.py INFO 		For literal, C_M is 
[[   0  282]
 [   0 1049]]
Mon, 01 Sep 2025 21:05:47 main.py INFO 		Acc is 0.3651, F1-micro is 0.3651
Mon, 01 Sep 2025 21:05:47 main.py INFO 		F1-macro is 0.2675, AUC is 0.5000
Mon, 01 Sep 2025 21:05:47 main.py INFO 		Pre-macro is 0.1826, Rec_macro is 0.5000
Mon, 01 Sep 2025 21:05:47 main.py INFO 		For deep, C_M is 
[[486   0]
 [845   0]]
Mon, 01 Sep 2025 21:05:47 main.py INFO In dataset test: Loss is [2.0744 0.6855 0.6927 0.6962]
Mon, 01 Sep 2025 21:05:47 main.py INFO 		Acc is 0.6351, F1-micro is 0.6351
Mon, 01 Sep 2025 21:05:47 main.py INFO 		F1-macro is 0.4948, AUC is 0.5000
Mon, 01 Sep 2025 21:05:47 main.py INFO 		Pre-macro is 0.4948, Rec_macro is 0.4948
Mon, 01 Sep 2025 21:05:47 main.py INFO 		For sarcasm, C_M is 
[[86 27]
 [27  8]]
Mon, 01 Sep 2025 21:05:47 main.py INFO 		Acc is 0.8108, F1-micro is 0.8108
Mon, 01 Sep 2025 21:05:47 main.py INFO 		F1-macro is 0.4478, AUC is 0.5000
Mon, 01 Sep 2025 21:05:47 main.py INFO 		Pre-macro is 0.4054, Rec_macro is 0.5000
Mon, 01 Sep 2025 21:05:47 main.py INFO 		For literal, C_M is 
[[  0  28]
 [  0 120]]
Mon, 01 Sep 2025 21:05:47 main.py INFO 		Acc is 0.3176, F1-micro is 0.3176
Mon, 01 Sep 2025 21:05:47 main.py INFO 		F1-macro is 0.2410, AUC is 0.5000
Mon, 01 Sep 2025 21:05:47 main.py INFO 		Pre-macro is 0.1588, Rec_macro is 0.5000
Mon, 01 Sep 2025 21:05:47 main.py INFO 		For deep, C_M is 
[[ 47   0]
 [101   0]]
Mon, 01 Sep 2025 21:05:47 main.py INFO testacc: 0.6351
Mon, 01 Sep 2025 21:05:55 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:05:55 main.py INFO Time of iter training 7.17 s
Mon, 01 Sep 2025 21:05:55 main.py INFO On iter step 1.0:, global step 64 Loss-step [2.0142 1.4516 1.1199 1.2391]
Mon, 01 Sep 2025 21:05:55 main.py INFO In dataset train: Loss is [0.3478 0.2110 0.0001 0.1367]
Mon, 01 Sep 2025 21:05:55 main.py INFO 		Acc is 0.9361, F1-micro is 0.9361
Mon, 01 Sep 2025 21:05:55 main.py INFO 		F1-macro is 0.8949, AUC is 0.5000
Mon, 01 Sep 2025 21:05:55 main.py INFO 		Pre-macro is 0.9450, Rec_macro is 0.8610
Mon, 01 Sep 2025 21:05:55 main.py INFO 		For sarcasm, C_M is 
[[1040    9]
 [  76  206]]
Mon, 01 Sep 2025 21:05:55 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:05:55 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:05:55 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:05:55 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:05:55 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:05:55 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:05:55 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:05:55 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:05:55 main.py INFO In dataset test: Loss is [0.6073 0.4784 0.0001 0.1288]
Mon, 01 Sep 2025 21:05:55 main.py INFO 		Acc is 0.8716, F1-micro is 0.8716
Mon, 01 Sep 2025 21:05:55 main.py INFO 		F1-macro is 0.7879, AUC is 0.5000
Mon, 01 Sep 2025 21:05:55 main.py INFO 		Pre-macro is 0.8836, Rec_macro is 0.7483
Mon, 01 Sep 2025 21:05:55 main.py INFO 		For sarcasm, C_M is 
[[111   2]
 [ 17  18]]
Mon, 01 Sep 2025 21:05:55 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:05:55 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:05:55 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:05:55 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:05:55 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:05:55 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:05:55 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:05:55 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:05:55 main.py INFO testacc: 0.8716
Mon, 01 Sep 2025 21:06:03 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:06:03 main.py INFO Time of iter training 7.86 s
Mon, 01 Sep 2025 21:06:03 main.py INFO On iter step 2.0:, global step 128 Loss-step [1.4122 1.2293 1.0001 1.1487]
Mon, 01 Sep 2025 21:06:04 main.py INFO In dataset train: Loss is [0.3161 0.1794 0.0001 0.1366]
Mon, 01 Sep 2025 21:06:04 main.py INFO 		Acc is 0.9421, F1-micro is 0.9421
Mon, 01 Sep 2025 21:06:04 main.py INFO 		F1-macro is 0.9191, AUC is 0.5000
Mon, 01 Sep 2025 21:06:04 main.py INFO 		Pre-macro is 0.8961, Rec_macro is 0.9503
Mon, 01 Sep 2025 21:06:04 main.py INFO 		For sarcasm, C_M is 
[[982  67]
 [ 10 272]]
Mon, 01 Sep 2025 21:06:04 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:06:04 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:06:04 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:06:04 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:06:04 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:06:04 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:06:04 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:06:04 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:06:04 main.py INFO In dataset test: Loss is [0.5108 0.3861 0.0001 0.1247]
Mon, 01 Sep 2025 21:06:04 main.py INFO 		Acc is 0.8378, F1-micro is 0.8378
Mon, 01 Sep 2025 21:06:04 main.py INFO 		F1-macro is 0.7709, AUC is 0.5000
Mon, 01 Sep 2025 21:06:04 main.py INFO 		Pre-macro is 0.7768, Rec_macro is 0.7656
Mon, 01 Sep 2025 21:06:04 main.py INFO 		For sarcasm, C_M is 
[[102  11]
 [ 13  22]]
Mon, 01 Sep 2025 21:06:04 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:06:04 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:06:04 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:06:04 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:06:04 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:06:04 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:06:04 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:06:04 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:06:04 main.py INFO testacc: 0.8716
Mon, 01 Sep 2025 21:06:12 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:06:12 main.py INFO Time of iter training 7.87 s
Mon, 01 Sep 2025 21:06:12 main.py INFO On iter step 3.0:, global step 192 Loss-step [1.3463 1.1734 1.0003 1.1470]
Mon, 01 Sep 2025 21:06:12 main.py INFO In dataset train: Loss is [0.1975 0.0610 0.0001 0.1364]
Mon, 01 Sep 2025 21:06:12 main.py INFO 		Acc is 0.9805, F1-micro is 0.9805
Mon, 01 Sep 2025 21:06:12 main.py INFO 		F1-macro is 0.9711, AUC is 0.5000
Mon, 01 Sep 2025 21:06:12 main.py INFO 		Pre-macro is 0.9664, Rec_macro is 0.9759
Mon, 01 Sep 2025 21:06:12 main.py INFO 		For sarcasm, C_M is 
[[1032   17]
 [   9  273]]
Mon, 01 Sep 2025 21:06:12 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:06:12 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:06:12 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:06:12 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:06:12 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:06:12 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:06:12 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:06:12 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:06:12 main.py INFO In dataset test: Loss is [0.7933 0.6676 0.0001 0.1257]
Mon, 01 Sep 2025 21:06:12 main.py INFO 		Acc is 0.8581, F1-micro is 0.8581
Mon, 01 Sep 2025 21:06:12 main.py INFO 		F1-macro is 0.7832, AUC is 0.5000
Mon, 01 Sep 2025 21:06:12 main.py INFO 		Pre-macro is 0.8231, Rec_macro is 0.7592
Mon, 01 Sep 2025 21:06:12 main.py INFO 		For sarcasm, C_M is 
[[107   6]
 [ 15  20]]
Mon, 01 Sep 2025 21:06:12 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:06:12 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:06:12 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:06:12 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:06:12 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:06:12 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:06:12 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:06:12 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:06:12 main.py INFO testacc: 0.8716
Mon, 01 Sep 2025 21:06:20 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:06:20 main.py INFO Time of iter training 7.91 s
Mon, 01 Sep 2025 21:06:20 main.py INFO On iter step 4.0:, global step 256 Loss-step [1.2497 1.0899 1.0001 1.1465]
Mon, 01 Sep 2025 21:06:21 main.py INFO In dataset train: Loss is [0.1624 0.0260 0.0001 0.1363]
Mon, 01 Sep 2025 21:06:21 main.py INFO 		Acc is 0.9932, F1-micro is 0.9932
Mon, 01 Sep 2025 21:06:21 main.py INFO 		F1-macro is 0.9899, AUC is 0.5000
Mon, 01 Sep 2025 21:06:21 main.py INFO 		Pre-macro is 0.9905, Rec_macro is 0.9892
Mon, 01 Sep 2025 21:06:21 main.py INFO 		For sarcasm, C_M is 
[[1045    4]
 [   5  277]]
Mon, 01 Sep 2025 21:06:21 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:06:21 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:06:21 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:06:21 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:06:21 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:06:21 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:06:21 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:06:21 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:06:21 main.py INFO In dataset test: Loss is [0.9079 0.7817 0.0000 0.1262]
Mon, 01 Sep 2025 21:06:21 main.py INFO 		Acc is 0.8716, F1-micro is 0.8716
Mon, 01 Sep 2025 21:06:21 main.py INFO 		F1-macro is 0.7936, AUC is 0.5000
Mon, 01 Sep 2025 21:06:21 main.py INFO 		Pre-macro is 0.8683, Rec_macro is 0.7582
Mon, 01 Sep 2025 21:06:21 main.py INFO 		For sarcasm, C_M is 
[[110   3]
 [ 16  19]]
Mon, 01 Sep 2025 21:06:21 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:06:21 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:06:21 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:06:21 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:06:21 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:06:21 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:06:21 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:06:21 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:06:21 main.py INFO testacc: 0.8716
Mon, 01 Sep 2025 21:06:29 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:06:29 main.py INFO Time of iter training 8.08 s
Mon, 01 Sep 2025 21:06:29 main.py INFO On iter step 5.0:, global step 320 Loss-step [1.2185 1.0619 1.0000 1.1474]
Mon, 01 Sep 2025 21:06:30 main.py INFO In dataset train: Loss is [0.1461 0.0097 0.0000 0.1364]
Mon, 01 Sep 2025 21:06:30 main.py INFO 		Acc is 0.9992, F1-micro is 0.9992
Mon, 01 Sep 2025 21:06:30 main.py INFO 		F1-macro is 0.9989, AUC is 0.5000
Mon, 01 Sep 2025 21:06:30 main.py INFO 		Pre-macro is 0.9995, Rec_macro is 0.9982
Mon, 01 Sep 2025 21:06:30 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   1  281]]
Mon, 01 Sep 2025 21:06:30 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:06:30 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:06:30 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:06:30 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:06:30 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:06:30 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:06:30 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:06:30 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:06:30 main.py INFO In dataset test: Loss is [1.2895 1.1638 0.0000 0.1256]
Mon, 01 Sep 2025 21:06:30 main.py INFO 		Acc is 0.8784, F1-micro is 0.8784
Mon, 01 Sep 2025 21:06:30 main.py INFO 		F1-macro is 0.8070, AUC is 0.5000
Mon, 01 Sep 2025 21:06:30 main.py INFO 		Pre-macro is 0.8748, Rec_macro is 0.7724
Mon, 01 Sep 2025 21:06:30 main.py INFO 		For sarcasm, C_M is 
[[110   3]
 [ 15  20]]
Mon, 01 Sep 2025 21:06:30 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:06:30 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:06:30 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:06:30 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:06:30 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:06:30 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:06:30 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:06:30 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:06:30 main.py INFO testacc: 0.8784
Mon, 01 Sep 2025 21:06:38 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:06:38 main.py INFO Time of iter training 7.74 s
Mon, 01 Sep 2025 21:06:38 main.py INFO On iter step 6.0:, global step 384 Loss-step [1.2309 1.0740 1.0000 1.1460]
Mon, 01 Sep 2025 21:06:38 main.py INFO In dataset train: Loss is [0.1575 0.0212 0.0000 0.1363]
Mon, 01 Sep 2025 21:06:38 main.py INFO 		Acc is 0.9985, F1-micro is 0.9985
Mon, 01 Sep 2025 21:06:38 main.py INFO 		F1-macro is 0.9978, AUC is 0.5000
Mon, 01 Sep 2025 21:06:38 main.py INFO 		Pre-macro is 0.9978, Rec_macro is 0.9978
Mon, 01 Sep 2025 21:06:38 main.py INFO 		For sarcasm, C_M is 
[[1048    1]
 [   1  281]]
Mon, 01 Sep 2025 21:06:38 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:06:38 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:06:38 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:06:38 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:06:38 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:06:38 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:06:38 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:06:38 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:06:38 main.py INFO In dataset test: Loss is [0.8396 0.7132 0.0000 0.1264]
Mon, 01 Sep 2025 21:06:38 main.py INFO 		Acc is 0.8986, F1-micro is 0.8986
Mon, 01 Sep 2025 21:06:38 main.py INFO 		F1-macro is 0.8370, AUC is 0.5000
Mon, 01 Sep 2025 21:06:38 main.py INFO 		Pre-macro is 0.9217, Rec_macro is 0.7956
Mon, 01 Sep 2025 21:06:38 main.py INFO 		For sarcasm, C_M is 
[[112   1]
 [ 14  21]]
Mon, 01 Sep 2025 21:06:38 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:06:38 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:06:38 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:06:38 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:06:38 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:06:38 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:06:38 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:06:38 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:06:38 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:06:46 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:06:46 main.py INFO Time of iter training 8.24 s
Mon, 01 Sep 2025 21:06:46 main.py INFO On iter step 7.0:, global step 448 Loss-step [1.1836 1.0320 1.0000 1.1469]
Mon, 01 Sep 2025 21:06:47 main.py INFO In dataset train: Loss is [0.1418 0.0053 0.0000 0.1365]
Mon, 01 Sep 2025 21:06:47 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:06:47 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:06:47 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:06:47 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:06:47 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:06:47 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:06:47 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:06:47 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:06:47 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:06:47 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:06:47 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:06:47 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:06:47 main.py INFO In dataset test: Loss is [1.0950 0.9668 0.0000 0.1282]
Mon, 01 Sep 2025 21:06:47 main.py INFO 		Acc is 0.8851, F1-micro is 0.8851
Mon, 01 Sep 2025 21:06:47 main.py INFO 		F1-macro is 0.8102, AUC is 0.5000
Mon, 01 Sep 2025 21:06:47 main.py INFO 		Pre-macro is 0.9125, Rec_macro is 0.7670
Mon, 01 Sep 2025 21:06:47 main.py INFO 		For sarcasm, C_M is 
[[112   1]
 [ 16  19]]
Mon, 01 Sep 2025 21:06:47 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:06:47 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:06:47 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:06:47 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:06:47 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:06:47 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:06:47 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:06:47 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:06:47 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:06:54 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:06:54 main.py INFO Time of iter training 7.35 s
Mon, 01 Sep 2025 21:06:54 main.py INFO On iter step 8.0:, global step 512 Loss-step [1.1836 1.0308 1.0000 1.1482]
Mon, 01 Sep 2025 21:06:55 main.py INFO In dataset train: Loss is [0.1569 0.0200 0.0000 0.1368]
Mon, 01 Sep 2025 21:06:55 main.py INFO 		Acc is 0.9977, F1-micro is 0.9977
Mon, 01 Sep 2025 21:06:55 main.py INFO 		F1-macro is 0.9966, AUC is 0.5000
Mon, 01 Sep 2025 21:06:55 main.py INFO 		Pre-macro is 0.9973, Rec_macro is 0.9960
Mon, 01 Sep 2025 21:06:55 main.py INFO 		For sarcasm, C_M is 
[[1048    1]
 [   2  280]]
Mon, 01 Sep 2025 21:06:55 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:06:55 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:06:55 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:06:55 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:06:55 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:06:55 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:06:55 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:06:55 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:06:55 main.py INFO In dataset test: Loss is [0.8372 0.7135 0.0000 0.1237]
Mon, 01 Sep 2025 21:06:55 main.py INFO 		Acc is 0.8784, F1-micro is 0.8784
Mon, 01 Sep 2025 21:06:55 main.py INFO 		F1-macro is 0.8070, AUC is 0.5000
Mon, 01 Sep 2025 21:06:55 main.py INFO 		Pre-macro is 0.8748, Rec_macro is 0.7724
Mon, 01 Sep 2025 21:06:55 main.py INFO 		For sarcasm, C_M is 
[[110   3]
 [ 15  20]]
Mon, 01 Sep 2025 21:06:55 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:06:55 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:06:55 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:06:55 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:06:55 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:06:55 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:06:55 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:06:55 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:06:55 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:07:02 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:07:02 main.py INFO Time of iter training 7.38 s
Mon, 01 Sep 2025 21:07:02 main.py INFO On iter step 9.0:, global step 576 Loss-step [1.1691 1.0201 1.0000 1.1461]
Mon, 01 Sep 2025 21:07:03 main.py INFO In dataset train: Loss is [0.1370 0.0006 0.0000 0.1364]
Mon, 01 Sep 2025 21:07:03 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:07:03 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:07:03 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:07:03 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:07:03 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:07:03 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:07:03 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:07:03 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:07:03 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:07:03 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:07:03 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:07:03 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:07:03 main.py INFO In dataset test: Loss is [1.2269 1.1012 0.0000 0.1256]
Mon, 01 Sep 2025 21:07:03 main.py INFO 		Acc is 0.8716, F1-micro is 0.8716
Mon, 01 Sep 2025 21:07:03 main.py INFO 		F1-macro is 0.7936, AUC is 0.5000
Mon, 01 Sep 2025 21:07:03 main.py INFO 		Pre-macro is 0.8683, Rec_macro is 0.7582
Mon, 01 Sep 2025 21:07:03 main.py INFO 		For sarcasm, C_M is 
[[110   3]
 [ 16  19]]
Mon, 01 Sep 2025 21:07:03 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:07:03 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:07:03 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:07:03 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:07:03 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:07:03 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:07:03 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:07:03 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:07:03 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:07:10 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:07:10 main.py INFO Time of iter training 7.23 s
Mon, 01 Sep 2025 21:07:10 main.py INFO On iter step 10.0:, global step 640 Loss-step [1.1714 1.0213 1.0000 1.1469]
Mon, 01 Sep 2025 21:07:11 main.py INFO In dataset train: Loss is [0.1372 0.0008 0.0000 0.1364]
Mon, 01 Sep 2025 21:07:11 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:07:11 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:07:11 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:07:11 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:07:11 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:07:11 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:07:11 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:07:11 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:07:11 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:07:11 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:07:11 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:07:11 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:07:11 main.py INFO In dataset test: Loss is [1.4590 1.3331 0.0000 0.1259]
Mon, 01 Sep 2025 21:07:11 main.py INFO 		Acc is 0.8716, F1-micro is 0.8716
Mon, 01 Sep 2025 21:07:11 main.py INFO 		F1-macro is 0.7989, AUC is 0.5000
Mon, 01 Sep 2025 21:07:11 main.py INFO 		Pre-macro is 0.8562, Rec_macro is 0.7680
Mon, 01 Sep 2025 21:07:11 main.py INFO 		For sarcasm, C_M is 
[[109   4]
 [ 15  20]]
Mon, 01 Sep 2025 21:07:11 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:07:11 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:07:11 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:07:11 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:07:11 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:07:11 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:07:11 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:07:11 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:07:11 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:07:19 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:07:19 main.py INFO Time of iter training 8.33 s
Mon, 01 Sep 2025 21:07:19 main.py INFO On iter step 11.0:, global step 704 Loss-step [1.1795 1.0286 1.0000 1.1466]
Mon, 01 Sep 2025 21:07:20 main.py INFO In dataset train: Loss is [0.1558 0.0195 0.0000 0.1364]
Mon, 01 Sep 2025 21:07:20 main.py INFO 		Acc is 0.9917, F1-micro is 0.9917
Mon, 01 Sep 2025 21:07:20 main.py INFO 		F1-macro is 0.9878, AUC is 0.5000
Mon, 01 Sep 2025 21:07:20 main.py INFO 		Pre-macro is 0.9812, Rec_macro is 0.9948
Mon, 01 Sep 2025 21:07:20 main.py INFO 		For sarcasm, C_M is 
[[1038   11]
 [   0  282]]
Mon, 01 Sep 2025 21:07:20 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:07:20 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:07:20 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:07:20 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:07:20 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:07:20 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:07:20 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:07:20 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:07:20 main.py INFO In dataset test: Loss is [1.0509 0.9237 0.0000 0.1272]
Mon, 01 Sep 2025 21:07:20 main.py INFO 		Acc is 0.8784, F1-micro is 0.8784
Mon, 01 Sep 2025 21:07:20 main.py INFO 		F1-macro is 0.8164, AUC is 0.5000
Mon, 01 Sep 2025 21:07:20 main.py INFO 		Pre-macro is 0.8537, Rec_macro is 0.7922
Mon, 01 Sep 2025 21:07:20 main.py INFO 		For sarcasm, C_M is 
[[108   5]
 [ 13  22]]
Mon, 01 Sep 2025 21:07:20 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:07:20 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:07:20 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:07:20 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:07:20 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:07:20 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:07:20 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:07:20 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:07:20 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:07:28 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:07:28 main.py INFO Time of iter training 7.77 s
Mon, 01 Sep 2025 21:07:28 main.py INFO On iter step 12.0:, global step 768 Loss-step [1.1762 1.0266 1.0000 1.1457]
Mon, 01 Sep 2025 21:07:28 main.py INFO In dataset train: Loss is [0.1383 0.0019 0.0000 0.1364]
Mon, 01 Sep 2025 21:07:28 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:07:28 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:07:28 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:07:28 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:07:28 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:07:28 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:07:28 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:07:28 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:07:28 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:07:28 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:07:28 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:07:28 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:07:29 main.py INFO In dataset test: Loss is [1.3487 1.2220 0.0000 0.1267]
Mon, 01 Sep 2025 21:07:29 main.py INFO 		Acc is 0.8919, F1-micro is 0.8919
Mon, 01 Sep 2025 21:07:29 main.py INFO 		F1-macro is 0.8238, AUC is 0.5000
Mon, 01 Sep 2025 21:07:29 main.py INFO 		Pre-macro is 0.9171, Rec_macro is 0.7813
Mon, 01 Sep 2025 21:07:29 main.py INFO 		For sarcasm, C_M is 
[[112   1]
 [ 15  20]]
Mon, 01 Sep 2025 21:07:29 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:07:29 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:07:29 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:07:29 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:07:29 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:07:29 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:07:29 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:07:29 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:07:29 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:07:36 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:07:36 main.py INFO Time of iter training 7.67 s
Mon, 01 Sep 2025 21:07:36 main.py INFO On iter step 13.0:, global step 832 Loss-step [1.1837 1.0312 1.0000 1.1479]
Mon, 01 Sep 2025 21:07:37 main.py INFO In dataset train: Loss is [0.1494 0.0129 0.0001 0.1365]
Mon, 01 Sep 2025 21:07:37 main.py INFO 		Acc is 0.9992, F1-micro is 0.9992
Mon, 01 Sep 2025 21:07:37 main.py INFO 		F1-macro is 0.9989, AUC is 0.5000
Mon, 01 Sep 2025 21:07:37 main.py INFO 		Pre-macro is 0.9995, Rec_macro is 0.9982
Mon, 01 Sep 2025 21:07:37 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   1  281]]
Mon, 01 Sep 2025 21:07:37 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:07:37 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:07:37 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:07:37 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:07:37 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:07:37 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:07:37 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:07:37 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:07:37 main.py INFO In dataset test: Loss is [0.9260 0.8008 0.0001 0.1251]
Mon, 01 Sep 2025 21:07:37 main.py INFO 		Acc is 0.8986, F1-micro is 0.8986
Mon, 01 Sep 2025 21:07:37 main.py INFO 		F1-macro is 0.8412, AUC is 0.5000
Mon, 01 Sep 2025 21:07:37 main.py INFO 		Pre-macro is 0.9059, Rec_macro is 0.8054
Mon, 01 Sep 2025 21:07:37 main.py INFO 		For sarcasm, C_M is 
[[111   2]
 [ 13  22]]
Mon, 01 Sep 2025 21:07:37 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:07:37 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:07:37 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:07:37 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:07:37 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:07:37 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:07:37 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:07:37 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:07:37 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:07:44 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:07:44 main.py INFO Time of iter training 7.55 s
Mon, 01 Sep 2025 21:07:44 main.py INFO On iter step 14.0:, global step 896 Loss-step [1.1635 1.0146 1.0001 1.1467]
Mon, 01 Sep 2025 21:07:45 main.py INFO In dataset train: Loss is [0.1367 0.0004 0.0000 0.1364]
Mon, 01 Sep 2025 21:07:45 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:07:45 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:07:45 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:07:45 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:07:45 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:07:45 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:07:45 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:07:45 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:07:45 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:07:45 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:07:45 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:07:45 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:07:45 main.py INFO In dataset test: Loss is [1.7099 1.5829 0.0000 0.1270]
Mon, 01 Sep 2025 21:07:45 main.py INFO 		Acc is 0.8716, F1-micro is 0.8716
Mon, 01 Sep 2025 21:07:45 main.py INFO 		F1-macro is 0.7879, AUC is 0.5000
Mon, 01 Sep 2025 21:07:45 main.py INFO 		Pre-macro is 0.8836, Rec_macro is 0.7483
Mon, 01 Sep 2025 21:07:45 main.py INFO 		For sarcasm, C_M is 
[[111   2]
 [ 17  18]]
Mon, 01 Sep 2025 21:07:45 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:07:45 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:07:45 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:07:45 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:07:45 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:07:45 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:07:45 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:07:45 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:07:45 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:07:53 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:07:53 main.py INFO Time of iter training 8.06 s
Mon, 01 Sep 2025 21:07:53 main.py INFO On iter step 15.0:, global step 960 Loss-step [1.1577 1.0097 1.0000 1.1466]
Mon, 01 Sep 2025 21:07:54 main.py INFO In dataset train: Loss is [0.1376 0.0012 0.0000 0.1365]
Mon, 01 Sep 2025 21:07:54 main.py INFO 		Acc is 0.9992, F1-micro is 0.9992
Mon, 01 Sep 2025 21:07:54 main.py INFO 		F1-macro is 0.9989, AUC is 0.5000
Mon, 01 Sep 2025 21:07:54 main.py INFO 		Pre-macro is 0.9982, Rec_macro is 0.9995
Mon, 01 Sep 2025 21:07:54 main.py INFO 		For sarcasm, C_M is 
[[1048    1]
 [   0  282]]
Mon, 01 Sep 2025 21:07:54 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:07:54 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:07:54 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:07:54 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:07:54 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:07:54 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:07:54 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:07:54 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:07:54 main.py INFO In dataset test: Loss is [1.6066 1.4785 0.0000 0.1281]
Mon, 01 Sep 2025 21:07:54 main.py INFO 		Acc is 0.8784, F1-micro is 0.8784
Mon, 01 Sep 2025 21:07:54 main.py INFO 		F1-macro is 0.8070, AUC is 0.5000
Mon, 01 Sep 2025 21:07:54 main.py INFO 		Pre-macro is 0.8748, Rec_macro is 0.7724
Mon, 01 Sep 2025 21:07:54 main.py INFO 		For sarcasm, C_M is 
[[110   3]
 [ 15  20]]
Mon, 01 Sep 2025 21:07:54 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:07:54 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:07:54 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:07:54 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:07:54 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:07:54 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:07:54 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:07:54 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:07:54 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:08:01 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:08:01 main.py INFO Time of iter training 7.35 s
Mon, 01 Sep 2025 21:08:01 main.py INFO On iter step 16.0:, global step 1024 Loss-step [1.1587 1.0109 1.0000 1.1463]
Mon, 01 Sep 2025 21:08:02 main.py INFO In dataset train: Loss is [0.1367 0.0004 0.0000 0.1364]
Mon, 01 Sep 2025 21:08:02 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:08:02 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:08:02 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:08:02 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:08:02 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:08:02 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:08:02 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:08:02 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:08:02 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:08:02 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:08:02 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:08:02 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:08:02 main.py INFO In dataset test: Loss is [1.2494 1.1225 0.0000 0.1269]
Mon, 01 Sep 2025 21:08:02 main.py INFO 		Acc is 0.8784, F1-micro is 0.8784
Mon, 01 Sep 2025 21:08:02 main.py INFO 		F1-macro is 0.8070, AUC is 0.5000
Mon, 01 Sep 2025 21:08:02 main.py INFO 		Pre-macro is 0.8748, Rec_macro is 0.7724
Mon, 01 Sep 2025 21:08:02 main.py INFO 		For sarcasm, C_M is 
[[110   3]
 [ 15  20]]
Mon, 01 Sep 2025 21:08:02 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:08:02 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:08:02 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:08:02 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:08:02 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:08:02 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:08:02 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:08:02 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:08:02 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:08:09 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:08:09 main.py INFO Time of iter training 7.63 s
Mon, 01 Sep 2025 21:08:09 main.py INFO On iter step 17.0:, global step 1088 Loss-step [1.1531 1.0061 1.0000 1.1461]
Mon, 01 Sep 2025 21:08:10 main.py INFO In dataset train: Loss is [0.1365 0.0001 0.0000 0.1364]
Mon, 01 Sep 2025 21:08:10 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:08:10 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:08:10 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:08:10 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:08:10 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:08:10 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:08:10 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:08:10 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:08:10 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:08:10 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:08:10 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:08:10 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:08:10 main.py INFO In dataset test: Loss is [1.6019 1.4746 0.0000 0.1273]
Mon, 01 Sep 2025 21:08:10 main.py INFO 		Acc is 0.8784, F1-micro is 0.8784
Mon, 01 Sep 2025 21:08:10 main.py INFO 		F1-macro is 0.8018, AUC is 0.5000
Mon, 01 Sep 2025 21:08:10 main.py INFO 		Pre-macro is 0.8894, Rec_macro is 0.7626
Mon, 01 Sep 2025 21:08:10 main.py INFO 		For sarcasm, C_M is 
[[111   2]
 [ 16  19]]
Mon, 01 Sep 2025 21:08:10 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:08:10 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:08:10 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:08:10 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:08:10 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:08:10 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:08:10 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:08:10 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:08:10 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:08:18 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:08:18 main.py INFO Time of iter training 7.30 s
Mon, 01 Sep 2025 21:08:18 main.py INFO On iter step 18.0:, global step 1152 Loss-step [1.1526 1.0048 1.0000 1.1470]
Mon, 01 Sep 2025 21:08:18 main.py INFO In dataset train: Loss is [0.1366 0.0002 0.0000 0.1364]
Mon, 01 Sep 2025 21:08:18 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:08:18 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:08:18 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:08:18 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:08:18 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:08:18 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:08:18 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:08:18 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:08:18 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:08:18 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:08:18 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:08:18 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:08:18 main.py INFO In dataset test: Loss is [1.9943 1.8667 0.0000 0.1276]
Mon, 01 Sep 2025 21:08:18 main.py INFO 		Acc is 0.8851, F1-micro is 0.8851
Mon, 01 Sep 2025 21:08:18 main.py INFO 		F1-macro is 0.8153, AUC is 0.5000
Mon, 01 Sep 2025 21:08:18 main.py INFO 		Pre-macro is 0.8950, Rec_macro is 0.7769
Mon, 01 Sep 2025 21:08:18 main.py INFO 		For sarcasm, C_M is 
[[111   2]
 [ 15  20]]
Mon, 01 Sep 2025 21:08:18 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:08:18 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:08:18 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:08:18 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:08:18 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:08:18 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:08:18 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:08:18 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:08:18 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:08:26 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:08:26 main.py INFO Time of iter training 7.79 s
Mon, 01 Sep 2025 21:08:26 main.py INFO On iter step 19.0:, global step 1216 Loss-step [1.1541 1.0049 1.0000 1.1485]
Mon, 01 Sep 2025 21:08:27 main.py INFO In dataset train: Loss is [0.1364 0.0001 0.0000 0.1364]
Mon, 01 Sep 2025 21:08:27 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:08:27 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:08:27 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:08:27 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:08:27 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:08:27 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:08:27 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:08:27 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:08:27 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:08:27 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:08:27 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:08:27 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:08:27 main.py INFO In dataset test: Loss is [1.9424 1.8160 0.0000 0.1264]
Mon, 01 Sep 2025 21:08:27 main.py INFO 		Acc is 0.8784, F1-micro is 0.8784
Mon, 01 Sep 2025 21:08:27 main.py INFO 		F1-macro is 0.8070, AUC is 0.5000
Mon, 01 Sep 2025 21:08:27 main.py INFO 		Pre-macro is 0.8748, Rec_macro is 0.7724
Mon, 01 Sep 2025 21:08:27 main.py INFO 		For sarcasm, C_M is 
[[110   3]
 [ 15  20]]
Mon, 01 Sep 2025 21:08:27 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:08:27 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:08:27 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:08:27 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:08:27 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:08:27 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:08:27 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:08:27 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:08:27 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:08:35 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:08:35 main.py INFO Time of iter training 7.95 s
Mon, 01 Sep 2025 21:08:35 main.py INFO On iter step 20.0:, global step 1280 Loss-step [1.1662 1.0161 1.0000 1.1477]
Mon, 01 Sep 2025 21:08:35 main.py INFO In dataset train: Loss is [0.1370 0.0005 0.0000 0.1364]
Mon, 01 Sep 2025 21:08:35 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:08:35 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:08:35 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:08:35 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:08:35 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:08:35 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:08:35 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:08:35 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:08:35 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:08:35 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:08:35 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:08:35 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:08:35 main.py INFO In dataset test: Loss is [1.4796 1.3538 0.0000 0.1258]
Mon, 01 Sep 2025 21:08:35 main.py INFO 		Acc is 0.8716, F1-micro is 0.8716
Mon, 01 Sep 2025 21:08:35 main.py INFO 		F1-macro is 0.7879, AUC is 0.5000
Mon, 01 Sep 2025 21:08:35 main.py INFO 		Pre-macro is 0.8836, Rec_macro is 0.7483
Mon, 01 Sep 2025 21:08:35 main.py INFO 		For sarcasm, C_M is 
[[111   2]
 [ 17  18]]
Mon, 01 Sep 2025 21:08:35 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:08:35 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:08:35 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:08:35 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:08:35 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:08:35 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:08:35 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:08:35 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:08:35 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:08:42 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:08:42 main.py INFO Time of iter training 7.03 s
Mon, 01 Sep 2025 21:08:42 main.py INFO On iter step 21.0:, global step 1344 Loss-step [1.1660 1.0154 1.0000 1.1482]
Mon, 01 Sep 2025 21:08:43 main.py INFO In dataset train: Loss is [0.1399 0.0034 0.0000 0.1365]
Mon, 01 Sep 2025 21:08:43 main.py INFO 		Acc is 0.9992, F1-micro is 0.9992
Mon, 01 Sep 2025 21:08:43 main.py INFO 		F1-macro is 0.9989, AUC is 0.5000
Mon, 01 Sep 2025 21:08:43 main.py INFO 		Pre-macro is 0.9995, Rec_macro is 0.9982
Mon, 01 Sep 2025 21:08:43 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   1  281]]
Mon, 01 Sep 2025 21:08:43 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:08:43 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:08:43 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:08:43 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:08:43 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:08:43 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:08:43 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:08:43 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:08:43 main.py INFO In dataset test: Loss is [1.2269 1.1019 0.0000 0.1250]
Mon, 01 Sep 2025 21:08:43 main.py INFO 		Acc is 0.8784, F1-micro is 0.8784
Mon, 01 Sep 2025 21:08:43 main.py INFO 		F1-macro is 0.8070, AUC is 0.5000
Mon, 01 Sep 2025 21:08:43 main.py INFO 		Pre-macro is 0.8748, Rec_macro is 0.7724
Mon, 01 Sep 2025 21:08:43 main.py INFO 		For sarcasm, C_M is 
[[110   3]
 [ 15  20]]
Mon, 01 Sep 2025 21:08:43 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:08:43 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:08:43 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:08:43 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:08:43 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:08:43 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:08:43 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:08:43 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:08:43 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:08:50 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:08:50 main.py INFO Time of iter training 7.09 s
Mon, 01 Sep 2025 21:08:50 main.py INFO On iter step 22.0:, global step 1408 Loss-step [1.1597 1.0115 1.0000 1.1465]
Mon, 01 Sep 2025 21:08:51 main.py INFO In dataset train: Loss is [0.1403 0.0039 0.0000 0.1364]
Mon, 01 Sep 2025 21:08:51 main.py INFO 		Acc is 0.9992, F1-micro is 0.9992
Mon, 01 Sep 2025 21:08:51 main.py INFO 		F1-macro is 0.9989, AUC is 0.5000
Mon, 01 Sep 2025 21:08:51 main.py INFO 		Pre-macro is 0.9982, Rec_macro is 0.9995
Mon, 01 Sep 2025 21:08:51 main.py INFO 		For sarcasm, C_M is 
[[1048    1]
 [   0  282]]
Mon, 01 Sep 2025 21:08:51 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:08:51 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:08:51 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:08:51 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:08:51 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:08:51 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:08:51 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:08:51 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:08:51 main.py INFO In dataset test: Loss is [1.3515 1.2251 0.0000 0.1265]
Mon, 01 Sep 2025 21:08:51 main.py INFO 		Acc is 0.8649, F1-micro is 0.8649
Mon, 01 Sep 2025 21:08:51 main.py INFO 		F1-macro is 0.7910, AUC is 0.5000
Mon, 01 Sep 2025 21:08:51 main.py INFO 		Pre-macro is 0.8390, Rec_macro is 0.7636
Mon, 01 Sep 2025 21:08:51 main.py INFO 		For sarcasm, C_M is 
[[108   5]
 [ 15  20]]
Mon, 01 Sep 2025 21:08:51 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:08:51 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:08:51 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:08:51 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:08:51 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:08:51 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:08:51 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:08:51 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:08:51 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:08:58 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:08:58 main.py INFO Time of iter training 7.67 s
Mon, 01 Sep 2025 21:08:58 main.py INFO On iter step 23.0:, global step 1472 Loss-step [1.1587 1.0121 1.0000 1.1449]
Mon, 01 Sep 2025 21:08:59 main.py INFO In dataset train: Loss is [0.1481 0.0118 0.0000 0.1364]
Mon, 01 Sep 2025 21:08:59 main.py INFO 		Acc is 0.9970, F1-micro is 0.9970
Mon, 01 Sep 2025 21:08:59 main.py INFO 		F1-macro is 0.9955, AUC is 0.5000
Mon, 01 Sep 2025 21:08:59 main.py INFO 		Pre-macro is 0.9930, Rec_macro is 0.9981
Mon, 01 Sep 2025 21:08:59 main.py INFO 		For sarcasm, C_M is 
[[1045    4]
 [   0  282]]
Mon, 01 Sep 2025 21:08:59 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:08:59 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:08:59 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:08:59 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:08:59 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:08:59 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:08:59 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:08:59 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:08:59 main.py INFO In dataset test: Loss is [1.3990 1.2725 0.0000 0.1265]
Mon, 01 Sep 2025 21:08:59 main.py INFO 		Acc is 0.8649, F1-micro is 0.8649
Mon, 01 Sep 2025 21:08:59 main.py INFO 		F1-macro is 0.7960, AUC is 0.5000
Mon, 01 Sep 2025 21:08:59 main.py INFO 		Pre-macro is 0.8310, Rec_macro is 0.7735
Mon, 01 Sep 2025 21:08:59 main.py INFO 		For sarcasm, C_M is 
[[107   6]
 [ 14  21]]
Mon, 01 Sep 2025 21:08:59 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:08:59 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:08:59 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:08:59 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:08:59 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:08:59 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:08:59 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:08:59 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:08:59 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:09:06 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:09:06 main.py INFO Time of iter training 7.09 s
Mon, 01 Sep 2025 21:09:06 main.py INFO On iter step 24.0:, global step 1536 Loss-step [1.1598 1.0101 1.0000 1.1482]
Mon, 01 Sep 2025 21:09:07 main.py INFO In dataset train: Loss is [0.1365 0.0001 0.0000 0.1364]
Mon, 01 Sep 2025 21:09:07 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:09:07 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:09:07 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:09:07 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:09:07 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:09:07 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:09:07 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:09:07 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:09:07 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:09:07 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:09:07 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:09:07 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:09:07 main.py INFO In dataset test: Loss is [2.0144 1.8878 0.0000 0.1266]
Mon, 01 Sep 2025 21:09:07 main.py INFO 		Acc is 0.8851, F1-micro is 0.8851
Mon, 01 Sep 2025 21:09:07 main.py INFO 		F1-macro is 0.8102, AUC is 0.5000
Mon, 01 Sep 2025 21:09:07 main.py INFO 		Pre-macro is 0.9125, Rec_macro is 0.7670
Mon, 01 Sep 2025 21:09:07 main.py INFO 		For sarcasm, C_M is 
[[112   1]
 [ 16  19]]
Mon, 01 Sep 2025 21:09:07 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:09:07 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:09:07 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:09:07 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:09:07 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:09:07 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:09:07 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:09:07 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:09:07 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:09:14 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:09:14 main.py INFO Time of iter training 7.38 s
Mon, 01 Sep 2025 21:09:14 main.py INFO On iter step 25.0:, global step 1600 Loss-step [1.1536 1.0061 1.0000 1.1466]
Mon, 01 Sep 2025 21:09:15 main.py INFO In dataset train: Loss is [0.1431 0.0066 0.0000 0.1365]
Mon, 01 Sep 2025 21:09:15 main.py INFO 		Acc is 0.9992, F1-micro is 0.9992
Mon, 01 Sep 2025 21:09:15 main.py INFO 		F1-macro is 0.9989, AUC is 0.5000
Mon, 01 Sep 2025 21:09:15 main.py INFO 		Pre-macro is 0.9982, Rec_macro is 0.9995
Mon, 01 Sep 2025 21:09:15 main.py INFO 		For sarcasm, C_M is 
[[1048    1]
 [   0  282]]
Mon, 01 Sep 2025 21:09:15 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:09:15 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:09:15 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:09:15 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:09:15 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:09:15 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:09:15 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:09:15 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:09:15 main.py INFO In dataset test: Loss is [1.1293 1.0041 0.0000 0.1252]
Mon, 01 Sep 2025 21:09:15 main.py INFO 		Acc is 0.8581, F1-micro is 0.8581
Mon, 01 Sep 2025 21:09:15 main.py INFO 		F1-macro is 0.7883, AUC is 0.5000
Mon, 01 Sep 2025 21:09:15 main.py INFO 		Pre-macro is 0.8167, Rec_macro is 0.7690
Mon, 01 Sep 2025 21:09:15 main.py INFO 		For sarcasm, C_M is 
[[106   7]
 [ 14  21]]
Mon, 01 Sep 2025 21:09:15 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:09:15 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:09:15 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:09:15 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:09:15 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:09:15 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:09:15 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:09:15 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:09:15 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:09:22 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:09:22 main.py INFO Time of iter training 7.67 s
Mon, 01 Sep 2025 21:09:22 main.py INFO On iter step 26.0:, global step 1664 Loss-step [1.1540 1.0063 1.0000 1.1468]
Mon, 01 Sep 2025 21:09:23 main.py INFO In dataset train: Loss is [0.1364 0.0000 0.0000 0.1364]
Mon, 01 Sep 2025 21:09:23 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:09:23 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:09:23 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:09:23 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:09:23 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:09:23 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:09:23 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:09:23 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:09:23 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:09:23 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:09:23 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:09:23 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:09:23 main.py INFO In dataset test: Loss is [1.9346 1.8077 0.0000 0.1269]
Mon, 01 Sep 2025 21:09:23 main.py INFO 		Acc is 0.8784, F1-micro is 0.8784
Mon, 01 Sep 2025 21:09:23 main.py INFO 		F1-macro is 0.8018, AUC is 0.5000
Mon, 01 Sep 2025 21:09:23 main.py INFO 		Pre-macro is 0.8894, Rec_macro is 0.7626
Mon, 01 Sep 2025 21:09:23 main.py INFO 		For sarcasm, C_M is 
[[111   2]
 [ 16  19]]
Mon, 01 Sep 2025 21:09:23 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:09:23 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:09:23 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:09:23 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:09:23 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:09:23 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:09:23 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:09:23 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:09:23 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:09:31 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:09:31 main.py INFO Time of iter training 7.51 s
Mon, 01 Sep 2025 21:09:31 main.py INFO On iter step 27.0:, global step 1728 Loss-step [1.1527 1.0052 1.0000 1.1467]
Mon, 01 Sep 2025 21:09:31 main.py INFO In dataset train: Loss is [0.1365 0.0001 0.0000 0.1364]
Mon, 01 Sep 2025 21:09:31 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:09:31 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:09:31 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:09:31 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:09:31 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:09:31 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:09:31 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:09:31 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:09:31 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:09:31 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:09:31 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:09:31 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:09:31 main.py INFO In dataset test: Loss is [1.6653 1.5385 0.0000 0.1268]
Mon, 01 Sep 2025 21:09:31 main.py INFO 		Acc is 0.8851, F1-micro is 0.8851
Mon, 01 Sep 2025 21:09:31 main.py INFO 		F1-macro is 0.8153, AUC is 0.5000
Mon, 01 Sep 2025 21:09:31 main.py INFO 		Pre-macro is 0.8950, Rec_macro is 0.7769
Mon, 01 Sep 2025 21:09:31 main.py INFO 		For sarcasm, C_M is 
[[111   2]
 [ 15  20]]
Mon, 01 Sep 2025 21:09:31 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:09:31 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:09:31 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:09:31 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:09:31 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:09:31 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:09:31 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:09:31 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:09:31 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:09:39 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:09:39 main.py INFO Time of iter training 7.57 s
Mon, 01 Sep 2025 21:09:39 main.py INFO On iter step 28.0:, global step 1792 Loss-step [1.1502 1.0031 1.0000 1.1466]
Mon, 01 Sep 2025 21:09:40 main.py INFO In dataset train: Loss is [0.1364 0.0000 0.0000 0.1364]
Mon, 01 Sep 2025 21:09:40 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:09:40 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:09:40 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:09:40 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:09:40 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:09:40 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:09:40 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:09:40 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:09:40 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:09:40 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:09:40 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:09:40 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:09:40 main.py INFO In dataset test: Loss is [2.3086 2.1816 0.0000 0.1270]
Mon, 01 Sep 2025 21:09:40 main.py INFO 		Acc is 0.8851, F1-micro is 0.8851
Mon, 01 Sep 2025 21:09:40 main.py INFO 		F1-macro is 0.8102, AUC is 0.5000
Mon, 01 Sep 2025 21:09:40 main.py INFO 		Pre-macro is 0.9125, Rec_macro is 0.7670
Mon, 01 Sep 2025 21:09:40 main.py INFO 		For sarcasm, C_M is 
[[112   1]
 [ 16  19]]
Mon, 01 Sep 2025 21:09:40 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:09:40 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:09:40 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:09:40 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:09:40 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:09:40 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:09:40 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:09:40 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:09:40 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:09:47 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:09:47 main.py INFO Time of iter training 7.54 s
Mon, 01 Sep 2025 21:09:47 main.py INFO On iter step 29.0:, global step 1856 Loss-step [1.1520 1.0052 1.0000 1.1461]
Mon, 01 Sep 2025 21:09:48 main.py INFO In dataset train: Loss is [0.1365 0.0001 0.0000 0.1364]
Mon, 01 Sep 2025 21:09:48 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:09:48 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:09:48 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:09:48 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:09:48 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:09:48 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:09:48 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:09:48 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:09:48 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:09:48 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:09:48 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:09:48 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:09:48 main.py INFO In dataset test: Loss is [1.4235 1.2975 0.0000 0.1260]
Mon, 01 Sep 2025 21:09:48 main.py INFO 		Acc is 0.8851, F1-micro is 0.8851
Mon, 01 Sep 2025 21:09:48 main.py INFO 		F1-macro is 0.8102, AUC is 0.5000
Mon, 01 Sep 2025 21:09:48 main.py INFO 		Pre-macro is 0.9125, Rec_macro is 0.7670
Mon, 01 Sep 2025 21:09:48 main.py INFO 		For sarcasm, C_M is 
[[112   1]
 [ 16  19]]
Mon, 01 Sep 2025 21:09:48 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:09:48 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:09:48 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:09:48 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:09:48 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:09:48 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:09:48 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:09:48 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:09:48 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:09:55 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:09:55 main.py INFO Time of iter training 7.18 s
Mon, 01 Sep 2025 21:09:55 main.py INFO On iter step 30.0:, global step 1920 Loss-step [1.1571 1.0085 1.0000 1.1473]
Mon, 01 Sep 2025 21:09:56 main.py INFO In dataset train: Loss is [0.1365 0.0001 0.0000 0.1364]
Mon, 01 Sep 2025 21:09:56 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:09:56 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:09:56 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:09:56 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:09:56 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:09:56 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:09:56 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:09:56 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:09:56 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:09:56 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:09:56 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:09:56 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:09:56 main.py INFO In dataset test: Loss is [1.4273 1.3016 0.0000 0.1257]
Mon, 01 Sep 2025 21:09:56 main.py INFO 		Acc is 0.8851, F1-micro is 0.8851
Mon, 01 Sep 2025 21:09:56 main.py INFO 		F1-macro is 0.8102, AUC is 0.5000
Mon, 01 Sep 2025 21:09:56 main.py INFO 		Pre-macro is 0.9125, Rec_macro is 0.7670
Mon, 01 Sep 2025 21:09:56 main.py INFO 		For sarcasm, C_M is 
[[112   1]
 [ 16  19]]
Mon, 01 Sep 2025 21:09:56 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:09:56 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:09:56 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:09:56 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:09:56 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:09:56 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:09:56 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:09:56 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:09:56 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:10:03 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:10:03 main.py INFO Time of iter training 7.73 s
Mon, 01 Sep 2025 21:10:03 main.py INFO On iter step 31.0:, global step 1984 Loss-step [1.1488 1.0023 1.0000 1.1461]
Mon, 01 Sep 2025 21:10:04 main.py INFO In dataset train: Loss is [0.1366 0.0002 0.0000 0.1364]
Mon, 01 Sep 2025 21:10:04 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:10:04 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:10:04 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:10:04 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:10:04 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:10:04 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:10:04 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:10:04 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:10:04 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:10:04 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:10:04 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:10:04 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:10:04 main.py INFO In dataset test: Loss is [2.3906 2.2631 0.0000 0.1275]
Mon, 01 Sep 2025 21:10:04 main.py INFO 		Acc is 0.8716, F1-micro is 0.8716
Mon, 01 Sep 2025 21:10:04 main.py INFO 		F1-macro is 0.7879, AUC is 0.5000
Mon, 01 Sep 2025 21:10:04 main.py INFO 		Pre-macro is 0.8836, Rec_macro is 0.7483
Mon, 01 Sep 2025 21:10:04 main.py INFO 		For sarcasm, C_M is 
[[111   2]
 [ 17  18]]
Mon, 01 Sep 2025 21:10:04 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:10:04 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:10:04 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:10:04 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:10:04 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:10:04 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:10:04 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:10:04 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:10:04 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:10:12 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:10:12 main.py INFO Time of iter training 7.67 s
Mon, 01 Sep 2025 21:10:12 main.py INFO On iter step 32.0:, global step 2048 Loss-step [1.1647 1.0148 1.0000 1.1477]
Mon, 01 Sep 2025 21:10:12 main.py INFO In dataset train: Loss is [0.1369 0.0006 0.0000 0.1364]
Mon, 01 Sep 2025 21:10:12 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:10:12 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:10:12 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:10:12 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:10:12 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:10:12 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:10:12 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:10:12 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:10:12 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:10:12 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:10:12 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:10:12 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:10:12 main.py INFO In dataset test: Loss is [2.4758 2.3494 0.0000 0.1264]
Mon, 01 Sep 2025 21:10:12 main.py INFO 		Acc is 0.8784, F1-micro is 0.8784
Mon, 01 Sep 2025 21:10:12 main.py INFO 		F1-macro is 0.7961, AUC is 0.5000
Mon, 01 Sep 2025 21:10:12 main.py INFO 		Pre-macro is 0.9078, Rec_macro is 0.7527
Mon, 01 Sep 2025 21:10:12 main.py INFO 		For sarcasm, C_M is 
[[112   1]
 [ 17  18]]
Mon, 01 Sep 2025 21:10:12 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:10:12 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:10:12 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:10:12 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:10:12 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:10:12 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:10:12 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:10:12 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:10:12 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:10:20 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:10:20 main.py INFO Time of iter training 7.83 s
Mon, 01 Sep 2025 21:10:20 main.py INFO On iter step 33.0:, global step 2112 Loss-step [1.1653 1.0162 1.0000 1.1467]
Mon, 01 Sep 2025 21:10:21 main.py INFO In dataset train: Loss is [0.1408 0.0044 0.0001 0.1364]
Mon, 01 Sep 2025 21:10:21 main.py INFO 		Acc is 0.9992, F1-micro is 0.9992
Mon, 01 Sep 2025 21:10:21 main.py INFO 		F1-macro is 0.9989, AUC is 0.5000
Mon, 01 Sep 2025 21:10:21 main.py INFO 		Pre-macro is 0.9995, Rec_macro is 0.9982
Mon, 01 Sep 2025 21:10:21 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   1  281]]
Mon, 01 Sep 2025 21:10:21 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:10:21 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:10:21 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:10:21 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:10:21 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:10:21 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:10:21 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:10:21 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:10:21 main.py INFO In dataset test: Loss is [1.5047 1.3769 0.0000 0.1277]
Mon, 01 Sep 2025 21:10:21 main.py INFO 		Acc is 0.8514, F1-micro is 0.8514
Mon, 01 Sep 2025 21:10:21 main.py INFO 		F1-macro is 0.7756, AUC is 0.5000
Mon, 01 Sep 2025 21:10:21 main.py INFO 		Pre-macro is 0.8084, Rec_macro is 0.7547
Mon, 01 Sep 2025 21:10:21 main.py INFO 		For sarcasm, C_M is 
[[106   7]
 [ 15  20]]
Mon, 01 Sep 2025 21:10:21 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:10:21 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:10:21 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:10:21 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:10:21 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:10:21 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:10:21 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:10:21 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:10:21 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:10:29 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:10:29 main.py INFO Time of iter training 7.82 s
Mon, 01 Sep 2025 21:10:29 main.py INFO On iter step 34.0:, global step 2176 Loss-step [1.1589 1.0118 1.0000 1.1453]
Mon, 01 Sep 2025 21:10:29 main.py INFO In dataset train: Loss is [0.1366 0.0003 0.0000 0.1364]
Mon, 01 Sep 2025 21:10:29 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:10:29 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:10:29 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:10:29 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:10:29 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:10:29 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:10:29 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:10:29 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:10:29 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:10:29 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:10:29 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:10:29 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:10:29 main.py INFO In dataset test: Loss is [2.4487 2.3216 0.0000 0.1271]
Mon, 01 Sep 2025 21:10:29 main.py INFO 		Acc is 0.8649, F1-micro is 0.8649
Mon, 01 Sep 2025 21:10:29 main.py INFO 		F1-macro is 0.7798, AUC is 0.5000
Mon, 01 Sep 2025 21:10:29 main.py INFO 		Pre-macro is 0.8616, Rec_macro is 0.7439
Mon, 01 Sep 2025 21:10:29 main.py INFO 		For sarcasm, C_M is 
[[110   3]
 [ 17  18]]
Mon, 01 Sep 2025 21:10:29 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:10:29 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:10:29 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:10:29 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:10:29 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:10:29 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:10:29 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:10:29 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:10:29 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:10:38 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:10:38 main.py INFO Time of iter training 8.47 s
Mon, 01 Sep 2025 21:10:38 main.py INFO On iter step 35.0:, global step 2240 Loss-step [1.1492 1.0011 1.0000 1.1480]
Mon, 01 Sep 2025 21:10:38 main.py INFO In dataset train: Loss is [0.1364 0.0000 0.0000 0.1364]
Mon, 01 Sep 2025 21:10:38 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:10:38 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:10:38 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:10:38 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:10:38 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:10:38 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:10:38 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:10:38 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:10:38 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:10:38 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:10:38 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:10:38 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:10:39 main.py INFO In dataset test: Loss is [2.3997 2.2740 0.0000 0.1256]
Mon, 01 Sep 2025 21:10:39 main.py INFO 		Acc is 0.8716, F1-micro is 0.8716
Mon, 01 Sep 2025 21:10:39 main.py INFO 		F1-macro is 0.7879, AUC is 0.5000
Mon, 01 Sep 2025 21:10:39 main.py INFO 		Pre-macro is 0.8836, Rec_macro is 0.7483
Mon, 01 Sep 2025 21:10:39 main.py INFO 		For sarcasm, C_M is 
[[111   2]
 [ 17  18]]
Mon, 01 Sep 2025 21:10:39 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:10:39 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:10:39 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:10:39 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:10:39 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:10:39 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:10:39 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:10:39 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:10:39 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:10:47 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:10:47 main.py INFO Time of iter training 8.35 s
Mon, 01 Sep 2025 21:10:47 main.py INFO On iter step 36.0:, global step 2304 Loss-step [1.1476 1.0006 1.0000 1.1468]
Mon, 01 Sep 2025 21:10:48 main.py INFO In dataset train: Loss is [0.1364 0.0000 0.0000 0.1364]
Mon, 01 Sep 2025 21:10:48 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:10:48 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:10:48 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:10:48 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:10:48 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:10:48 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:10:48 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:10:48 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:10:48 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:10:48 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:10:48 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:10:48 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:10:48 main.py INFO In dataset test: Loss is [2.6122 2.4860 0.0000 0.1262]
Mon, 01 Sep 2025 21:10:48 main.py INFO 		Acc is 0.8716, F1-micro is 0.8716
Mon, 01 Sep 2025 21:10:48 main.py INFO 		F1-macro is 0.7879, AUC is 0.5000
Mon, 01 Sep 2025 21:10:48 main.py INFO 		Pre-macro is 0.8836, Rec_macro is 0.7483
Mon, 01 Sep 2025 21:10:48 main.py INFO 		For sarcasm, C_M is 
[[111   2]
 [ 17  18]]
Mon, 01 Sep 2025 21:10:48 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:10:48 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:10:48 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:10:48 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:10:48 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:10:48 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:10:48 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:10:48 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:10:48 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:10:56 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:10:56 main.py INFO Time of iter training 8.35 s
Mon, 01 Sep 2025 21:10:56 main.py INFO On iter step 37.0:, global step 2368 Loss-step [1.1478 1.0019 1.0000 1.1456]
Mon, 01 Sep 2025 21:10:57 main.py INFO In dataset train: Loss is [0.1364 0.0000 0.0000 0.1363]
Mon, 01 Sep 2025 21:10:57 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:10:57 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:10:57 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:10:57 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:10:57 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:10:57 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:10:57 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:10:57 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:10:57 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:10:57 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:10:57 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:10:57 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:10:57 main.py INFO In dataset test: Loss is [2.3291 2.2023 0.0000 0.1268]
Mon, 01 Sep 2025 21:10:57 main.py INFO 		Acc is 0.8716, F1-micro is 0.8716
Mon, 01 Sep 2025 21:10:57 main.py INFO 		F1-macro is 0.7936, AUC is 0.5000
Mon, 01 Sep 2025 21:10:57 main.py INFO 		Pre-macro is 0.8683, Rec_macro is 0.7582
Mon, 01 Sep 2025 21:10:57 main.py INFO 		For sarcasm, C_M is 
[[110   3]
 [ 16  19]]
Mon, 01 Sep 2025 21:10:57 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:10:57 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:10:57 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:10:57 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:10:57 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:10:57 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:10:57 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:10:57 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:10:57 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:11:04 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:11:04 main.py INFO Time of iter training 7.56 s
Mon, 01 Sep 2025 21:11:04 main.py INFO On iter step 38.0:, global step 2432 Loss-step [1.1527 1.0053 1.0000 1.1467]
Mon, 01 Sep 2025 21:11:05 main.py INFO In dataset train: Loss is [0.1379 0.0015 0.0000 0.1364]
Mon, 01 Sep 2025 21:11:05 main.py INFO 		Acc is 0.9992, F1-micro is 0.9992
Mon, 01 Sep 2025 21:11:05 main.py INFO 		F1-macro is 0.9989, AUC is 0.5000
Mon, 01 Sep 2025 21:11:05 main.py INFO 		Pre-macro is 0.9995, Rec_macro is 0.9982
Mon, 01 Sep 2025 21:11:05 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   1  281]]
Mon, 01 Sep 2025 21:11:05 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:11:05 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:11:05 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:11:05 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:11:05 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:11:05 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:11:05 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:11:05 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:11:05 main.py INFO In dataset test: Loss is [1.9342 1.8071 0.0000 0.1271]
Mon, 01 Sep 2025 21:11:05 main.py INFO 		Acc is 0.8716, F1-micro is 0.8716
Mon, 01 Sep 2025 21:11:05 main.py INFO 		F1-macro is 0.7989, AUC is 0.5000
Mon, 01 Sep 2025 21:11:05 main.py INFO 		Pre-macro is 0.8562, Rec_macro is 0.7680
Mon, 01 Sep 2025 21:11:05 main.py INFO 		For sarcasm, C_M is 
[[109   4]
 [ 15  20]]
Mon, 01 Sep 2025 21:11:05 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:11:05 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:11:05 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:11:05 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:11:05 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:11:05 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:11:05 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:11:05 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:11:05 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:11:12 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:11:12 main.py INFO Time of iter training 6.98 s
Mon, 01 Sep 2025 21:11:12 main.py INFO On iter step 39.0:, global step 2496 Loss-step [1.1526 1.0056 1.0000 1.1462]
Mon, 01 Sep 2025 21:11:12 main.py INFO In dataset train: Loss is [0.1370 0.0006 0.0000 0.1364]
Mon, 01 Sep 2025 21:11:12 main.py INFO 		Acc is 0.9992, F1-micro is 0.9992
Mon, 01 Sep 2025 21:11:12 main.py INFO 		F1-macro is 0.9989, AUC is 0.5000
Mon, 01 Sep 2025 21:11:12 main.py INFO 		Pre-macro is 0.9982, Rec_macro is 0.9995
Mon, 01 Sep 2025 21:11:12 main.py INFO 		For sarcasm, C_M is 
[[1048    1]
 [   0  282]]
Mon, 01 Sep 2025 21:11:12 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:11:12 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:11:12 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:11:12 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:11:12 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:11:12 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:11:12 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:11:12 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:11:13 main.py INFO In dataset test: Loss is [2.4004 2.2735 0.0000 0.1270]
Mon, 01 Sep 2025 21:11:13 main.py INFO 		Acc is 0.8581, F1-micro is 0.8581
Mon, 01 Sep 2025 21:11:13 main.py INFO 		F1-macro is 0.7719, AUC is 0.5000
Mon, 01 Sep 2025 21:11:13 main.py INFO 		Pre-macro is 0.8416, Rec_macro is 0.7394
Mon, 01 Sep 2025 21:11:13 main.py INFO 		For sarcasm, C_M is 
[[109   4]
 [ 17  18]]
Mon, 01 Sep 2025 21:11:13 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:11:13 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:11:13 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:11:13 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:11:13 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:11:13 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:11:13 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:11:13 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:11:13 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:11:20 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:11:20 main.py INFO Time of iter training 7.24 s
Mon, 01 Sep 2025 21:11:20 main.py INFO On iter step 40.0:, global step 2560 Loss-step [1.1843 1.0332 1.0001 1.1462]
Mon, 01 Sep 2025 21:11:20 main.py INFO In dataset train: Loss is [0.1470 0.0106 0.0000 0.1365]
Mon, 01 Sep 2025 21:11:20 main.py INFO 		Acc is 0.9977, F1-micro is 0.9977
Mon, 01 Sep 2025 21:11:20 main.py INFO 		F1-macro is 0.9966, AUC is 0.5000
Mon, 01 Sep 2025 21:11:20 main.py INFO 		Pre-macro is 0.9947, Rec_macro is 0.9986
Mon, 01 Sep 2025 21:11:20 main.py INFO 		For sarcasm, C_M is 
[[1046    3]
 [   0  282]]
Mon, 01 Sep 2025 21:11:20 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:11:20 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:11:20 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:11:20 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:11:20 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:11:20 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:11:20 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:11:20 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:11:20 main.py INFO In dataset test: Loss is [1.3479 1.2198 0.0000 0.1280]
Mon, 01 Sep 2025 21:11:20 main.py INFO 		Acc is 0.8446, F1-micro is 0.8446
Mon, 01 Sep 2025 21:11:20 main.py INFO 		F1-macro is 0.7681, AUC is 0.5000
Mon, 01 Sep 2025 21:11:20 main.py INFO 		Pre-macro is 0.7946, Rec_macro is 0.7503
Mon, 01 Sep 2025 21:11:20 main.py INFO 		For sarcasm, C_M is 
[[105   8]
 [ 15  20]]
Mon, 01 Sep 2025 21:11:20 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:11:20 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:11:20 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:11:20 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:11:20 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:11:20 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:11:20 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:11:20 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:11:20 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:11:28 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:11:28 main.py INFO Time of iter training 7.40 s
Mon, 01 Sep 2025 21:11:28 main.py INFO On iter step 41.0:, global step 2624 Loss-step [1.1664 1.0159 1.0000 1.1481]
Mon, 01 Sep 2025 21:11:28 main.py INFO In dataset train: Loss is [0.1372 0.0008 0.0000 0.1364]
Mon, 01 Sep 2025 21:11:28 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:11:28 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:11:28 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:11:28 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:11:28 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:11:28 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:11:28 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:11:28 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:11:28 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:11:28 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:11:28 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:11:28 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:11:28 main.py INFO In dataset test: Loss is [1.7197 1.5940 0.0000 0.1257]
Mon, 01 Sep 2025 21:11:28 main.py INFO 		Acc is 0.8649, F1-micro is 0.8649
Mon, 01 Sep 2025 21:11:28 main.py INFO 		F1-macro is 0.7798, AUC is 0.5000
Mon, 01 Sep 2025 21:11:28 main.py INFO 		Pre-macro is 0.8616, Rec_macro is 0.7439
Mon, 01 Sep 2025 21:11:28 main.py INFO 		For sarcasm, C_M is 
[[110   3]
 [ 17  18]]
Mon, 01 Sep 2025 21:11:28 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:11:28 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:11:28 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:11:28 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:11:28 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:11:28 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:11:28 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:11:28 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:11:28 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:11:36 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:11:36 main.py INFO Time of iter training 7.40 s
Mon, 01 Sep 2025 21:11:36 main.py INFO On iter step 42.0:, global step 2688 Loss-step [1.1490 1.0023 1.0000 1.1464]
Mon, 01 Sep 2025 21:11:36 main.py INFO In dataset train: Loss is [0.1364 0.0000 0.0000 0.1364]
Mon, 01 Sep 2025 21:11:36 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:11:36 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:11:36 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:11:36 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:11:36 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:11:36 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:11:36 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:11:36 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:11:36 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:11:36 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:11:36 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:11:36 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:11:37 main.py INFO In dataset test: Loss is [2.0800 1.9534 0.0000 0.1265]
Mon, 01 Sep 2025 21:11:37 main.py INFO 		Acc is 0.8716, F1-micro is 0.8716
Mon, 01 Sep 2025 21:11:37 main.py INFO 		F1-macro is 0.7989, AUC is 0.5000
Mon, 01 Sep 2025 21:11:37 main.py INFO 		Pre-macro is 0.8562, Rec_macro is 0.7680
Mon, 01 Sep 2025 21:11:37 main.py INFO 		For sarcasm, C_M is 
[[109   4]
 [ 15  20]]
Mon, 01 Sep 2025 21:11:37 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:11:37 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:11:37 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:11:37 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:11:37 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:11:37 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:11:37 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:11:37 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:11:37 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:11:45 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:11:45 main.py INFO Time of iter training 8.14 s
Mon, 01 Sep 2025 21:11:45 main.py INFO On iter step 43.0:, global step 2752 Loss-step [1.1488 1.0018 1.0000 1.1467]
Mon, 01 Sep 2025 21:11:45 main.py INFO In dataset train: Loss is [0.1364 0.0000 0.0000 0.1364]
Mon, 01 Sep 2025 21:11:45 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:11:45 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:11:45 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:11:45 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:11:45 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:11:45 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:11:45 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:11:45 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:11:45 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:11:45 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:11:45 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:11:45 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:11:45 main.py INFO In dataset test: Loss is [2.0786 1.9527 0.0000 0.1259]
Mon, 01 Sep 2025 21:11:45 main.py INFO 		Acc is 0.8649, F1-micro is 0.8649
Mon, 01 Sep 2025 21:11:45 main.py INFO 		F1-macro is 0.7798, AUC is 0.5000
Mon, 01 Sep 2025 21:11:45 main.py INFO 		Pre-macro is 0.8616, Rec_macro is 0.7439
Mon, 01 Sep 2025 21:11:45 main.py INFO 		For sarcasm, C_M is 
[[110   3]
 [ 17  18]]
Mon, 01 Sep 2025 21:11:45 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:11:45 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:11:45 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:11:45 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:11:45 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:11:45 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:11:45 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:11:45 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:11:45 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:11:53 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:11:53 main.py INFO Time of iter training 7.79 s
Mon, 01 Sep 2025 21:11:53 main.py INFO On iter step 44.0:, global step 2816 Loss-step [1.1477 1.0011 1.0000 1.1464]
Mon, 01 Sep 2025 21:11:54 main.py INFO In dataset train: Loss is [0.1364 0.0001 0.0000 0.1364]
Mon, 01 Sep 2025 21:11:54 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:11:54 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:11:54 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:11:54 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:11:54 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:11:54 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:11:54 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:11:54 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:11:54 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:11:54 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:11:54 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:11:54 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:11:54 main.py INFO In dataset test: Loss is [1.6648 1.5379 0.0000 0.1269]
Mon, 01 Sep 2025 21:11:54 main.py INFO 		Acc is 0.8514, F1-micro is 0.8514
Mon, 01 Sep 2025 21:11:54 main.py INFO 		F1-macro is 0.7701, AUC is 0.5000
Mon, 01 Sep 2025 21:11:54 main.py INFO 		Pre-macro is 0.8150, Rec_macro is 0.7449
Mon, 01 Sep 2025 21:11:54 main.py INFO 		For sarcasm, C_M is 
[[107   6]
 [ 16  19]]
Mon, 01 Sep 2025 21:11:54 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:11:54 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:11:54 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:11:54 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:11:54 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:11:54 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:11:54 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:11:54 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:11:54 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:12:02 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:12:02 main.py INFO Time of iter training 8.22 s
Mon, 01 Sep 2025 21:12:02 main.py INFO On iter step 45.0:, global step 2880 Loss-step [1.1471 1.0016 1.0000 1.1452]
Mon, 01 Sep 2025 21:12:03 main.py INFO In dataset train: Loss is [0.1364 0.0000 0.0000 0.1364]
Mon, 01 Sep 2025 21:12:03 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:12:03 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:12:03 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:12:03 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:12:03 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:12:03 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:12:03 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:12:03 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:12:03 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:12:03 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:12:03 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:12:03 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:12:03 main.py INFO In dataset test: Loss is [2.1889 2.0628 0.0000 0.1261]
Mon, 01 Sep 2025 21:12:03 main.py INFO 		Acc is 0.8649, F1-micro is 0.8649
Mon, 01 Sep 2025 21:12:03 main.py INFO 		F1-macro is 0.7798, AUC is 0.5000
Mon, 01 Sep 2025 21:12:03 main.py INFO 		Pre-macro is 0.8616, Rec_macro is 0.7439
Mon, 01 Sep 2025 21:12:03 main.py INFO 		For sarcasm, C_M is 
[[110   3]
 [ 17  18]]
Mon, 01 Sep 2025 21:12:03 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:12:03 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:12:03 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:12:03 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:12:03 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:12:03 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:12:03 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:12:03 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:12:03 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:12:10 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:12:10 main.py INFO Time of iter training 7.51 s
Mon, 01 Sep 2025 21:12:10 main.py INFO On iter step 46.0:, global step 2944 Loss-step [1.1492 1.0008 1.0000 1.1483]
Mon, 01 Sep 2025 21:12:11 main.py INFO In dataset train: Loss is [0.1364 0.0000 0.0000 0.1364]
Mon, 01 Sep 2025 21:12:11 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:12:11 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:12:11 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:12:11 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:12:11 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:12:11 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:12:11 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:12:11 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:12:11 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:12:11 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:12:11 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:12:11 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:12:11 main.py INFO In dataset test: Loss is [1.8386 1.7128 0.0000 0.1258]
Mon, 01 Sep 2025 21:12:11 main.py INFO 		Acc is 0.8581, F1-micro is 0.8581
Mon, 01 Sep 2025 21:12:11 main.py INFO 		F1-macro is 0.7832, AUC is 0.5000
Mon, 01 Sep 2025 21:12:11 main.py INFO 		Pre-macro is 0.8231, Rec_macro is 0.7592
Mon, 01 Sep 2025 21:12:11 main.py INFO 		For sarcasm, C_M is 
[[107   6]
 [ 15  20]]
Mon, 01 Sep 2025 21:12:11 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:12:11 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:12:11 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:12:11 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:12:11 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:12:11 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:12:11 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:12:11 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:12:11 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:12:19 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:12:19 main.py INFO Time of iter training 7.65 s
Mon, 01 Sep 2025 21:12:19 main.py INFO On iter step 47.0:, global step 3008 Loss-step [1.1477 1.0012 1.0000 1.1464]
Mon, 01 Sep 2025 21:12:19 main.py INFO In dataset train: Loss is [0.1364 0.0000 0.0000 0.1364]
Mon, 01 Sep 2025 21:12:19 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:12:19 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:12:19 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:12:19 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:12:19 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:12:19 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:12:19 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:12:19 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:12:19 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:12:19 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:12:19 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:12:19 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:12:19 main.py INFO In dataset test: Loss is [2.3499 2.2236 0.0000 0.1263]
Mon, 01 Sep 2025 21:12:19 main.py INFO 		Acc is 0.8716, F1-micro is 0.8716
Mon, 01 Sep 2025 21:12:19 main.py INFO 		F1-macro is 0.7879, AUC is 0.5000
Mon, 01 Sep 2025 21:12:19 main.py INFO 		Pre-macro is 0.8836, Rec_macro is 0.7483
Mon, 01 Sep 2025 21:12:19 main.py INFO 		For sarcasm, C_M is 
[[111   2]
 [ 17  18]]
Mon, 01 Sep 2025 21:12:19 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:12:19 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:12:19 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:12:19 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:12:19 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:12:19 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:12:19 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:12:19 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:12:19 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:12:27 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:12:27 main.py INFO Time of iter training 7.42 s
Mon, 01 Sep 2025 21:12:27 main.py INFO On iter step 48.0:, global step 3072 Loss-step [1.1492 1.0030 1.0000 1.1458]
Mon, 01 Sep 2025 21:12:27 main.py INFO In dataset train: Loss is [0.1364 0.0000 0.0000 0.1364]
Mon, 01 Sep 2025 21:12:27 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:12:27 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:12:27 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:12:27 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:12:27 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:12:27 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:12:27 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:12:27 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:12:27 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:12:27 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:12:27 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:12:27 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:12:27 main.py INFO In dataset test: Loss is [2.0709 1.9444 0.0000 0.1264]
Mon, 01 Sep 2025 21:12:27 main.py INFO 		Acc is 0.8649, F1-micro is 0.8649
Mon, 01 Sep 2025 21:12:27 main.py INFO 		F1-macro is 0.7856, AUC is 0.5000
Mon, 01 Sep 2025 21:12:27 main.py INFO 		Pre-macro is 0.8490, Rec_macro is 0.7537
Mon, 01 Sep 2025 21:12:27 main.py INFO 		For sarcasm, C_M is 
[[109   4]
 [ 16  19]]
Mon, 01 Sep 2025 21:12:27 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:12:27 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:12:27 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:12:27 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:12:27 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:12:27 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:12:27 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:12:27 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:12:27 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:12:35 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:12:35 main.py INFO Time of iter training 7.35 s
Mon, 01 Sep 2025 21:12:35 main.py INFO On iter step 49.0:, global step 3136 Loss-step [1.1469 1.0003 1.0000 1.1466]
Mon, 01 Sep 2025 21:12:35 main.py INFO In dataset train: Loss is [0.1364 0.0000 0.0000 0.1364]
Mon, 01 Sep 2025 21:12:35 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:12:35 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:12:35 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:12:35 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:12:35 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:12:35 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:12:35 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:12:35 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:12:35 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:12:35 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:12:35 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:12:35 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:12:35 main.py INFO In dataset test: Loss is [2.2097 2.0826 0.0000 0.1271]
Mon, 01 Sep 2025 21:12:35 main.py INFO 		Acc is 0.8716, F1-micro is 0.8716
Mon, 01 Sep 2025 21:12:35 main.py INFO 		F1-macro is 0.7936, AUC is 0.5000
Mon, 01 Sep 2025 21:12:35 main.py INFO 		Pre-macro is 0.8683, Rec_macro is 0.7582
Mon, 01 Sep 2025 21:12:35 main.py INFO 		For sarcasm, C_M is 
[[110   3]
 [ 16  19]]
Mon, 01 Sep 2025 21:12:35 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:12:35 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:12:35 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:12:35 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:12:35 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:12:35 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:12:35 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:12:35 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:12:35 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:12:43 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:12:43 main.py INFO Time of iter training 7.75 s
Mon, 01 Sep 2025 21:12:43 main.py INFO On iter step 50.0:, global step 3200 Loss-step [1.1626 1.0143 1.0000 1.1462]
Mon, 01 Sep 2025 21:12:44 main.py INFO In dataset train: Loss is [0.1366 0.0002 0.0000 0.1364]
Mon, 01 Sep 2025 21:12:44 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:12:44 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:12:44 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:12:44 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:12:44 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:12:44 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:12:44 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:12:44 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:12:44 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:12:44 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:12:44 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:12:44 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:12:44 main.py INFO In dataset test: Loss is [1.4402 1.3133 0.0000 0.1268]
Mon, 01 Sep 2025 21:12:44 main.py INFO 		Acc is 0.8649, F1-micro is 0.8649
Mon, 01 Sep 2025 21:12:44 main.py INFO 		F1-macro is 0.7798, AUC is 0.5000
Mon, 01 Sep 2025 21:12:44 main.py INFO 		Pre-macro is 0.8616, Rec_macro is 0.7439
Mon, 01 Sep 2025 21:12:44 main.py INFO 		For sarcasm, C_M is 
[[110   3]
 [ 17  18]]
Mon, 01 Sep 2025 21:12:44 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:12:44 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:12:44 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:12:44 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:12:44 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:12:44 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:12:44 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:12:44 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:12:44 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:12:51 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:12:51 main.py INFO Time of iter training 7.85 s
Mon, 01 Sep 2025 21:12:51 main.py INFO On iter step 51.0:, global step 3264 Loss-step [1.1490 1.0023 1.0000 1.1464]
Mon, 01 Sep 2025 21:12:52 main.py INFO In dataset train: Loss is [0.1365 0.0001 0.0000 0.1364]
Mon, 01 Sep 2025 21:12:52 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:12:52 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:12:52 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:12:52 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:12:52 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:12:52 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:12:52 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:12:52 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:12:52 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:12:52 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:12:52 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:12:52 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:12:52 main.py INFO In dataset test: Loss is [1.4586 1.3321 0.0000 0.1265]
Mon, 01 Sep 2025 21:12:52 main.py INFO 		Acc is 0.8716, F1-micro is 0.8716
Mon, 01 Sep 2025 21:12:52 main.py INFO 		F1-macro is 0.8038, AUC is 0.5000
Mon, 01 Sep 2025 21:12:52 main.py INFO 		Pre-macro is 0.8465, Rec_macro is 0.7779
Mon, 01 Sep 2025 21:12:52 main.py INFO 		For sarcasm, C_M is 
[[108   5]
 [ 14  21]]
Mon, 01 Sep 2025 21:12:52 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:12:52 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:12:52 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:12:52 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:12:52 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:12:52 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:12:52 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:12:52 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:12:52 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:12:59 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:12:59 main.py INFO Time of iter training 7.22 s
Mon, 01 Sep 2025 21:12:59 main.py INFO On iter step 52.0:, global step 3328 Loss-step [1.1524 1.0039 1.0000 1.1479]
Mon, 01 Sep 2025 21:13:00 main.py INFO In dataset train: Loss is [0.1365 0.0001 0.0000 0.1364]
Mon, 01 Sep 2025 21:13:00 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:13:00 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:13:00 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:13:00 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:13:00 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:13:00 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:13:00 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:13:00 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:13:00 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:13:00 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:13:00 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:13:00 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:13:00 main.py INFO In dataset test: Loss is [1.7509 1.6247 0.0000 0.1262]
Mon, 01 Sep 2025 21:13:00 main.py INFO 		Acc is 0.8784, F1-micro is 0.8784
Mon, 01 Sep 2025 21:13:00 main.py INFO 		F1-macro is 0.8018, AUC is 0.5000
Mon, 01 Sep 2025 21:13:00 main.py INFO 		Pre-macro is 0.8894, Rec_macro is 0.7626
Mon, 01 Sep 2025 21:13:00 main.py INFO 		For sarcasm, C_M is 
[[111   2]
 [ 16  19]]
Mon, 01 Sep 2025 21:13:00 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:13:00 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:13:00 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:13:00 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:13:00 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:13:00 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:13:00 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:13:00 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:13:00 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:13:07 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:13:07 main.py INFO Time of iter training 6.91 s
Mon, 01 Sep 2025 21:13:07 main.py INFO On iter step 53.0:, global step 3392 Loss-step [1.1472 1.0005 1.0000 1.1466]
Mon, 01 Sep 2025 21:13:07 main.py INFO In dataset train: Loss is [0.1364 0.0000 0.0000 0.1364]
Mon, 01 Sep 2025 21:13:07 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:13:07 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:13:07 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:13:07 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:13:07 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:13:07 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:13:07 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:13:07 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:13:07 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:13:07 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:13:07 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:13:07 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:13:08 main.py INFO In dataset test: Loss is [1.8036 1.6772 0.0000 0.1264]
Mon, 01 Sep 2025 21:13:08 main.py INFO 		Acc is 0.8716, F1-micro is 0.8716
Mon, 01 Sep 2025 21:13:08 main.py INFO 		F1-macro is 0.7936, AUC is 0.5000
Mon, 01 Sep 2025 21:13:08 main.py INFO 		Pre-macro is 0.8683, Rec_macro is 0.7582
Mon, 01 Sep 2025 21:13:08 main.py INFO 		For sarcasm, C_M is 
[[110   3]
 [ 16  19]]
Mon, 01 Sep 2025 21:13:08 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:13:08 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:13:08 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:13:08 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:13:08 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:13:08 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:13:08 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:13:08 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:13:08 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:13:14 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:13:14 main.py INFO Time of iter training 6.94 s
Mon, 01 Sep 2025 21:13:14 main.py INFO On iter step 54.0:, global step 3456 Loss-step [1.1471 1.0002 1.0000 1.1469]
Mon, 01 Sep 2025 21:13:15 main.py INFO In dataset train: Loss is [0.1364 0.0000 0.0000 0.1364]
Mon, 01 Sep 2025 21:13:15 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:13:15 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:13:15 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:13:15 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:13:15 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:13:15 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:13:15 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:13:15 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:13:15 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:13:15 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:13:15 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:13:15 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:13:15 main.py INFO In dataset test: Loss is [2.0543 1.9278 0.0000 0.1265]
Mon, 01 Sep 2025 21:13:15 main.py INFO 		Acc is 0.8649, F1-micro is 0.8649
Mon, 01 Sep 2025 21:13:15 main.py INFO 		F1-macro is 0.7856, AUC is 0.5000
Mon, 01 Sep 2025 21:13:15 main.py INFO 		Pre-macro is 0.8490, Rec_macro is 0.7537
Mon, 01 Sep 2025 21:13:15 main.py INFO 		For sarcasm, C_M is 
[[109   4]
 [ 16  19]]
Mon, 01 Sep 2025 21:13:15 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:13:15 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:13:15 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:13:15 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:13:15 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:13:15 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:13:15 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:13:15 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:13:15 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:13:22 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:13:22 main.py INFO Time of iter training 7.08 s
Mon, 01 Sep 2025 21:13:22 main.py INFO On iter step 55.0:, global step 3520 Loss-step [1.1469 1.0004 1.0000 1.1464]
Mon, 01 Sep 2025 21:13:23 main.py INFO In dataset train: Loss is [0.1364 0.0000 0.0000 0.1364]
Mon, 01 Sep 2025 21:13:23 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:13:23 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:13:23 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:13:23 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:13:23 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:13:23 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:13:23 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:13:23 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:13:23 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:13:23 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:13:23 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:13:23 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:13:23 main.py INFO In dataset test: Loss is [1.9268 1.7999 0.0000 0.1269]
Mon, 01 Sep 2025 21:13:23 main.py INFO 		Acc is 0.8649, F1-micro is 0.8649
Mon, 01 Sep 2025 21:13:23 main.py INFO 		F1-macro is 0.7856, AUC is 0.5000
Mon, 01 Sep 2025 21:13:23 main.py INFO 		Pre-macro is 0.8490, Rec_macro is 0.7537
Mon, 01 Sep 2025 21:13:23 main.py INFO 		For sarcasm, C_M is 
[[109   4]
 [ 16  19]]
Mon, 01 Sep 2025 21:13:23 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:13:23 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:13:23 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:13:23 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:13:23 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:13:23 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:13:23 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:13:23 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:13:23 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:13:30 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:13:30 main.py INFO Time of iter training 7.16 s
Mon, 01 Sep 2025 21:13:30 main.py INFO On iter step 56.0:, global step 3584 Loss-step [1.1531 1.0072 1.0000 1.1449]
Mon, 01 Sep 2025 21:13:31 main.py INFO In dataset train: Loss is [0.1391 0.0028 0.0000 0.1364]
Mon, 01 Sep 2025 21:13:31 main.py INFO 		Acc is 0.9992, F1-micro is 0.9992
Mon, 01 Sep 2025 21:13:31 main.py INFO 		F1-macro is 0.9989, AUC is 0.5000
Mon, 01 Sep 2025 21:13:31 main.py INFO 		Pre-macro is 0.9982, Rec_macro is 0.9995
Mon, 01 Sep 2025 21:13:31 main.py INFO 		For sarcasm, C_M is 
[[1048    1]
 [   0  282]]
Mon, 01 Sep 2025 21:13:31 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:13:31 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:13:31 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:13:31 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:13:31 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:13:31 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:13:31 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:13:31 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:13:31 main.py INFO In dataset test: Loss is [1.3816 1.2549 0.0000 0.1267]
Mon, 01 Sep 2025 21:13:31 main.py INFO 		Acc is 0.8716, F1-micro is 0.8716
Mon, 01 Sep 2025 21:13:31 main.py INFO 		F1-macro is 0.8038, AUC is 0.5000
Mon, 01 Sep 2025 21:13:31 main.py INFO 		Pre-macro is 0.8465, Rec_macro is 0.7779
Mon, 01 Sep 2025 21:13:31 main.py INFO 		For sarcasm, C_M is 
[[108   5]
 [ 14  21]]
Mon, 01 Sep 2025 21:13:31 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:13:31 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:13:31 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:13:31 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:13:31 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:13:31 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:13:31 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:13:31 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:13:31 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:13:38 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:13:38 main.py INFO Time of iter training 7.45 s
Mon, 01 Sep 2025 21:13:38 main.py INFO On iter step 57.0:, global step 3648 Loss-step [1.1505 1.0022 1.0000 1.1480]
Mon, 01 Sep 2025 21:13:39 main.py INFO In dataset train: Loss is [0.1364 0.0000 0.0000 0.1364]
Mon, 01 Sep 2025 21:13:39 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:13:39 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:13:39 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:13:39 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:13:39 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:13:39 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:13:39 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:13:39 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:13:39 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:13:39 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:13:39 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:13:39 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:13:39 main.py INFO In dataset test: Loss is [2.4840 2.3581 0.0000 0.1259]
Mon, 01 Sep 2025 21:13:39 main.py INFO 		Acc is 0.8649, F1-micro is 0.8649
Mon, 01 Sep 2025 21:13:39 main.py INFO 		F1-macro is 0.7798, AUC is 0.5000
Mon, 01 Sep 2025 21:13:39 main.py INFO 		Pre-macro is 0.8616, Rec_macro is 0.7439
Mon, 01 Sep 2025 21:13:39 main.py INFO 		For sarcasm, C_M is 
[[110   3]
 [ 17  18]]
Mon, 01 Sep 2025 21:13:39 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:13:39 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:13:39 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:13:39 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:13:39 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:13:39 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:13:39 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:13:39 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:13:39 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:13:46 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:13:46 main.py INFO Time of iter training 7.40 s
Mon, 01 Sep 2025 21:13:46 main.py INFO On iter step 58.0:, global step 3712 Loss-step [1.1498 1.0030 1.0000 1.1463]
Mon, 01 Sep 2025 21:13:47 main.py INFO In dataset train: Loss is [0.1368 0.0004 0.0000 0.1364]
Mon, 01 Sep 2025 21:13:47 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:13:47 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:13:47 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:13:47 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:13:47 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:13:47 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:13:47 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:13:47 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:13:47 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:13:47 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:13:47 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:13:47 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:13:47 main.py INFO In dataset test: Loss is [2.3153 2.1894 0.0000 0.1260]
Mon, 01 Sep 2025 21:13:47 main.py INFO 		Acc is 0.8716, F1-micro is 0.8716
Mon, 01 Sep 2025 21:13:47 main.py INFO 		F1-macro is 0.7879, AUC is 0.5000
Mon, 01 Sep 2025 21:13:47 main.py INFO 		Pre-macro is 0.8836, Rec_macro is 0.7483
Mon, 01 Sep 2025 21:13:47 main.py INFO 		For sarcasm, C_M is 
[[111   2]
 [ 17  18]]
Mon, 01 Sep 2025 21:13:47 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:13:47 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:13:47 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:13:47 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:13:47 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:13:47 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:13:47 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:13:47 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:13:47 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:13:54 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:13:54 main.py INFO Time of iter training 7.23 s
Mon, 01 Sep 2025 21:13:54 main.py INFO On iter step 59.0:, global step 3776 Loss-step [1.1468 1.0009 1.0000 1.1457]
Mon, 01 Sep 2025 21:13:55 main.py INFO In dataset train: Loss is [0.1364 0.0000 0.0000 0.1364]
Mon, 01 Sep 2025 21:13:55 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:13:55 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:13:55 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:13:55 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:13:55 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:13:55 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:13:55 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:13:55 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:13:55 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:13:55 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:13:55 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:13:55 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:13:55 main.py INFO In dataset test: Loss is [2.6324 2.5052 0.0000 0.1272]
Mon, 01 Sep 2025 21:13:55 main.py INFO 		Acc is 0.8581, F1-micro is 0.8581
Mon, 01 Sep 2025 21:13:55 main.py INFO 		F1-macro is 0.7719, AUC is 0.5000
Mon, 01 Sep 2025 21:13:55 main.py INFO 		Pre-macro is 0.8416, Rec_macro is 0.7394
Mon, 01 Sep 2025 21:13:55 main.py INFO 		For sarcasm, C_M is 
[[109   4]
 [ 17  18]]
Mon, 01 Sep 2025 21:13:55 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:13:55 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:13:55 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:13:55 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:13:55 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:13:55 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:13:55 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:13:55 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:13:55 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:14:02 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:14:02 main.py INFO Time of iter training 7.53 s
Mon, 01 Sep 2025 21:14:02 main.py INFO On iter step 60.0:, global step 3840 Loss-step [1.1469 1.0003 1.0000 1.1465]
Mon, 01 Sep 2025 21:14:03 main.py INFO In dataset train: Loss is [0.1364 0.0000 0.0000 0.1364]
Mon, 01 Sep 2025 21:14:03 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:14:03 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:14:03 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:14:03 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:14:03 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:14:03 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:14:03 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:14:03 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:14:03 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:14:03 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:14:03 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:14:03 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:14:03 main.py INFO In dataset test: Loss is [2.2530 2.1260 0.0000 0.1270]
Mon, 01 Sep 2025 21:14:03 main.py INFO 		Acc is 0.8649, F1-micro is 0.8649
Mon, 01 Sep 2025 21:14:03 main.py INFO 		F1-macro is 0.7856, AUC is 0.5000
Mon, 01 Sep 2025 21:14:03 main.py INFO 		Pre-macro is 0.8490, Rec_macro is 0.7537
Mon, 01 Sep 2025 21:14:03 main.py INFO 		For sarcasm, C_M is 
[[109   4]
 [ 16  19]]
Mon, 01 Sep 2025 21:14:03 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:14:03 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:14:03 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:14:03 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:14:03 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:14:03 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:14:03 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:14:03 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:14:03 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:14:11 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:14:11 main.py INFO Time of iter training 7.33 s
Mon, 01 Sep 2025 21:14:11 main.py INFO On iter step 61.0:, global step 3904 Loss-step [1.1468 1.0009 1.0000 1.1458]
Mon, 01 Sep 2025 21:14:11 main.py INFO In dataset train: Loss is [0.1364 0.0000 0.0000 0.1364]
Mon, 01 Sep 2025 21:14:11 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:14:11 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:14:11 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:14:11 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:14:11 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:14:11 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:14:11 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:14:11 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:14:11 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:14:11 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:14:11 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:14:11 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:14:11 main.py INFO In dataset test: Loss is [1.9165 1.7897 0.0000 0.1268]
Mon, 01 Sep 2025 21:14:11 main.py INFO 		Acc is 0.8649, F1-micro is 0.8649
Mon, 01 Sep 2025 21:14:11 main.py INFO 		F1-macro is 0.7910, AUC is 0.5000
Mon, 01 Sep 2025 21:14:11 main.py INFO 		Pre-macro is 0.8390, Rec_macro is 0.7636
Mon, 01 Sep 2025 21:14:11 main.py INFO 		For sarcasm, C_M is 
[[108   5]
 [ 15  20]]
Mon, 01 Sep 2025 21:14:11 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:14:11 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:14:11 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:14:11 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:14:11 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:14:11 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:14:11 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:14:11 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:14:11 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:14:19 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:14:19 main.py INFO Time of iter training 7.34 s
Mon, 01 Sep 2025 21:14:19 main.py INFO On iter step 62.0:, global step 3968 Loss-step [1.1473 1.0008 1.0000 1.1463]
Mon, 01 Sep 2025 21:14:19 main.py INFO In dataset train: Loss is [0.1364 0.0000 0.0000 0.1364]
Mon, 01 Sep 2025 21:14:19 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:14:19 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:14:19 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:14:19 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:14:19 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:14:19 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:14:19 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:14:19 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:14:19 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:14:19 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:14:19 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:14:19 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:14:19 main.py INFO In dataset test: Loss is [2.1088 1.9826 0.0000 0.1262]
Mon, 01 Sep 2025 21:14:19 main.py INFO 		Acc is 0.8716, F1-micro is 0.8716
Mon, 01 Sep 2025 21:14:19 main.py INFO 		F1-macro is 0.7936, AUC is 0.5000
Mon, 01 Sep 2025 21:14:19 main.py INFO 		Pre-macro is 0.8683, Rec_macro is 0.7582
Mon, 01 Sep 2025 21:14:19 main.py INFO 		For sarcasm, C_M is 
[[110   3]
 [ 16  19]]
Mon, 01 Sep 2025 21:14:19 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:14:19 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:14:19 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:14:19 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:14:19 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:14:19 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:14:19 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:14:19 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:14:19 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:14:26 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:14:26 main.py INFO Time of iter training 7.21 s
Mon, 01 Sep 2025 21:14:26 main.py INFO On iter step 63.0:, global step 4032 Loss-step [1.1488 1.0009 1.0000 1.1477]
Mon, 01 Sep 2025 21:14:27 main.py INFO In dataset train: Loss is [0.1365 0.0000 0.0000 0.1365]
Mon, 01 Sep 2025 21:14:27 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:14:27 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:14:27 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:14:27 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:14:27 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:14:27 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:14:27 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:14:27 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:14:27 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:14:27 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:14:27 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:14:27 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:14:27 main.py INFO In dataset test: Loss is [2.3785 2.2534 0.0000 0.1252]
Mon, 01 Sep 2025 21:14:27 main.py INFO 		Acc is 0.8649, F1-micro is 0.8649
Mon, 01 Sep 2025 21:14:27 main.py INFO 		F1-macro is 0.7798, AUC is 0.5000
Mon, 01 Sep 2025 21:14:27 main.py INFO 		Pre-macro is 0.8616, Rec_macro is 0.7439
Mon, 01 Sep 2025 21:14:27 main.py INFO 		For sarcasm, C_M is 
[[110   3]
 [ 17  18]]
Mon, 01 Sep 2025 21:14:27 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:14:27 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:14:27 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:14:27 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:14:27 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:14:27 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:14:27 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:14:27 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:14:27 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:14:35 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:14:35 main.py INFO Time of iter training 7.42 s
Mon, 01 Sep 2025 21:14:35 main.py INFO On iter step 64.0:, global step 4096 Loss-step [1.1512 1.0041 1.0000 1.1465]
Mon, 01 Sep 2025 21:14:35 main.py INFO In dataset train: Loss is [0.1383 0.0019 0.0000 0.1364]
Mon, 01 Sep 2025 21:14:35 main.py INFO 		Acc is 0.9992, F1-micro is 0.9992
Mon, 01 Sep 2025 21:14:35 main.py INFO 		F1-macro is 0.9989, AUC is 0.5000
Mon, 01 Sep 2025 21:14:35 main.py INFO 		Pre-macro is 0.9982, Rec_macro is 0.9995
Mon, 01 Sep 2025 21:14:35 main.py INFO 		For sarcasm, C_M is 
[[1048    1]
 [   0  282]]
Mon, 01 Sep 2025 21:14:35 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:14:35 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:14:35 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:14:35 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:14:35 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:14:35 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:14:35 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:14:35 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:14:35 main.py INFO In dataset test: Loss is [1.2869 1.1604 0.0000 0.1265]
Mon, 01 Sep 2025 21:14:35 main.py INFO 		Acc is 0.8649, F1-micro is 0.8649
Mon, 01 Sep 2025 21:14:35 main.py INFO 		F1-macro is 0.8006, AUC is 0.5000
Mon, 01 Sep 2025 21:14:35 main.py INFO 		Pre-macro is 0.8247, Rec_macro is 0.7833
Mon, 01 Sep 2025 21:14:35 main.py INFO 		For sarcasm, C_M is 
[[106   7]
 [ 13  22]]
Mon, 01 Sep 2025 21:14:35 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:14:35 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:14:35 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:14:35 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:14:35 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:14:35 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:14:35 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:14:35 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:14:35 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:14:42 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:14:42 main.py INFO Time of iter training 6.96 s
Mon, 01 Sep 2025 21:14:42 main.py INFO On iter step 65.0:, global step 4160 Loss-step [1.1508 1.0038 1.0000 1.1465]
Mon, 01 Sep 2025 21:14:43 main.py INFO In dataset train: Loss is [0.1488 0.0124 0.0000 0.1364]
Mon, 01 Sep 2025 21:14:43 main.py INFO 		Acc is 0.9992, F1-micro is 0.9992
Mon, 01 Sep 2025 21:14:43 main.py INFO 		F1-macro is 0.9989, AUC is 0.5000
Mon, 01 Sep 2025 21:14:43 main.py INFO 		Pre-macro is 0.9995, Rec_macro is 0.9982
Mon, 01 Sep 2025 21:14:43 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   1  281]]
Mon, 01 Sep 2025 21:14:43 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:14:43 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:14:43 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:14:43 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:14:43 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:14:43 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:14:43 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:14:43 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:14:43 main.py INFO In dataset test: Loss is [1.7550 1.6284 0.0000 0.1266]
Mon, 01 Sep 2025 21:14:43 main.py INFO 		Acc is 0.8784, F1-micro is 0.8784
Mon, 01 Sep 2025 21:14:43 main.py INFO 		F1-macro is 0.8018, AUC is 0.5000
Mon, 01 Sep 2025 21:14:43 main.py INFO 		Pre-macro is 0.8894, Rec_macro is 0.7626
Mon, 01 Sep 2025 21:14:43 main.py INFO 		For sarcasm, C_M is 
[[111   2]
 [ 16  19]]
Mon, 01 Sep 2025 21:14:43 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:14:43 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:14:43 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:14:43 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:14:43 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:14:43 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:14:43 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:14:43 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:14:43 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:14:50 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:14:50 main.py INFO Time of iter training 7.70 s
Mon, 01 Sep 2025 21:14:50 main.py INFO On iter step 66.0:, global step 4224 Loss-step [1.1595 1.0115 1.0000 1.1464]
Mon, 01 Sep 2025 21:14:51 main.py INFO In dataset train: Loss is [0.1365 0.0002 0.0000 0.1364]
Mon, 01 Sep 2025 21:14:51 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:14:51 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:14:51 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:14:51 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:14:51 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:14:51 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:14:51 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:14:51 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:14:51 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:14:51 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:14:51 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:14:51 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:14:51 main.py INFO In dataset test: Loss is [1.6594 1.5328 0.0000 0.1266]
Mon, 01 Sep 2025 21:14:51 main.py INFO 		Acc is 0.8581, F1-micro is 0.8581
Mon, 01 Sep 2025 21:14:51 main.py INFO 		F1-macro is 0.7719, AUC is 0.5000
Mon, 01 Sep 2025 21:14:51 main.py INFO 		Pre-macro is 0.8416, Rec_macro is 0.7394
Mon, 01 Sep 2025 21:14:51 main.py INFO 		For sarcasm, C_M is 
[[109   4]
 [ 17  18]]
Mon, 01 Sep 2025 21:14:51 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:14:51 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:14:51 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:14:51 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:14:51 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:14:51 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:14:51 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:14:51 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:14:51 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:14:58 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:14:58 main.py INFO Time of iter training 6.96 s
Mon, 01 Sep 2025 21:14:58 main.py INFO On iter step 67.0:, global step 4288 Loss-step [1.1471 1.0021 1.0000 1.1447]
Mon, 01 Sep 2025 21:14:59 main.py INFO In dataset train: Loss is [0.1364 0.0000 0.0000 0.1364]
Mon, 01 Sep 2025 21:14:59 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:14:59 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:14:59 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:14:59 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:14:59 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:14:59 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:14:59 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:14:59 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:14:59 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:14:59 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:14:59 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:14:59 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:14:59 main.py INFO In dataset test: Loss is [1.9640 1.8369 0.0000 0.1272]
Mon, 01 Sep 2025 21:14:59 main.py INFO 		Acc is 0.8716, F1-micro is 0.8716
Mon, 01 Sep 2025 21:14:59 main.py INFO 		F1-macro is 0.7989, AUC is 0.5000
Mon, 01 Sep 2025 21:14:59 main.py INFO 		Pre-macro is 0.8562, Rec_macro is 0.7680
Mon, 01 Sep 2025 21:14:59 main.py INFO 		For sarcasm, C_M is 
[[109   4]
 [ 15  20]]
Mon, 01 Sep 2025 21:14:59 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:14:59 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:14:59 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:14:59 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:14:59 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:14:59 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:14:59 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:14:59 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:14:59 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:15:06 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:15:06 main.py INFO Time of iter training 7.57 s
Mon, 01 Sep 2025 21:15:06 main.py INFO On iter step 68.0:, global step 4352 Loss-step [1.1519 1.0033 1.0000 1.1481]
Mon, 01 Sep 2025 21:15:07 main.py INFO In dataset train: Loss is [0.1364 0.0001 0.0000 0.1364]
Mon, 01 Sep 2025 21:15:07 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:15:07 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:15:07 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:15:07 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:15:07 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:15:07 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:15:07 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:15:07 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:15:07 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:15:07 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:15:07 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:15:07 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:15:07 main.py INFO In dataset test: Loss is [1.8994 1.7730 0.0000 0.1264]
Mon, 01 Sep 2025 21:15:07 main.py INFO 		Acc is 0.8851, F1-micro is 0.8851
Mon, 01 Sep 2025 21:15:07 main.py INFO 		F1-macro is 0.8153, AUC is 0.5000
Mon, 01 Sep 2025 21:15:07 main.py INFO 		Pre-macro is 0.8950, Rec_macro is 0.7769
Mon, 01 Sep 2025 21:15:07 main.py INFO 		For sarcasm, C_M is 
[[111   2]
 [ 15  20]]
Mon, 01 Sep 2025 21:15:07 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:15:07 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:15:07 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:15:07 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:15:07 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:15:07 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:15:07 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:15:07 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:15:07 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:15:15 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:15:15 main.py INFO Time of iter training 8.43 s
Mon, 01 Sep 2025 21:15:15 main.py INFO On iter step 69.0:, global step 4416 Loss-step [1.1466 1.0004 1.0000 1.1461]
Mon, 01 Sep 2025 21:15:16 main.py INFO In dataset train: Loss is [0.1364 0.0000 0.0000 0.1364]
Mon, 01 Sep 2025 21:15:16 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:15:16 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:15:16 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:15:16 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:15:16 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:15:16 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:15:16 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:15:16 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:15:16 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:15:16 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:15:16 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:15:16 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:15:16 main.py INFO In dataset test: Loss is [2.2398 2.1139 0.0000 0.1259]
Mon, 01 Sep 2025 21:15:16 main.py INFO 		Acc is 0.8649, F1-micro is 0.8649
Mon, 01 Sep 2025 21:15:16 main.py INFO 		F1-macro is 0.7798, AUC is 0.5000
Mon, 01 Sep 2025 21:15:16 main.py INFO 		Pre-macro is 0.8616, Rec_macro is 0.7439
Mon, 01 Sep 2025 21:15:16 main.py INFO 		For sarcasm, C_M is 
[[110   3]
 [ 17  18]]
Mon, 01 Sep 2025 21:15:16 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:15:16 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:15:16 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:15:16 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:15:16 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:15:16 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:15:16 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:15:16 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:15:16 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:15:23 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:15:23 main.py INFO Time of iter training 7.16 s
Mon, 01 Sep 2025 21:15:23 main.py INFO On iter step 70.0:, global step 4480 Loss-step [1.1463 1.0002 1.0000 1.1460]
Mon, 01 Sep 2025 21:15:24 main.py INFO In dataset train: Loss is [0.1364 0.0000 0.0000 0.1364]
Mon, 01 Sep 2025 21:15:24 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:15:24 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:15:24 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:15:24 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:15:24 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:15:24 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:15:24 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:15:24 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:15:24 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:15:24 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:15:24 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:15:24 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:15:24 main.py INFO In dataset test: Loss is [2.2544 2.1276 0.0000 0.1268]
Mon, 01 Sep 2025 21:15:24 main.py INFO 		Acc is 0.8716, F1-micro is 0.8716
Mon, 01 Sep 2025 21:15:24 main.py INFO 		F1-macro is 0.7879, AUC is 0.5000
Mon, 01 Sep 2025 21:15:24 main.py INFO 		Pre-macro is 0.8836, Rec_macro is 0.7483
Mon, 01 Sep 2025 21:15:24 main.py INFO 		For sarcasm, C_M is 
[[111   2]
 [ 17  18]]
Mon, 01 Sep 2025 21:15:24 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:15:24 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:15:24 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:15:24 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:15:24 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:15:24 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:15:24 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:15:24 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:15:24 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:15:31 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:15:31 main.py INFO Time of iter training 7.39 s
Mon, 01 Sep 2025 21:15:31 main.py INFO On iter step 71.0:, global step 4544 Loss-step [1.1469 1.0005 1.0000 1.1462]
Mon, 01 Sep 2025 21:15:32 main.py INFO In dataset train: Loss is [0.1364 0.0000 0.0000 0.1364]
Mon, 01 Sep 2025 21:15:32 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:15:32 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:15:32 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:15:32 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:15:32 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:15:32 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:15:32 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:15:32 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:15:32 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:15:32 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:15:32 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:15:32 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:15:32 main.py INFO In dataset test: Loss is [1.9701 1.8428 0.0000 0.1273]
Mon, 01 Sep 2025 21:15:32 main.py INFO 		Acc is 0.8716, F1-micro is 0.8716
Mon, 01 Sep 2025 21:15:32 main.py INFO 		F1-macro is 0.7936, AUC is 0.5000
Mon, 01 Sep 2025 21:15:32 main.py INFO 		Pre-macro is 0.8683, Rec_macro is 0.7582
Mon, 01 Sep 2025 21:15:32 main.py INFO 		For sarcasm, C_M is 
[[110   3]
 [ 16  19]]
Mon, 01 Sep 2025 21:15:32 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:15:32 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:15:32 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:15:32 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:15:32 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:15:32 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:15:32 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:15:32 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:15:32 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:15:40 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:15:40 main.py INFO Time of iter training 8.00 s
Mon, 01 Sep 2025 21:15:40 main.py INFO On iter step 72.0:, global step 4608 Loss-step [1.1518 1.0048 1.0000 1.1463]
Mon, 01 Sep 2025 21:15:41 main.py INFO In dataset train: Loss is [0.1370 0.0006 0.0000 0.1364]
Mon, 01 Sep 2025 21:15:41 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:15:41 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:15:41 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:15:41 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:15:41 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:15:41 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:15:41 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:15:41 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:15:41 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:15:41 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:15:41 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:15:41 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:15:41 main.py INFO In dataset test: Loss is [1.6764 1.5486 0.0000 0.1278]
Mon, 01 Sep 2025 21:15:41 main.py INFO 		Acc is 0.8649, F1-micro is 0.8649
Mon, 01 Sep 2025 21:15:41 main.py INFO 		F1-macro is 0.7856, AUC is 0.5000
Mon, 01 Sep 2025 21:15:41 main.py INFO 		Pre-macro is 0.8490, Rec_macro is 0.7537
Mon, 01 Sep 2025 21:15:41 main.py INFO 		For sarcasm, C_M is 
[[109   4]
 [ 16  19]]
Mon, 01 Sep 2025 21:15:41 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:15:41 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:15:41 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:15:41 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:15:41 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:15:41 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:15:41 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:15:41 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:15:41 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:15:48 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:15:48 main.py INFO Time of iter training 6.95 s
Mon, 01 Sep 2025 21:15:48 main.py INFO On iter step 73.0:, global step 4672 Loss-step [1.1467 1.0008 1.0000 1.1458]
Mon, 01 Sep 2025 21:15:48 main.py INFO In dataset train: Loss is [0.1364 0.0000 0.0000 0.1364]
Mon, 01 Sep 2025 21:15:48 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:15:48 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:15:48 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:15:48 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:15:48 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:15:48 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:15:48 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:15:48 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:15:48 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:15:48 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:15:48 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:15:48 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:15:48 main.py INFO In dataset test: Loss is [2.2412 2.1144 0.0000 0.1267]
Mon, 01 Sep 2025 21:15:48 main.py INFO 		Acc is 0.8649, F1-micro is 0.8649
Mon, 01 Sep 2025 21:15:48 main.py INFO 		F1-macro is 0.7856, AUC is 0.5000
Mon, 01 Sep 2025 21:15:48 main.py INFO 		Pre-macro is 0.8490, Rec_macro is 0.7537
Mon, 01 Sep 2025 21:15:48 main.py INFO 		For sarcasm, C_M is 
[[109   4]
 [ 16  19]]
Mon, 01 Sep 2025 21:15:48 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:15:48 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:15:48 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:15:48 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:15:48 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:15:48 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:15:48 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:15:48 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:15:48 main.py INFO testacc: 0.8986
Mon, 01 Sep 2025 21:15:56 main.py INFO --------------------------------------------------
Mon, 01 Sep 2025 21:15:56 main.py INFO Time of iter training 7.37 s
Mon, 01 Sep 2025 21:15:56 main.py INFO On iter step 74.0:, global step 4736 Loss-step [1.1488 1.0005 1.0000 1.1483]
Mon, 01 Sep 2025 21:15:56 main.py INFO In dataset train: Loss is [0.1364 0.0000 0.0000 0.1364]
Mon, 01 Sep 2025 21:15:56 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:15:56 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:15:56 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:15:56 main.py INFO 		For sarcasm, C_M is 
[[1049    0]
 [   0  282]]
Mon, 01 Sep 2025 21:15:56 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:15:56 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:15:56 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:15:56 main.py INFO 		For literal, C_M is 
[[ 282    0]
 [   0 1049]]
Mon, 01 Sep 2025 21:15:56 main.py INFO 		Acc is 0.9504, F1-micro is 0.9504
Mon, 01 Sep 2025 21:15:56 main.py INFO 		F1-macro is 0.9448, AUC is 0.5000
Mon, 01 Sep 2025 21:15:56 main.py INFO 		Pre-macro is 0.9638, Rec_macro is 0.9321
Mon, 01 Sep 2025 21:15:56 main.py INFO 		For deep, C_M is 
[[420  66]
 [  0 845]]
Mon, 01 Sep 2025 21:15:56 main.py INFO In dataset test: Loss is [2.3368 2.2110 0.0000 0.1258]
Mon, 01 Sep 2025 21:15:56 main.py INFO 		Acc is 0.8649, F1-micro is 0.8649
Mon, 01 Sep 2025 21:15:56 main.py INFO 		F1-macro is 0.7798, AUC is 0.5000
Mon, 01 Sep 2025 21:15:56 main.py INFO 		Pre-macro is 0.8616, Rec_macro is 0.7439
Mon, 01 Sep 2025 21:15:56 main.py INFO 		For sarcasm, C_M is 
[[110   3]
 [ 17  18]]
Mon, 01 Sep 2025 21:15:56 main.py INFO 		Acc is 1.0000, F1-micro is 1.0000
Mon, 01 Sep 2025 21:15:56 main.py INFO 		F1-macro is 1.0000, AUC is 0.5000
Mon, 01 Sep 2025 21:15:56 main.py INFO 		Pre-macro is 1.0000, Rec_macro is 1.0000
Mon, 01 Sep 2025 21:15:56 main.py INFO 		For literal, C_M is 
[[ 28   0]
 [  0 120]]
Mon, 01 Sep 2025 21:15:56 main.py INFO 		Acc is 0.9392, F1-micro is 0.9392
Mon, 01 Sep 2025 21:15:56 main.py INFO 		F1-macro is 0.9257, AUC is 0.5000
Mon, 01 Sep 2025 21:15:56 main.py INFO 		Pre-macro is 0.9591, Rec_macro is 0.9043
Mon, 01 Sep 2025 21:15:56 main.py INFO 		For deep, C_M is 
[[ 38   9]
 [  0 101]]
Mon, 01 Sep 2025 21:15:56 main.py INFO testacc: 0.8986
